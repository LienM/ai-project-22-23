{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Introduction to Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('../data/articles.csv')\n",
    "customers = pd.read_csv('../data/customers.csv')\n",
    "# sample_submisison = pd.read_csv('../data/sample_submission.csv')\n",
    "transactions = pd.read_csv('../data/temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The H&M Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105542 entries, 0 to 105541\n",
      "Data columns (total 25 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   article_id                    105542 non-null  int64 \n",
      " 1   product_code                  105542 non-null  int64 \n",
      " 2   prod_name                     105542 non-null  object\n",
      " 3   product_type_no               105542 non-null  int64 \n",
      " 4   product_type_name             105542 non-null  object\n",
      " 5   product_group_name            105542 non-null  object\n",
      " 6   graphical_appearance_no       105542 non-null  int64 \n",
      " 7   graphical_appearance_name     105542 non-null  object\n",
      " 8   colour_group_code             105542 non-null  int64 \n",
      " 9   colour_group_name             105542 non-null  object\n",
      " 10  perceived_colour_value_id     105542 non-null  int64 \n",
      " 11  perceived_colour_value_name   105542 non-null  object\n",
      " 12  perceived_colour_master_id    105542 non-null  int64 \n",
      " 13  perceived_colour_master_name  105542 non-null  object\n",
      " 14  department_no                 105542 non-null  int64 \n",
      " 15  department_name               105542 non-null  object\n",
      " 16  index_code                    105542 non-null  object\n",
      " 17  index_name                    105542 non-null  object\n",
      " 18  index_group_no                105542 non-null  int64 \n",
      " 19  index_group_name              105542 non-null  object\n",
      " 20  section_no                    105542 non-null  int64 \n",
      " 21  section_name                  105542 non-null  object\n",
      " 22  garment_group_no              105542 non-null  int64 \n",
      " 23  garment_group_name            105542 non-null  object\n",
      " 24  detail_desc                   105126 non-null  object\n",
      "dtypes: int64(11), object(14)\n",
      "memory usage: 20.1+ MB\n"
     ]
    }
   ],
   "source": [
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1371980 entries, 0 to 1371979\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count    Dtype  \n",
      "---  ------                  --------------    -----  \n",
      " 0   customer_id             1371980 non-null  object \n",
      " 1   FN                      476930 non-null   float64\n",
      " 2   Active                  464404 non-null   float64\n",
      " 3   club_member_status      1365918 non-null  object \n",
      " 4   fashion_news_frequency  1355971 non-null  object \n",
      " 5   age                     1356119 non-null  float64\n",
      " 6   postal_code             1371980 non-null  object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 73.3+ MB\n"
     ]
    }
   ],
   "source": [
    "customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 499999 entries, 0 to 499998\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   t_dat             499999 non-null  object \n",
      " 1   customer_id       499999 non-null  object \n",
      " 2   article_id        499999 non-null  int64  \n",
      " 3   price             499999 non-null  float64\n",
      " 4   sales_channel_id  499999 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 19.1+ MB\n"
     ]
    }
   ],
   "source": [
    "transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = transactions.merge(customers, how='inner', on='customer_id')\n",
    "# X = X.merge(articles, how='inner', on='article_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Samples \n",
    "If you would rather work with samples instead of the whole dataset (while prototyping your code). You can use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: https://www.kaggle.com/code/paweljankiewicz/hm-create-dataset-samples\n",
    "# This extracts three sampled datasets, containing 0.1%, 1% and 5% of all users and their transactions, and the associated articles.\n",
    "for sample_repr, sample in [(\"01\", 0.001), (\"1\", 0.01), (\"5\", 0.05)]:\n",
    "    customers_sample = customers.sample(int(customers.shape[0]*sample), replace=False)\n",
    "    customers_sample_ids = set(customers_sample[\"customer_id\"])\n",
    "    transactions_sample = transactions[transactions[\"customer_id\"].isin(customers_sample_ids)]\n",
    "    articles_sample_ids = set(transactions_sample[\"article_id\"])\n",
    "    articles_sample = articles[articles[\"article_id\"].isin(articles_sample_ids)]\n",
    "    customers_sample.to_csv(f\"../data/customers_sample{sample_repr}.csv.gz\", index=False)\n",
    "    transactions_sample.to_csv(f\"../data/transactions_sample{sample_repr}.csv.gz\", index=False)\n",
    "    articles_sample.to_csv(f\"../data/articles_sample{sample_repr}.csv.gz\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_sample = pd.read_csv('../data/articles_sample01.csv.gz')\n",
    "customers_sample = pd.read_csv('../data/customers_sample01.csv.gz')\n",
    "transactions_sample = pd.read_csv('../data/transactions_sample01.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1371 entries, 0 to 1370\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   customer_id             1371 non-null   object \n",
      " 1   FN                      514 non-null    float64\n",
      " 2   Active                  504 non-null    float64\n",
      " 3   club_member_status      1366 non-null   object \n",
      " 4   fashion_news_frequency  1360 non-null   object \n",
      " 5   age                     1358 non-null   float64\n",
      " 6   postal_code             1371 non-null   object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 75.1+ KB\n"
     ]
    }
   ],
   "source": [
    "customers_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 513 entries, 0 to 512\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   t_dat             513 non-null    object \n",
      " 1   customer_id       513 non-null    object \n",
      " 2   article_id        513 non-null    int64  \n",
      " 3   price             513 non-null    float64\n",
      " 4   sales_channel_id  513 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 20.2+ KB\n"
     ]
    }
   ],
   "source": [
    "transactions_sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simplified Task: Binary Classification\n",
    "\n",
    "The task of predicting which 12 items users are most likely to buy in the next week is difficult to translate to a traditional classification machine learning setting. \n",
    "To obtain the 12 items a user is most likely to buy, we need to make predictions for all items (or the ones selected by a baseline) and select the 12 that have the highest predicted scores.\n",
    "\n",
    "In this assignment, we'll consider a simplified task: Predict whether a user ordered a single item or not, based on the features of the user and the item. \n",
    "We provide a baseline logistic regression model below, but haven't done much feature preprocessing or engineering!\n",
    "Initially, it is always best to focus your efforts on getting your features in the right shape and setting up the right validation scheme and baselines.\n",
    "Once you are sure that your features add value and your validation scheme is correct, then you typically move on to trying more elaborate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd rather use a sample. Uncomment the following code:\n",
    "# transactions = transactions_sample\n",
    "# customers = customers_sample\n",
    "# articles = articles_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['ordered'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem setting is an example of a \"PU learning\" problem, i.e. only positives are labeled, everything else is unlabeled (and can be either positive or negative). \n",
    "Of course, we cannot train a classifier with just positive samples: The classifier will just learn that everything is positive.\n",
    "Therefore, we need to manually generate negative samples.\n",
    "\n",
    "Below, we use a simple random negative sampling strategy.\n",
    "We want to create a balanced dataset, meaning that we have just as many positives as negatives.\n",
    "This makes sure that the classifier will not benefit from predicting the positive/negative class more often than the other.\n",
    "Realistically, the amount of positive samples is of course many times smaller than the amount of unlabeled, possibly negative instances.\n",
    "\n",
    "\n",
    "If you want to try your hand at a more complex negative sampling strategy, you may want to check out this blog as a starting point: https://medium.com/mlearning-ai/overview-negative-sampling-on-recommendation-systems-230a051c6cd7.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        t_dat                                        customer_id  article_id  \\\n0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   663713001   \n1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   541518023   \n2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   505221004   \n3  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687003   \n4  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687004   \n\n      price  sales_channel_id  ordered  \n0  0.050831                 2        1  \n1  0.030492                 2        1  \n2  0.015237                 2        1  \n3  0.016932                 2        1  \n4  0.016932                 2        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-20</td>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>663713001</td>\n      <td>0.050831</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-20</td>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>541518023</td>\n      <td>0.030492</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>505221004</td>\n      <td>0.015237</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>685687003</td>\n      <td>0.016932</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>685687004</td>\n      <td>0.016932</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's happening here? \n",
    "# We're creating negative samples. I.e. we're creating transactions that didn't actually occur.\n",
    "# First, we need to know which interactions did occur:\n",
    "positive_pairs = list(map(tuple, transactions[['customer_id', 'article_id']].drop_duplicates().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        t_dat                                        customer_id  article_id  \\\n0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   663713001   \n1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   541518023   \n2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   505221004   \n3  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687003   \n4  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687004   \n\n      price  sales_channel_id  ordered  \n0  0.050831                 2        1  \n1  0.030492                 2        1  \n2  0.015237                 2        1  \n3  0.016932                 2        1  \n4  0.016932                 2        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-20</td>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>663713001</td>\n      <td>0.050831</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-20</td>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>541518023</td>\n      <td>0.030492</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>505221004</td>\n      <td>0.015237</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>685687003</td>\n      <td>0.016932</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>685687004</td>\n      <td>0.016932</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we need to know what every synthetic transaction should contain: a date, a customer_id, an article_id, price, sales_channel_id. We will set ordered = 0, as these transactions didn't really occur.\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract real values\n",
    "real_dates = transactions[\"t_dat\"].unique()\n",
    "real_customers = transactions[\"customer_id\"].unique()\n",
    "real_articles = transactions[\"article_id\"].unique()\n",
    "real_channels = transactions[\"sales_channel_id\"].unique()\n",
    "article_and_price = transactions[[\"article_id\",\"price\"]].drop_duplicates(\"article_id\").set_index(\"article_id\").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499999\n"
     ]
    }
   ],
   "source": [
    "# How many negatives do we need to sample?\n",
    "num_neg_pos = transactions.shape[0]\n",
    "print(num_neg_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling negatives by selecting random users, articles, dates and sales channel:\n",
    "# Note: This is quite naive. Some articles may not even have been available at the date we are sampling.\n",
    "random.seed(42)\n",
    "\n",
    "# Afterwards, we need to remove potential duplicates, so we'll sample too many.\n",
    "num_neg_samples = int(num_neg_pos * 1.1)\n",
    "\n",
    "# Sample each of the independent attributes.\n",
    "neg_dates = np.random.choice(real_dates, size=num_neg_samples)\n",
    "neg_articles = np.random.choice(real_articles, size=num_neg_samples)\n",
    "neg_customers = np.random.choice(real_customers, size=num_neg_samples)\n",
    "neg_channels = np.random.choice(real_channels, size=num_neg_samples)\n",
    "ordered = np.array([0] * num_neg_samples)\n",
    "# Assign to every article a real price.\n",
    "neg_prices = article_and_price[neg_articles].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_transactions = pd.DataFrame([neg_dates, neg_customers, neg_articles, neg_prices, neg_channels, ordered], index=transactions.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        t_dat                                        customer_id article_id  \\\n0  2018-09-23  3207a8a93ab3a978cd4ad4ff719b9b644cec95cc18840c...  714418001   \n1  2018-09-28  7bda69f018a1b7be2bacdf712d8aaf7a1bacf052b4b572...  176550020   \n2  2018-09-25  04e6fea09c850352c46cc54afbe0b62db1e497eab630fa...  515158001   \n3  2018-09-24  2427a1e6c33d3c9c47c53182d39ba9dbb68e59f9a146d4...  624661002   \n4  2018-09-24  32db696f74299dd12ebfd257dd76f06d8b2b6be8dede3f...  620855001   \n\n       price sales_channel_id ordered  \n0  0.0338814                2       0  \n1  0.0169322                1       0  \n2  0.0254068                1       0  \n3  0.0135424                2       0  \n4  0.0152373                1       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-23</td>\n      <td>3207a8a93ab3a978cd4ad4ff719b9b644cec95cc18840c...</td>\n      <td>714418001</td>\n      <td>0.0338814</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-28</td>\n      <td>7bda69f018a1b7be2bacdf712d8aaf7a1bacf052b4b572...</td>\n      <td>176550020</td>\n      <td>0.0169322</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-09-25</td>\n      <td>04e6fea09c850352c46cc54afbe0b62db1e497eab630fa...</td>\n      <td>515158001</td>\n      <td>0.0254068</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-09-24</td>\n      <td>2427a1e6c33d3c9c47c53182d39ba9dbb68e59f9a146d4...</td>\n      <td>624661002</td>\n      <td>0.0135424</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-09-24</td>\n      <td>32db696f74299dd12ebfd257dd76f06d8b2b6be8dede3f...</td>\n      <td>620855001</td>\n      <td>0.0152373</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result:\n",
    "neg_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(549998, 6)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove random negative samples that actually coincide with positives\n",
    "df = neg_transactions[\n",
    "    ~neg_transactions.set_index([\"customer_id\", \"article_id\"]).index.isin(positive_pairs)\n",
    "]\n",
    "\n",
    "# Remove any excess\n",
    "chosen_neg_transactions = df.sample(num_neg_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the negative samples to the positive samples:\n",
    "transactions = pd.concat([transactions, chosen_neg_transactions])\n",
    "transactions = transactions.merge(customers, how=\"inner\", on='customer_id')\n",
    "transactions = transactions.merge(articles, how=\"inner\", on='article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 999998 entries, 0 to 999997\n",
      "Data columns (total 36 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   t_dat                         999998 non-null  object \n",
      " 1   customer_id                   999998 non-null  object \n",
      " 2   article_id                    999998 non-null  object \n",
      " 3   price                         999998 non-null  object \n",
      " 4   sales_channel_id              999998 non-null  object \n",
      " 5   ordered                       999998 non-null  object \n",
      " 6   FN                            410991 non-null  float64\n",
      " 7   Active                        401514 non-null  float64\n",
      " 8   club_member_status            988928 non-null  object \n",
      " 9   fashion_news_frequency        995383 non-null  object \n",
      " 10  age                           995291 non-null  float64\n",
      " 11  postal_code                   999998 non-null  object \n",
      " 12  product_code                  999998 non-null  int64  \n",
      " 13  prod_name                     999998 non-null  object \n",
      " 14  product_type_no               999998 non-null  int64  \n",
      " 15  product_type_name             999998 non-null  object \n",
      " 16  product_group_name            999998 non-null  object \n",
      " 17  graphical_appearance_no       999998 non-null  int64  \n",
      " 18  graphical_appearance_name     999998 non-null  object \n",
      " 19  colour_group_code             999998 non-null  int64  \n",
      " 20  colour_group_name             999998 non-null  object \n",
      " 21  perceived_colour_value_id     999998 non-null  int64  \n",
      " 22  perceived_colour_value_name   999998 non-null  object \n",
      " 23  perceived_colour_master_id    999998 non-null  int64  \n",
      " 24  perceived_colour_master_name  999998 non-null  object \n",
      " 25  department_no                 999998 non-null  int64  \n",
      " 26  department_name               999998 non-null  object \n",
      " 27  index_code                    999998 non-null  object \n",
      " 28  index_name                    999998 non-null  object \n",
      " 29  index_group_no                999998 non-null  int64  \n",
      " 30  index_group_name              999998 non-null  object \n",
      " 31  section_no                    999998 non-null  int64  \n",
      " 32  section_name                  999998 non-null  object \n",
      " 33  garment_group_no              999998 non-null  int64  \n",
      " 34  garment_group_name            999998 non-null  object \n",
      " 35  detail_desc                   990471 non-null  object \n",
      "dtypes: float64(3), int64(10), object(23)\n",
      "memory usage: 282.3+ MB\n"
     ]
    }
   ],
   "source": [
    "transactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Preprocessing\n",
    "Some very basic preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                         customer_id   age article_id  \\\n0  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  24.0  663713001   \n1  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  24.0  663713001   \n2  3681748607f3287d2c3a65e00bb5fb153de30e9becf158...  30.0  663713001   \n3  429302530c2e74d1d230e836023b93071ddbf3f5ad1107...  57.0  663713001   \n4  4ef5967ff17bf474bffebe5b16bd54878e1d4105f7b4ed...  37.0  663713001   \n\n  sales_channel_id      price ordered  \n0                2  0.0508305       1  \n1                2  0.0508305       1  \n2                2  0.0494746       1  \n3                2  0.0508305       0  \n4                2  0.0508305       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>sales_channel_id</th>\n      <th>price</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>24.0</td>\n      <td>663713001</td>\n      <td>2</td>\n      <td>0.0508305</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>24.0</td>\n      <td>663713001</td>\n      <td>2</td>\n      <td>0.0508305</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3681748607f3287d2c3a65e00bb5fb153de30e9becf158...</td>\n      <td>30.0</td>\n      <td>663713001</td>\n      <td>2</td>\n      <td>0.0494746</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>429302530c2e74d1d230e836023b93071ddbf3f5ad1107...</td>\n      <td>57.0</td>\n      <td>663713001</td>\n      <td>2</td>\n      <td>0.0508305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4ef5967ff17bf474bffebe5b16bd54878e1d4105f7b4ed...</td>\n      <td>37.0</td>\n      <td>663713001</td>\n      <td>2</td>\n      <td>0.0508305</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm dropping a lot of columns, use them in your engineering tasks!\n",
    "transactions_processed = transactions[['customer_id', 'age', 'article_id', 'sales_channel_id', 'price', 'ordered']].copy()\n",
    "transactions_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does it make sense to label encode?\n",
    "# Label encoding the customer and article IDs:\n",
    "customer_encoder = preprocessing.LabelEncoder()\n",
    "article_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_processed['customer_id'] = customer_encoder.fit_transform(transactions_processed['customer_id'])\n",
    "transactions_processed['article_id'] = article_encoder.fit_transform(transactions_processed['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2'],\n      dtype=object)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to go back to the original encoding:\n",
    "customer_encoder.inverse_transform([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   customer_id   age  article_id sales_channel_id      price ordered\n0            1  24.0       21488                2  0.0508305       1\n1            1  24.0       21488                2  0.0508305       1\n2        28068  30.0       21488                2  0.0494746       1\n3        34303  57.0       21488                2  0.0508305       0\n4        40832  37.0       21488                2  0.0508305       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>sales_channel_id</th>\n      <th>price</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24.0</td>\n      <td>21488</td>\n      <td>2</td>\n      <td>0.0508305</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>24.0</td>\n      <td>21488</td>\n      <td>2</td>\n      <td>0.0508305</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28068</td>\n      <td>30.0</td>\n      <td>21488</td>\n      <td>2</td>\n      <td>0.0494746</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34303</td>\n      <td>57.0</td>\n      <td>21488</td>\n      <td>2</td>\n      <td>0.0508305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40832</td>\n      <td>37.0</td>\n      <td>21488</td>\n      <td>2</td>\n      <td>0.0508305</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can you come up with a NaN strategy that makes sense for each column in the dataset?\n",
    "# Imputing all NaN values with zeros:\n",
    "transactions_processed = transactions_processed.fillna(0)\n",
    "transactions_processed.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does it make sense to one-hot encode?\n",
    "# One-hot-encoding sales_channel_id:\n",
    "transactions_processed = pd.get_dummies(transactions_processed, columns=['sales_channel_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   customer_id   age  article_id     price  ordered  sales_channel_id_1  \\\n0            1  24.0       21488  0.050831        1                   0   \n1            1  24.0       21488  0.050831        1                   0   \n2        28068  30.0       21488  0.049475        1                   0   \n3        34303  57.0       21488  0.050831        0                   0   \n4        40832  37.0       21488  0.050831        1                   0   \n\n   sales_channel_id_2  \n0                   1  \n1                   1  \n2                   1  \n3                   1  \n4                   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>ordered</th>\n      <th>sales_channel_id_1</th>\n      <th>sales_channel_id_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24.0</td>\n      <td>21488</td>\n      <td>0.050831</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>24.0</td>\n      <td>21488</td>\n      <td>0.050831</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28068</td>\n      <td>30.0</td>\n      <td>21488</td>\n      <td>0.049475</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34303</td>\n      <td>57.0</td>\n      <td>21488</td>\n      <td>0.050831</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40832</td>\n      <td>37.0</td>\n      <td>21488</td>\n      <td>0.050831</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Train / Test Split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(transactions_processed.drop('ordered', axis=1), transactions_processed['ordered'], test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        customer_id   age  article_id     price  sales_channel_id_1  \\\n378046        21895  24.0       11175  0.033881                   0   \n510062        87354  31.0       20397  0.010153                   0   \n534815       119250  26.0       11308  0.008458                   0   \n342590        38958  34.0       13653  0.064390                   1   \n559414        89894  26.0        8121  0.011847                   1   \n\n        sales_channel_id_2  \n378046                   1  \n510062                   1  \n534815                   1  \n342590                   0  \n559414                   0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id_1</th>\n      <th>sales_channel_id_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>378046</th>\n      <td>21895</td>\n      <td>24.0</td>\n      <td>11175</td>\n      <td>0.033881</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>510062</th>\n      <td>87354</td>\n      <td>31.0</td>\n      <td>20397</td>\n      <td>0.010153</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>534815</th>\n      <td>119250</td>\n      <td>26.0</td>\n      <td>11308</td>\n      <td>0.008458</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>342590</th>\n      <td>38958</td>\n      <td>34.0</td>\n      <td>13653</td>\n      <td>0.064390</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>559414</th>\n      <td>89894</td>\n      <td>26.0</td>\n      <td>8121</td>\n      <td>0.011847</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "378046    1\n510062    1\n534815    1\n342590    0\n559414    1\nName: ordered, dtype: int64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will take a few minutes to run, if you're using the whole dataset:\n",
    "baseline = LogisticRegression(random_state=42)\n",
    "baseline = baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.5384392 , 0.4615608 ],\n       [0.48492453, 0.51507547],\n       [0.50096165, 0.49903835],\n       ...,\n       [0.47828686, 0.52171314],\n       [0.48197963, 0.51802037],\n       [0.48827761, 0.51172239]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "987229    0\n79954     1\n567130    0\n500891    1\n55399     0\n         ..\n395942    1\n417771    1\n713259    0\n794020    0\n573083    0\nName: ordered, Length: 100000, dtype: int64"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.51373"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Accuracy:\n",
    "baseline.score(X_test, y_test)\n",
    "# As you can seen, the accuracy is ~0.51. In other words, the classifier predicts correctly 51% of the time whether a customer did or din't buy an item.\n",
    "# Can you improve this baseline logistic regression model by doing better preprocessing and generating new features?\n",
    "# Also think about my steps! Did it make sense to include the article and customer ids? (And things like that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.43      0.47     49861\n",
      "           1       0.51      0.60      0.55     50139\n",
      "\n",
      "    accuracy                           0.51    100000\n",
      "   macro avg       0.51      0.51      0.51    100000\n",
      "weighted avg       0.51      0.51      0.51    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Metrics:\n",
    "predictions = baseline.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 0, ..., 1, 1, 1])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Feature engineering\n",
    "**TODO:** \n",
    "- In groups (of 2-3 students), think about (a few) features that can be engineered (preprocess and generate new features). Divide the work!\n",
    "- Do these engineered features improve the baseline model?\n",
    "- Add your thoughts & results to a slide deck for discussion next week (again, 1 slide per person).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "transactions_processed = transactions[['customer_id', 'age', 'article_id', 'price', 'postal_code', 't_dat', 'colour_group_code', 'ordered']].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Impute the nan values in the age column with median value\n",
    "median_age = transactions_processed['age'].median()\n",
    "transactions_processed['age'] = transactions_processed['age'].fillna(median_age)\n",
    "# Imputing the rest of the NaN values with zeros:\n",
    "transactions_processed = transactions_processed.fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              customer_id   age  article_id  \\\n0       000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  24.0   663713001   \n1       000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  24.0   663713001   \n2       3681748607f3287d2c3a65e00bb5fb153de30e9becf158...  30.0   663713001   \n3       429302530c2e74d1d230e836023b93071ddbf3f5ad1107...  57.0   663713001   \n4       4ef5967ff17bf474bffebe5b16bd54878e1d4105f7b4ed...  37.0   663713001   \n...                                                   ...   ...         ...   \n999993  a2db2373943e322f46aa34d177c9e3b7a4ff64a133e52f...  68.0   553518007   \n999994  2c443284739efecc16e07cef758679868ba8d4ac3875de...  67.0   553518007   \n999995  43994d39beb6ec372f599f9df2386ed03a857498f73881...  24.0   553518007   \n999996  2c329773998ed69c0c6c4f1fa092b937c2c9f972389fb3...  26.0   553518007   \n999997  94414cf6ed0850b1e6379cad071ea119f44bf86c0dc571...  44.0   553518007   \n\n           price                                        postal_code  \\\n0       0.050831  64f17e6a330a85798e4998f62d0930d14db8db1c054af6...   \n1       0.050831  64f17e6a330a85798e4998f62d0930d14db8db1c054af6...   \n2       0.049475  aea9af1fd9b5d3aa98820e66a7a093f54def0e4db44153...   \n3       0.050831  0f8ff57c1f243f5c2c7aae7b3f21a767b4cf419e118bff...   \n4       0.050831  7adb1bc2fa962cfb71b31c97223a5b03bb7886e2be56c9...   \n...          ...                                                ...   \n999993  0.015237  c36047c259cdf40bf22fbe34c609533bee323338782261...   \n999994  0.015237  84eefbc081c719cb7f45bbf7a1cb3a40533b146e85c4e0...   \n999995  0.015237  b360f7323fa693951fe2cdb2f7b2c88bbe99923a4545e6...   \n999996  0.015237  6362198700033f9feb256c5d20b988484bd8cbe7409f8a...   \n999997  0.015237  e0ae5112c687171274f87c5bf8778ab033bda1a51c2e96...   \n\n        colour_group_code  ordered  diff  age_bracket  count_age  \\\n0                       9        1     9          2.0        101   \n1                       9        1     5          2.0        101   \n2                       9        1     9          3.0        101   \n3                       9        0     7          5.0        101   \n4                       9        1     9          3.0        101   \n...                   ...      ...   ...          ...        ...   \n999993                 12        0     7          6.0          8   \n999994                 12        0     9          6.0          8   \n999995                 12        0     1          2.0          8   \n999996                 12        0     8          2.0          8   \n999997                 12        0     6          4.0          8   \n\n        count_postal_code  count_colour  \n0                       2           101  \n1                       2           101  \n2                       1           101  \n3                       1           101  \n4                       1           101  \n...                   ...           ...  \n999993                  1             8  \n999994                  1             8  \n999995                  1             8  \n999996                  1             8  \n999997                  1             8  \n\n[999998 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>postal_code</th>\n      <th>colour_group_code</th>\n      <th>ordered</th>\n      <th>diff</th>\n      <th>age_bracket</th>\n      <th>count_age</th>\n      <th>count_postal_code</th>\n      <th>count_colour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>24.0</td>\n      <td>663713001</td>\n      <td>0.050831</td>\n      <td>64f17e6a330a85798e4998f62d0930d14db8db1c054af6...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>9</td>\n      <td>2.0</td>\n      <td>101</td>\n      <td>2</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>24.0</td>\n      <td>663713001</td>\n      <td>0.050831</td>\n      <td>64f17e6a330a85798e4998f62d0930d14db8db1c054af6...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2.0</td>\n      <td>101</td>\n      <td>2</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3681748607f3287d2c3a65e00bb5fb153de30e9becf158...</td>\n      <td>30.0</td>\n      <td>663713001</td>\n      <td>0.049475</td>\n      <td>aea9af1fd9b5d3aa98820e66a7a093f54def0e4db44153...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>9</td>\n      <td>3.0</td>\n      <td>101</td>\n      <td>1</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>429302530c2e74d1d230e836023b93071ddbf3f5ad1107...</td>\n      <td>57.0</td>\n      <td>663713001</td>\n      <td>0.050831</td>\n      <td>0f8ff57c1f243f5c2c7aae7b3f21a767b4cf419e118bff...</td>\n      <td>9</td>\n      <td>0</td>\n      <td>7</td>\n      <td>5.0</td>\n      <td>101</td>\n      <td>1</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4ef5967ff17bf474bffebe5b16bd54878e1d4105f7b4ed...</td>\n      <td>37.0</td>\n      <td>663713001</td>\n      <td>0.050831</td>\n      <td>7adb1bc2fa962cfb71b31c97223a5b03bb7886e2be56c9...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>9</td>\n      <td>3.0</td>\n      <td>101</td>\n      <td>1</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999993</th>\n      <td>a2db2373943e322f46aa34d177c9e3b7a4ff64a133e52f...</td>\n      <td>68.0</td>\n      <td>553518007</td>\n      <td>0.015237</td>\n      <td>c36047c259cdf40bf22fbe34c609533bee323338782261...</td>\n      <td>12</td>\n      <td>0</td>\n      <td>7</td>\n      <td>6.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>999994</th>\n      <td>2c443284739efecc16e07cef758679868ba8d4ac3875de...</td>\n      <td>67.0</td>\n      <td>553518007</td>\n      <td>0.015237</td>\n      <td>84eefbc081c719cb7f45bbf7a1cb3a40533b146e85c4e0...</td>\n      <td>12</td>\n      <td>0</td>\n      <td>9</td>\n      <td>6.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>999995</th>\n      <td>43994d39beb6ec372f599f9df2386ed03a857498f73881...</td>\n      <td>24.0</td>\n      <td>553518007</td>\n      <td>0.015237</td>\n      <td>b360f7323fa693951fe2cdb2f7b2c88bbe99923a4545e6...</td>\n      <td>12</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>999996</th>\n      <td>2c329773998ed69c0c6c4f1fa092b937c2c9f972389fb3...</td>\n      <td>26.0</td>\n      <td>553518007</td>\n      <td>0.015237</td>\n      <td>6362198700033f9feb256c5d20b988484bd8cbe7409f8a...</td>\n      <td>12</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>999997</th>\n      <td>94414cf6ed0850b1e6379cad071ea119f44bf86c0dc571...</td>\n      <td>44.0</td>\n      <td>553518007</td>\n      <td>0.015237</td>\n      <td>e0ae5112c687171274f87c5bf8778ab033bda1a51c2e96...</td>\n      <td>12</td>\n      <td>0</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>999998 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FEATURE: calculate diff with latest bought\n",
    "transactions_processed['t_dat'] = pd.to_datetime(transactions_processed['t_dat'], format='%Y-%m-%d')\n",
    "transactions_processed['last_bought'] = transactions_processed['t_dat'].max()\n",
    "transactions_processed['diff'] = (transactions_processed['last_bought'] - transactions_processed['t_dat']).dt.days\n",
    "transactions_processed = transactions_processed.drop(['last_bought', 't_dat'], axis=1)\n",
    "# FEATURE: count popularity per age bracket\n",
    "transactions_processed['age_bracket'] = transactions_processed['age'] // 10\n",
    "article_counts = transactions_processed[['article_id', 'colour_group_code']].value_counts()\n",
    "article_counts.name = 'count_age'\n",
    "transactions_processed = transactions_processed.merge(article_counts, on=['article_id', 'colour_group_code'])\n",
    "# FEATURE: count transactions per postal code group\n",
    "article_counts = transactions_processed[['article_id', 'postal_code']].value_counts()\n",
    "article_counts.name = 'count_postal_code'\n",
    "transactions_processed = transactions_processed.merge(article_counts, on=['article_id', 'postal_code'])\n",
    "# FEATURE: count transactions per colour group\n",
    "article_counts = transactions_processed[['article_id', 'colour_group_code']].value_counts()\n",
    "article_counts.name = 'count_colour'\n",
    "transactions_processed = transactions_processed.merge(article_counts, on=['article_id', 'colour_group_code'])\n",
    "transactions_processed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Does it make sense to label encode?\n",
    "# Label encoding the customer and article IDs:\n",
    "customer_encoder = preprocessing.LabelEncoder()\n",
    "article_encoder = preprocessing.LabelEncoder()\n",
    "postal_encoder = preprocessing.LabelEncoder()\n",
    "transactions_processed['customer_id'] = customer_encoder.fit_transform(transactions_processed['customer_id'])\n",
    "transactions_processed['article_id'] = article_encoder.fit_transform(transactions_processed['article_id'])\n",
    "transactions_processed['postal_code'] = postal_encoder.fit_transform(transactions_processed['postal_code'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "           price\n0       0.084882\n1       0.084882\n2       0.082587\n3       0.084882\n4       0.084882\n...          ...\n999993  0.024641\n999994  0.024641\n999995  0.024641\n999996  0.024641\n999997  0.024641\n\n[999998 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.084882</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.084882</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.082587</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.084882</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.084882</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999993</th>\n      <td>0.024641</td>\n    </tr>\n    <tr>\n      <th>999994</th>\n      <td>0.024641</td>\n    </tr>\n    <tr>\n      <th>999995</th>\n      <td>0.024641</td>\n    </tr>\n    <tr>\n      <th>999996</th>\n      <td>0.024641</td>\n    </tr>\n    <tr>\n      <th>999997</th>\n      <td>0.024641</td>\n    </tr>\n  </tbody>\n</table>\n<p>999998 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_processed = transactions_processed.replace([np.inf, -np.inf], 0)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "transactions_processed[['price']] = scaler.fit_transform(transactions_processed[['price']])\n",
    "transactions_processed[['price']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0         0.056211\n1         0.056211\n2         0.056211\n3         0.056211\n4         0.056211\n            ...   \n999993    0.056196\n999994    0.170941\n999995    0.005709\n999996    0.017183\n999997    0.099225\nName: price_y, Length: 999998, dtype: float64"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_processed = transactions_processed.merge(transactions_processed.groupby('postal_code')[['price']].median(), how='inner', on='postal_code')\n",
    "transactions_processed['price_y']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cleaning up the nan values and custom processing the price column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/basil/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78     49960\n",
      "           1       0.84      0.63      0.72     50040\n",
      "\n",
      "    accuracy                           0.76    100000\n",
      "   macro avg       0.77      0.76      0.75    100000\n",
      "weighted avg       0.77      0.76      0.75    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(transactions_processed.drop('ordered', axis=1), transactions_processed['ordered'], test_size=0.10, random_state=42)\n",
    "# Will take a few minutes to run, if you're using the whole dataset:\n",
    "baseline = LogisticRegression(random_state=42)\n",
    "baseline = baseline.fit(X_train, y_train)\n",
    "print(baseline.score(X_test, y_test))\n",
    "# Classification Metrics:\n",
    "predictions = baseline.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
