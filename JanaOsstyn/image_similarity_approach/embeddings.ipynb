{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Embeddings\n",
    "Create embeddings for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import threading, math, os, json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functions import idp, odp, move_files, create_directory_if_not_exists, remove_directory_if_exists, list_directory_if_exists\n",
    "\n",
    "from keras.applications import ResNet50, ResNet50V2, ResNet101, ResNet101V2, ResNet152, ResNet152V2, InceptionV3, InceptionResNetV2, VGG16, VGG19, Xception\n",
    "from keras.applications.resnet import preprocess_input as resnet_preprocess_input\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input as inception_resnet_v2_preprocess_input\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_preprocess_input\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "from keras.applications.xception import preprocess_input as xception_preprocess_input\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.utils import load_img as keras_load_img\n",
    "from keras.utils import img_to_array\n",
    "from keras import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "MODEL = 'ResNet50'                                                      # model name of the pre-trained model to use\n",
    "IMG_WIDTH, IMG_HEIGHT, CHANNELS = 224, 224, 3                           # model input dimensions\n",
    "NR_ROWS_PER_THREAD = 6000                                               # nr of articles to process in each thread\n",
    "ONE_HOT_ENCODE_COLUMNS = ['index_group_no', 'garment_group_no']         # columns to one-hot-encode in the extended embeddings\n",
    "OTHER_COLUMNS = ['popularity']                                          # columns to add as they are in the extended embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def embeddings_odp(filename, creation=False):\n",
    "    \"\"\"\n",
    "    Get the filename including the path to store/open a file containing embeddings.\n",
    "    :param filename: the filename of the file\n",
    "    :param creation: if True, the directory is 'embeddings_creation' instead of 'embeddings'\n",
    "    :return: the filename with path\n",
    "    \"\"\"\n",
    "    directory = 'embeddings_creation' if creation else 'embeddings'\n",
    "    create_directory_if_not_exists(directory=odp(filename=directory))\n",
    "    return odp(filename=f'{directory}/{filename}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 13:41:13.150741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 13:41:13.313508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jana/anaconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-29 13:41:13.313521: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-29 13:41:13.314041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 2048)             0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/api/applications/\n",
    "if MODEL == 'ResNet50':\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = resnet_preprocess_input\n",
    "elif MODEL == 'ResNet50V2':\n",
    "    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = resnet_preprocess_input\n",
    "elif MODEL == 'ResNet101':\n",
    "    base_model = ResNet101(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = resnet_preprocess_input\n",
    "elif MODEL == 'ResNet101V2':\n",
    "    base_model = ResNet101V2(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = resnet_preprocess_input\n",
    "elif MODEL == 'ResNet152':\n",
    "    base_model = ResNet152(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = resnet_preprocess_input\n",
    "elif MODEL == 'ResNet152V2':\n",
    "    base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = resnet_preprocess_input\n",
    "elif MODEL == 'InceptionV3':\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = inception_preprocess_input\n",
    "elif MODEL == 'InceptionResNetV2':\n",
    "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = inception_resnet_v2_preprocess_input\n",
    "elif MODEL == 'VGG16':\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = vgg16_preprocess_input\n",
    "elif MODEL == 'VGG19':\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = vgg19_preprocess_input\n",
    "elif MODEL == 'Xception':\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "    preprocess_input = xception_preprocess_input\n",
    "else:\n",
    "    raise Exception('Model not recognized')\n",
    "\n",
    "base_model.trainable = False\n",
    "model = Sequential([base_model, GlobalMaxPooling2D()])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "2048"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_shape = model.get_layer(model.layers[1].name).output_shape[1]\n",
    "embedding_shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedding pipeline\n",
    "### Calculating the embeddings using multithreading\n",
    "Each thread outputs a file with the embeddings for the rows it processed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "article_df = pd.read_feather(idp(filename='articles_processed.feather'))\n",
    "nr_articles = article_df.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_embedding_for_image(img_name):\n",
    "    \"\"\"\n",
    "    Smallest piece in the embedding-creation process.\n",
    "    This function calculates the embedding of a single image.\n",
    "    :param img_name: the name of the image for which to get the embedding\n",
    "    :return: the embedding (or a numpy array of zeros if the image couldn't be found or an exception occurred, with shape embedding_shape)\n",
    "    \"\"\"\n",
    "    if img_name == 'does not exist':\n",
    "        return np.zeros(embedding_shape)\n",
    "\n",
    "    try:\n",
    "        img = keras_load_img(idp(f'images/{img_name}'), target_size=(IMG_WIDTH, IMG_HEIGHT))     # load and reshape image\n",
    "        img_array = img_to_array(img)                                           # convert image to array\n",
    "        img_array = np.expand_dims(img_array, axis=0)                           # expand dimensions (1, w, h)\n",
    "        img_array = preprocess_input(img_array)                                 # preprocess input\n",
    "        del img\n",
    "        return model.predict(img_array, verbose=0).reshape(-1)\n",
    "    except Exception:\n",
    "        return np.zeros(embedding_shape)\n",
    "\n",
    "def embedding_creation_thread_function(min_row_ind, max_row_ind, thread_nr):\n",
    "    \"\"\"\n",
    "    Extract the rows of the dataframe from index min_ind to index max_ind.\n",
    "    Then, create embeddings for all images in these rows.\n",
    "    The embeddings for all selected rows are written to a file numbered by thread_nr.\n",
    "    :param min_row_ind: smallest row index in the range to retrieve\n",
    "    :param max_row_ind: largest row index in the range to retrieve\n",
    "    :param thread_nr: nr of the thread (printing purposes only)\n",
    "    \"\"\"\n",
    "    print(f\"[=>    ] Started              : Thread {thread_nr} ({min_row_ind} --> {max_row_ind})\")\n",
    "    part_of_df = article_df.iloc[min_row_ind:max_row_ind]\n",
    "    map_embeddings_df = part_of_df['image_name'].apply(lambda img_name: get_embedding_for_image(img_name=img_name))\n",
    "    print(f\"[===>  ] Creating embeddings  : Thread {thread_nr} ({min_row_ind} --> {max_row_ind})\")\n",
    "    embeddings_df = map_embeddings_df.apply(pd.Series)\n",
    "    embeddings_df = embeddings_df.reset_index()\n",
    "    embeddings_df.columns = embeddings_df.columns.astype(str)\n",
    "    embeddings_df.to_feather(embeddings_odp(filename=f'embeddings_{thread_nr}.feather', creation=True))\n",
    "    print(f\"[=====>] Finished             : Thread {thread_nr} ({min_row_ind} --> {max_row_ind})\")\n",
    "    return\n",
    "\n",
    "def run_threaded_embedding_creation():\n",
    "    \"\"\"\n",
    "    Create the embeddings for all images in the dataset.\n",
    "    The embeddings are created image per image, which makes the RAM consumption is fairly low. Therefore, to speed up things, multithreading is used.\n",
    "    Each thread calculates the embeddings for embedding_step rows in the dataframe, and writes those embeddings to a file numbered by this thread\n",
    "    \"\"\"\n",
    "\n",
    "    min_row_ind, max_row_ind = 0, NR_ROWS_PER_THREAD    # lower and upperbound of rows to extract within a thread\n",
    "    thread_nr = 1                                       # only for progress printing\n",
    "    threads = list()\n",
    "\n",
    "    # create threads\n",
    "    while article_df.shape[0] > min_row_ind:\n",
    "        print(f\"Main    : created and started thread {thread_nr}\")\n",
    "        # create and start thread\n",
    "        thread = threading.Thread(target=embedding_creation_thread_function, args=(min_row_ind, max_row_ind, thread_nr,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        # update parameters\n",
    "        min_row_ind, max_row_ind = max_row_ind, min(nr_articles, max_row_ind + NR_ROWS_PER_THREAD)\n",
    "        thread_nr += 1\n",
    "\n",
    "    # join threads\n",
    "    for thread_index, thread in enumerate(threads):\n",
    "        print(f\"Main    : next thread to join: {thread_index + 1}\")\n",
    "        thread.join()\n",
    "        print(f\"Main    : thread {thread_index + 1} done\")\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main    : created and started thread %d 1\n",
      "[=>    ] Started              : Thread 1 (0 --> 6000)\n",
      "Main    : created and started thread %d 2\n",
      "[=>    ] Started              : Thread 2 (6000 --> 12000)\n",
      "Main    : created and started thread %d 3\n",
      "[=>    ] Started              : Thread 3 (12000 --> 18000)\n",
      "Main    : created and started thread %d 4\n",
      "[=>    ] Started              : Thread 4 (18000 --> 24000)\n",
      "Main    : created and started thread %d 5\n",
      "[=>    ] Started              : Thread 5 (24000 --> 30000)\n",
      "Main    : created and started thread %d 6\n",
      "[=>    ] Started              : Thread 6 (30000 --> 36000)\n",
      "Main    : created and started thread %d 7\n",
      "[=>    ] Started              : Thread 7 (36000 --> 42000)\n",
      "Main    : created and started thread %d 8\n",
      "[=>    ] Started              : Thread 8 (42000 --> 48000)\n",
      "Main    : created and started thread %d 9\n",
      "[=>    ] Started              : Thread 9 (48000 --> 54000)\n",
      "Main    : created and started thread %d 10\n",
      "[=>    ] Started              : Thread 10 (54000 --> 60000)\n",
      "Main    : created and started thread %d 11\n",
      "[=>    ] Started              : Thread 11 (60000 --> 66000)\n",
      "Main    : created and started thread %d 12\n",
      "[=>    ] Started              : Thread 12 (66000 --> 72000)\n",
      "Main    : created and started thread %d 13\n",
      "[=>    ] Started              : Thread 13 (72000 --> 78000)\n",
      "Main    : created and started thread %d 14\n",
      "[=>    ] Started              : Thread 14 (78000 --> 84000)\n",
      "Main    : created and started thread %d 15\n",
      "[=>    ] Started              : Thread 15 (84000 --> 90000)\n",
      "Main    : created and started thread %d 16\n",
      "[=>    ] Started              : Thread 16 (90000 --> 96000)\n",
      "Main    : created and started thread %d 17\n",
      "[=>    ] Started              : Thread 17 (96000 --> 102000)\n",
      "Main    : created and started thread %d 18\n",
      "[=>    ] Started              : Thread 18 (102000 --> 105542)\n",
      "Main    : next thread to join: %d. 1\n",
      "[===>  ] Creating embeddings  : Thread 18 (102000 --> 105542)\n",
      "[=====>] Finished             : Thread 18 (102000 --> 105542)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "run_threaded_embedding_creation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Join embedding files\n",
    "The separate dataframes are joined to obtain a single dataframe with all embeddings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def join_embedding_files():\n",
    "    \"\"\"\n",
    "    Join all embedding files created in the different threads into a single file.\n",
    "    Some columns need to be removed.\n",
    "    :return: the dataframe containing all embeddings\n",
    "    \"\"\"\n",
    "    embeddings_list = [pd.read_feather(embeddings_odp(filename=f'embeddings_{i + 1}.feather', creation=True)) for i in range(math.ceil(nr_articles / NR_ROWS_PER_THREAD))]\n",
    "    all_embeddings = pd.concat(embeddings_list, ignore_index=True)\n",
    "    if 'Unnamed: 0' in all_embeddings.columns.values:\n",
    "        all_embeddings = all_embeddings.drop(['Unnamed: 0'], axis=1)\n",
    "    if 'index' in all_embeddings.columns.values:\n",
    "        all_embeddings = all_embeddings.drop(['index'], axis=1)\n",
    "    if not os.path.isdir(odp(filename='embeddings')):\n",
    "        os.mkdir(odp(filename='embeddings'))\n",
    "    all_embeddings.to_feather(embeddings_odp(filename='embeddings.feather'))\n",
    "    remove_directory_if_exists(directory=odp(filename='embeddings_creation'))\n",
    "    return all_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "embeddings = join_embedding_files()\n",
    "embeddings.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create extended embeddings\n",
    "Enlarge the embeddings by adding article properties.\n",
    "- `ONE_HOT_ENCODE_COLUMNS` = list of columns that should be added to the embeddings by one-hot-encoding them\n",
    "- `OTHER_COLUMNS` = list of columns that should be added straight away"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "extended_embeddings = embeddings.copy()\n",
    "for column in ONE_HOT_ENCODE_COLUMNS + OTHER_COLUMNS:\n",
    "    extended_embeddings[column] = article_df[column]\n",
    "extended_embeddings = pd.get_dummies(extended_embeddings, columns=ONE_HOT_ENCODE_COLUMNS)\n",
    "extended_embeddings.to_feather(embeddings_odp(filename='extended_embeddings.feather'))\n",
    "extended_embeddings.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Store files\n",
    "Create a directory characterizing the constants defined earlier, such that we later still know how these embeddings were obtained."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dir_name = f'embeddings_{MODEL}_W{IMG_WIDTH}_H{IMG_HEIGHT}'\n",
    "create_directory_if_not_exists(directory=embeddings_odp(filename=dir_name))\n",
    "\n",
    "json.dump({'ONE_HOT_ENCODE_COLUMNS': ONE_HOT_ENCODE_COLUMNS, 'OTHER_COLUMNS': OTHER_COLUMNS}, open(f'{embeddings_odp(dir_name)}/columns.json', 'w'))\n",
    "filenames = list_directory_if_exists(directory=odp('embeddings'))\n",
    "move_files(filenames=filenames, dir_from=embeddings_odp(filename='')[:-1], dir_to=embeddings_odp(filename=dir_name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reset -f"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}