{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adaeed1",
   "metadata": {},
   "source": [
    "# Comparing classifier implementations\n",
    "Objectives:\n",
    "- Compare multiple classifiers and see which one gets the best leaderboard score when all else is equal\n",
    "- Refactor code from the previous experiment (Unsold items test) to be more usable going forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d75830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8d3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('./data/transactions_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba497b",
   "metadata": {},
   "source": [
    "Replace customer ids with label encoding for space preservation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836ef65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_transactions_customers(transactions_df):\n",
    "    customers = pd.read_csv('./data/customers.csv')\n",
    "    customer_encoder = preprocessing.LabelEncoder()\n",
    "    customer_encoder.fit(customers['customer_id'])\n",
    "    transactions['customer_id'] = customer_encoder.transform(transactions['customer_id'])\n",
    "    np.save('customer_ids.npy', customer_encoder.classes_) \n",
    "    return customer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535b1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_encoder = encode_transactions_customers(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c51ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['purchased'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aecf7b",
   "metadata": {},
   "source": [
    "Transform string dates into weeks with the start of week 0 being the week for the final calculation (meaning everything in the data becomes a negative week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5515a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_string_dates_to_int(transactions_df):\n",
    "    import datetime\n",
    "\n",
    "    lookup = dict()\n",
    "    def str_dat_to_weeks_int(datestring):\n",
    "        return lookup.setdefault(datestring, (datetime.datetime.strptime(datestring, \"%Y-%m-%d\") - datetime.datetime(2020, 9, 23)).days//7)\n",
    "    \n",
    "    transactions_df[\"t_dat\"] = transactions_df[\"t_dat\"].map(str_dat_to_weeks_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd2c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_string_dates_to_int(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e79330",
   "metadata": {},
   "source": [
    "Drop all transactions which happened more than 20 weeks before the end of the data collection period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e1ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.drop(transactions[transactions[\"t_dat\"] < -20].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c989b0",
   "metadata": {},
   "source": [
    "Perform random negative sampling, most of this code is copied from the 2nd lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c8a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_samples_np_version(transactions_df, num_neg_pos):\n",
    "    real_dates = transactions[\"t_dat\"].unique()\n",
    "    real_customers = transactions[\"customer_id\"].unique()\n",
    "    real_articles = transactions[\"article_id\"].unique()\n",
    "    real_channels = transactions[\"sales_channel_id\"].unique()\n",
    "    article_and_price = transactions[[\"article_id\",\"price\"]].drop_duplicates(\"article_id\").set_index(\"article_id\").squeeze()\n",
    "\n",
    "    random.seed(42)\n",
    "    num_neg_samples = int(num_neg_pos * 1.1)\n",
    "\n",
    "    neg_dates = np.random.choice(real_dates, size=num_neg_samples)\n",
    "    neg_articles = np.random.choice(real_articles, size=num_neg_samples)\n",
    "    neg_customers = np.random.choice(real_customers, size=num_neg_samples)\n",
    "    neg_channels = np.random.choice(real_channels, size=num_neg_samples)\n",
    "    ordered = np.array([0] * num_neg_samples)\n",
    "\n",
    "    neg_prices = article_and_price[neg_articles].values\n",
    "    \n",
    "    return np.column_stack((neg_dates, neg_customers, neg_articles, neg_prices, neg_channels, ordered))\n",
    "    \n",
    "def generate_negative_samples(transactions_df):\n",
    "    num_neg_pos = transactions_df.shape[0]\n",
    "    positive_pairs = list(map(tuple, transactions_df[['customer_id', 'article_id']].drop_duplicates().values))\n",
    "    neg_transactions = pd.DataFrame(generate_negative_samples_np_version(transactions_df, num_neg_pos), columns=transactions_df.columns)\n",
    "    duplicate_indexes = neg_transactions[[\"customer_id\", \"article_id\"]].apply(tuple, 1).isin(positive_pairs)\n",
    "    neg_transactions = neg_transactions[~duplicate_indexes]\n",
    "    return neg_transactions.sample(num_neg_pos)\n",
    "\n",
    "def negative_sampling(transactions_df):\n",
    "    transactions_df = pd.concat([transactions_df, generate_negative_samples(transactions_df)])\n",
    "    transactions_df.reset_index(drop=True, inplace=True)\n",
    "    return transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80eec622",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = negative_sampling(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8364c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.to_feather('./data/negativesampled.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633388d",
   "metadata": {},
   "source": [
    "This is intended as a checkpoint for if I need to reset the jupyter notebook kernel be it due to crashing or due to running out of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86d97c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('./data/articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f42da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_feather(\"./data/negativesampled.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df586f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv('./data/customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16d3b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_encoder = preprocessing.LabelEncoder()\n",
    "customer_encoder.classes_ = np.load(\"customer_ids.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c499d39",
   "metadata": {},
   "source": [
    "Apply the label encoding to the customer table so it can be joined with transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df8501e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['customer_id'] = customer_encoder.transform(customers['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4096f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_encoder = preprocessing.LabelEncoder()\n",
    "customers[\"postal_code\"] = zip_encoder.fit_transform(customers[\"postal_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40f0e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_types_and_merge_transactions(transactions_df, customers_df, articles_df):\n",
    "    customers_df[\"age\"] = customers_df[\"age\"].fillna(25)\n",
    "    customers_df[\"age\"] = customers_df[\"age\"].astype(int)\n",
    "    articles_df[['article_id', 'product_code', 'product_type_no','graphical_appearance_no','colour_group_code',\n",
    "       'perceived_colour_value_id', 'perceived_colour_master_id', 'department_no',\n",
    "       'index_group_no', 'section_no', 'garment_group_no']] = articles_df[['article_id', 'product_code',\n",
    "       'product_type_no','graphical_appearance_no','colour_group_code',\n",
    "       'perceived_colour_value_id', 'perceived_colour_master_id', 'department_no',\n",
    "       'index_group_no', 'section_no', 'garment_group_no']].astype(int)\n",
    "    transactions_df[['t_dat', 'customer_id', 'article_id', 'sales_channel_id', 'purchased']] = transactions_df[['t_dat', 'customer_id', 'article_id', 'sales_channel_id', 'purchased']].astype(int)\n",
    "\n",
    "    transactions_df = transactions_df.merge(customers_df[[\"customer_id\", \"age\", \"postal_code\"]], how=\"inner\", on='customer_id')\n",
    "    transactions_df = transactions_df.merge(articles_df[[\"article_id\", \"product_code\", \"product_type_no\", \"graphical_appearance_no\", \"colour_group_code\", \"department_no\", \"index_group_no\", \"section_no\", \"garment_group_no\"]], how=\"inner\", on='article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7422747",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_types_and_merge_transactions(transactions, customers, articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32984d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(transactions.drop(['purchased', \"price\", 'sales_channel_id'], axis=1), transactions['purchased'], test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9268f0",
   "metadata": {},
   "source": [
    "Calculate the popular items which I will be using as candidates for the submission. 24 popular items in the past 20 weeks and 24 popular items in the past 4 weeks. If there is overlap, continue down the rank of the past 4 weeks. In extreme cases this results in 48 items that were popular in the past 4 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb9997ea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     706016001\n",
       "1     372860002\n",
       "2     751471001\n",
       "3     599580038\n",
       "4     610776002\n",
       "5     759871002\n",
       "6     372860001\n",
       "7     610776001\n",
       "8     841383002\n",
       "9     599580052\n",
       "10    448509014\n",
       "11    783346001\n",
       "12    806225002\n",
       "13    749699002\n",
       "14    800691007\n",
       "15    817472002\n",
       "16    739590032\n",
       "17    806388002\n",
       "18    850917001\n",
       "19    688537004\n",
       "20    811925009\n",
       "21    827968001\n",
       "22    759871025\n",
       "23    760084003\n",
       "Name: article_id, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_popular_items(transaction_df):\n",
    "    popular_all_time = transaction_df[transaction_df[\"purchased\"] == 1][[\"article_id\", \"purchased\"]].groupby(\"article_id\").count().sort_values(ascending=False, by=\"purchased\").head(24).index.to_series().reset_index(drop=True)\n",
    "    popular_by_month = transaction_df[(transaction_df[\"purchased\"] == 1) & (transaction_df[\"t_dat\"] >= -4)][[\"article_id\", \"purchased\"]].groupby(\"article_id\").count().sort_values(ascending=False, by=\"purchased\").head(48).index.to_series().reset_index(drop=True)\n",
    "    popular_by_month2 = popular_by_month[~popular_by_month.isin(popular_all_time)]\n",
    "    popular_by_month2 = popular_by_month2.reset_index(drop=True).head(24)\n",
    "    popular_candidates = pd.DataFrame(pd.concat([popular_all_time, popular_by_month2])).astype(int).reset_index(drop=True)\n",
    "    return popular_candidates, popular_by_month\n",
    "\n",
    "popular_candidates, popular_by_month = get_popular_items(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e85eb5d",
   "metadata": {},
   "source": [
    "Generate dataframe with all active customers and the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46e9286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ranker_input_df(transactions_df, candidates, customers_df, articles_df):\n",
    "    return pd.DataFrame(data={\"t_dat\": 0}, index=[0]).merge(transactions_df[[\"customer_id\"]].drop_duplicates(subset=\"customer_id\"), how=\"cross\").merge(candidates, how=\"cross\").merge(customers_df[[\"customer_id\", \"age\", \"postal_code\"]], how=\"inner\", on=\"customer_id\").merge(articles_df[[\"article_id\", \"product_code\", \"product_type_no\", \"graphical_appearance_no\", \"colour_group_code\", \"department_no\", \"index_group_no\", \"section_no\", \"garment_group_no\"]], how=\"inner\", on=\"article_id\")\n",
    "\n",
    "ranker_input = generate_ranker_input_df(transactions, popular_candidates, customers, articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e5a526",
   "metadata": {},
   "source": [
    "Functions to perform predictions and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6e44175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from the radekosmulski notebook\n",
    "def generate_ranking(df):\n",
    "    return df.sort_values(by=[\"customer_id\", \"p1\"], ascending=[True, False]).groupby(\"customer_id\")[\"article_id\"].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "147249d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_preds(df, classifier, filename, filler_candidates):\n",
    "    predictions = classifier.predict_proba(df)\n",
    "    df[[\"p0\", \"p1\"]] = predictions\n",
    "    ranking = generate_ranking(df)\n",
    "    \n",
    "    # Copied from the radekosmulski notebook\n",
    "    submission_df = pd.read_csv('data/sample_submission.csv')\n",
    "    preds = []\n",
    "    for c_id in customer_encoder.transform(submission_df.customer_id):\n",
    "        pred = ranking.get(c_id, filler_candidates)\n",
    "        preds.append(pred[:12])\n",
    "        \n",
    "    preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "    submission_df.prediction = preds\n",
    "    \n",
    "    submission_df.to_csv('./data/{}.csv'.format(filename), index=False)\n",
    "    df.drop(['p0', 'p1'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222bc88a",
   "metadata": {},
   "source": [
    "LightGBMClassifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd342ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's auc: 0.813333\tvalid_0's binary_logloss: 0.541055\tvalid_0's l1: 0.387631\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "# copying from https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py\n",
    "# combined with https://github.com/angelotc/LightGBM-binary-classification-example/blob/master/CCData.ipynb\n",
    "\n",
    "import lightgbm as lgb\n",
    "print('Starting training...')\n",
    "\n",
    "gbm = lgb.LGBMClassifier(learning_rate = 0.1, metric = 'l1', \n",
    "                        n_estimators = 20)\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=['auc', 'binary_logloss'],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c93263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(ranker_input, gbm, \"model_lgbm_binary\", popular_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec94fe4",
   "metadata": {},
   "source": [
    "LightGBMRanker implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbb745e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.778104\tvalid_0's binary_logloss: 5.37591\tvalid_0's l1: 0.522243\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "# copying from https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py\n",
    "# combined with https://github.com/angelotc/LightGBM-binary-classification-example/blob/master/CCData.ipynb\n",
    "# and this one https://github.com/radekosmulski/personalized_fashion_recs/blob/main/03c_Basic_Model_Submission.ipynb\n",
    "\n",
    "\n",
    "\n",
    "train_baskets = X_train.groupby(['t_dat', 'customer_id'])['article_id'].count().values\n",
    "train_baskets_test = X_test.groupby(['t_dat', 'customer_id'])['article_id'].count().values\n",
    "\n",
    "print('Starting training...')\n",
    "\n",
    "gbm = lgb.LGBMRanker(learning_rate = 0.1, metric = 'l1', \n",
    "                        n_estimators = 20)\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        group=train_baskets,\n",
    "        eval_group=[train_baskets_test],\n",
    "        eval_metric=['auc', 'binary_logloss'],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "026d9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(ranker_input, gbm, \"model_lgbm_ranker\", popular_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ef844",
   "metadata": {},
   "source": [
    "Logistic regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3e44fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LG = LogisticRegression(random_state=42)\n",
    "LG = LG.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9fd96a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(ranker_input, LG, \"model_logistic_regression\", popular_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a762521",
   "metadata": {},
   "source": [
    "Naive Bayes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "12c97b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "GNB = GaussianNB()\n",
    "GNB = GNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "37f1c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(ranker_input, GNB, \"model_naive_bayes\", popular_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa342d2",
   "metadata": {},
   "source": [
    "Random Forest implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27178c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators=20, max_depth=10, random_state=42)\n",
    "RFC = RFC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d5f9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(ranker_input, RFC, \"model_random_forest\", popular_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4dbb2d",
   "metadata": {},
   "source": [
    "Gradient boosting implementation via scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b900e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC = GradientBoostingClassifier(n_estimators=20, random_state=42, n_iter_no_change=5)\n",
    "GBC = GBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "832fe133",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(ranker_input, GBC, \"model_sklearn_gradient\", popular_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f8fa1",
   "metadata": {},
   "source": [
    "XGBoost implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7f6e279",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.74081\tvalidation_0-logloss:0.63255\n",
      "[1]\tvalidation_0-aucpr:0.75226\tvalidation_0-logloss:0.60041\n",
      "[2]\tvalidation_0-aucpr:0.75789\tvalidation_0-logloss:0.57958\n",
      "[3]\tvalidation_0-aucpr:0.76363\tvalidation_0-logloss:0.56570\n",
      "[4]\tvalidation_0-aucpr:0.77414\tvalidation_0-logloss:0.55265\n",
      "[5]\tvalidation_0-aucpr:0.78220\tvalidation_0-logloss:0.54431\n",
      "[6]\tvalidation_0-aucpr:0.78674\tvalidation_0-logloss:0.53890\n",
      "[7]\tvalidation_0-aucpr:0.79343\tvalidation_0-logloss:0.53155\n",
      "[8]\tvalidation_0-aucpr:0.79587\tvalidation_0-logloss:0.52812\n",
      "[9]\tvalidation_0-aucpr:0.79840\tvalidation_0-logloss:0.52495\n",
      "[10]\tvalidation_0-aucpr:0.80207\tvalidation_0-logloss:0.52111\n",
      "[11]\tvalidation_0-aucpr:0.80297\tvalidation_0-logloss:0.51902\n",
      "[12]\tvalidation_0-aucpr:0.80440\tvalidation_0-logloss:0.51692\n",
      "[13]\tvalidation_0-aucpr:0.80507\tvalidation_0-logloss:0.51592\n",
      "[14]\tvalidation_0-aucpr:0.80664\tvalidation_0-logloss:0.51364\n",
      "[15]\tvalidation_0-aucpr:0.80770\tvalidation_0-logloss:0.51170\n",
      "[16]\tvalidation_0-aucpr:0.80990\tvalidation_0-logloss:0.50901\n",
      "[17]\tvalidation_0-aucpr:0.81198\tvalidation_0-logloss:0.50631\n",
      "[18]\tvalidation_0-aucpr:0.81411\tvalidation_0-logloss:0.50387\n",
      "[19]\tvalidation_0-aucpr:0.81580\tvalidation_0-logloss:0.50206\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGBC = XGBClassifier(n_estimators=20, random_state=42, early_stopping_rounds=5, eval_metric=['aucpr', 'logloss'])\n",
    "XGBC = XGBC.fit(X_train, y_train,\n",
    "                eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15c405ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(ranker_input, XGBC, \"model_xgboost\", popular_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd34f8a",
   "metadata": {},
   "source": [
    "Catboost implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18f583b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.6243122\ttest: 0.6251442\tbest: 0.6251442 (0)\ttotal: 997ms\tremaining: 18.9s\n",
      "1:\tlearn: 0.5950279\ttest: 0.5953459\tbest: 0.5953459 (1)\ttotal: 1.95s\tremaining: 17.5s\n",
      "2:\tlearn: 0.5785664\ttest: 0.5793541\tbest: 0.5793541 (2)\ttotal: 2.92s\tremaining: 16.5s\n",
      "3:\tlearn: 0.5677026\ttest: 0.5685620\tbest: 0.5685620 (3)\ttotal: 3.92s\tremaining: 15.7s\n",
      "4:\tlearn: 0.5575830\ttest: 0.5583476\tbest: 0.5583476 (4)\ttotal: 4.96s\tremaining: 14.9s\n",
      "5:\tlearn: 0.5516687\ttest: 0.5524927\tbest: 0.5524927 (5)\ttotal: 5.96s\tremaining: 13.9s\n",
      "6:\tlearn: 0.5478969\ttest: 0.5487378\tbest: 0.5487378 (6)\ttotal: 6.88s\tremaining: 12.8s\n",
      "7:\tlearn: 0.5432536\ttest: 0.5440636\tbest: 0.5440636 (7)\ttotal: 7.86s\tremaining: 11.8s\n",
      "8:\tlearn: 0.5401012\ttest: 0.5408300\tbest: 0.5408300 (8)\ttotal: 8.81s\tremaining: 10.8s\n",
      "9:\tlearn: 0.5374814\ttest: 0.5382113\tbest: 0.5382113 (9)\ttotal: 9.76s\tremaining: 9.76s\n",
      "10:\tlearn: 0.5339554\ttest: 0.5347174\tbest: 0.5347174 (10)\ttotal: 10.9s\tremaining: 8.91s\n",
      "11:\tlearn: 0.5313766\ttest: 0.5320737\tbest: 0.5320737 (11)\ttotal: 11.8s\tremaining: 7.88s\n",
      "12:\tlearn: 0.5292990\ttest: 0.5300536\tbest: 0.5300536 (12)\ttotal: 12.9s\tremaining: 6.94s\n",
      "13:\tlearn: 0.5271947\ttest: 0.5279512\tbest: 0.5279512 (13)\ttotal: 13.7s\tremaining: 5.89s\n",
      "14:\tlearn: 0.5254927\ttest: 0.5262710\tbest: 0.5262710 (14)\ttotal: 14.6s\tremaining: 4.86s\n",
      "15:\tlearn: 0.5237735\ttest: 0.5245095\tbest: 0.5245095 (15)\ttotal: 15.4s\tremaining: 3.85s\n",
      "16:\tlearn: 0.5213908\ttest: 0.5220993\tbest: 0.5220993 (16)\ttotal: 16.4s\tremaining: 2.89s\n",
      "17:\tlearn: 0.5200758\ttest: 0.5207544\tbest: 0.5207544 (17)\ttotal: 17.4s\tremaining: 1.93s\n",
      "18:\tlearn: 0.5189343\ttest: 0.5196493\tbest: 0.5196493 (18)\ttotal: 18.4s\tremaining: 966ms\n",
      "19:\tlearn: 0.5181780\ttest: 0.5189111\tbest: 0.5189111 (19)\ttotal: 19.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5189111428\n",
      "bestIteration = 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "CBC = CatBoostClassifier(n_estimators=20, random_state=42, early_stopping_rounds=5, custom_metric=['AUC', 'Logloss'])\n",
    "CBC = CBC.fit(X_train, y_train,\n",
    "                eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a561f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(ranker_input, CBC, \"model_catboost\", popular_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f3d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
