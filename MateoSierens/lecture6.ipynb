{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c95c553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4e508cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/h-and-m-personalized-fashion-recommendations/discussion/308635\n",
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)\n",
    "\n",
    "def article_id_str_to_int(series):\n",
    "    return series.astype('int32')\n",
    "\n",
    "def article_id_int_to_str(series):\n",
    "    return '0' + series.astype('str')\n",
    "\n",
    "class Categorize(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_examples=0):\n",
    "        self.min_examples = min_examples\n",
    "        self.categories = []\n",
    "        \n",
    "    def fit(self, X):\n",
    "        for i in range(X.shape[1]):\n",
    "            vc = X.iloc[:, i].value_counts()\n",
    "            self.categories.append(vc[vc > self.min_examples].index.tolist())\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = {X.columns[i]: pd.Categorical(X.iloc[:, i], categories=self.categories[i]).codes for i in range(X.shape[1])}\n",
    "        return pd.DataFrame(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b318e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data with parquet\n",
    "transactions = pd.read_parquet('transactions_train.parquet')\n",
    "customers = pd.read_parquet('customers.parquet')\n",
    "articles = pd.read_parquet('articles.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f511f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352899"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers[\"postal_code\"].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3fedd468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105542 entries, 0 to 105541\n",
      "Data columns (total 25 columns):\n",
      " #   Column                        Non-Null Count   Dtype\n",
      "---  ------                        --------------   -----\n",
      " 0   article_id                    105542 non-null  int32\n",
      " 1   product_code                  105542 non-null  int32\n",
      " 2   prod_name                     105542 non-null  int32\n",
      " 3   product_type_no               105542 non-null  int32\n",
      " 4   product_type_name             105542 non-null  int16\n",
      " 5   product_group_name            105542 non-null  int8 \n",
      " 6   graphical_appearance_no       105542 non-null  int32\n",
      " 7   graphical_appearance_name     105542 non-null  int8 \n",
      " 8   colour_group_code             105542 non-null  int32\n",
      " 9   colour_group_name             105542 non-null  int8 \n",
      " 10  perceived_colour_value_id     105542 non-null  int32\n",
      " 11  perceived_colour_value_name   105542 non-null  int8 \n",
      " 12  perceived_colour_master_id    105542 non-null  int32\n",
      " 13  perceived_colour_master_name  105542 non-null  int8 \n",
      " 14  department_no                 105542 non-null  int32\n",
      " 15  department_name               105542 non-null  int16\n",
      " 16  index_code                    105542 non-null  int8 \n",
      " 17  index_name                    105542 non-null  int8 \n",
      " 18  index_group_no                105542 non-null  int32\n",
      " 19  index_group_name              105542 non-null  int8 \n",
      " 20  section_no                    105542 non-null  int32\n",
      " 21  section_name                  105542 non-null  int8 \n",
      " 22  garment_group_no              105542 non-null  int32\n",
      " 23  garment_group_name            105542 non-null  int8 \n",
      " 24  detail_desc                   105542 non-null  int32\n",
      "dtypes: int16(2), int32(13), int8(10)\n",
      "memory usage: 6.6 MB\n"
     ]
    }
   ],
   "source": [
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "108cbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_articles = transactions.merge(customers, on=\"customer_id\", how=\"inner\")[[\"article_id\", \"postal_code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "52773e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31788324 entries, 0 to 31788323\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Dtype\n",
      "---  ------       -----\n",
      " 0   article_id   int32\n",
      " 1   postal_code  int32\n",
      "dtypes: int32(2)\n",
      "memory usage: 485.1 MB\n"
     ]
    }
   ],
   "source": [
    "postal_articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bda7250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.matrix import InteractionMatrix\n",
    "from recpack.scenarios import WeakGeneralization\n",
    "from recpack.algorithms import MultVAE\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "from recpack.preprocessing.filters import MinItemsPerUser, MinUsersPerItem, MaxItemsPerUser, Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8fbe632b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b08cd3fca6d408383bdc94a1685273f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1429465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1193729ee8a44fbdab3f0751c31a91f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1429465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define preprocess pipeline\n",
    "preprocess = DataFramePreprocessor(\"article_id\", \"postal_code\")\n",
    "\n",
    "preprocess.add_filter(\n",
    "    Deduplicate(\"article_id\", \"postal_code\")\n",
    ")\n",
    "preprocess.add_filter(\n",
    "    MinItemsPerUser(400, \"article_id\", \"postal_code\")\n",
    ")\n",
    "preprocess.add_filter(\n",
    "    MinUsersPerItem(100, \"article_id\", \"postal_code\")\n",
    ")\n",
    "preprocess.add_filter(\n",
    "    MaxItemsPerUser(5000, \"article_id\", \"postal_code\")\n",
    ")\n",
    "interaction_matrix = preprocess.process(postal_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba5a183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d90f6b6ee7c44c5bdc2a2a1772d4e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d74c88d52574530af1a38dd7d0cc2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = WeakGeneralization(0.8, validation=True)\n",
    "scenario.split(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9221306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5109, 7582)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db4c632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = MultVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2003770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 22:23:28,190 - base - recpack - INFO - Processed epoch 0 in 1.14 s.Batch Training Loss = 2005.4914\n",
      "2022-11-29 22:23:54,608 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.011561434392827651, which is better than previous iterations.\n",
      "2022-11-29 22:23:54,610 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-11-29 22:23:54,664 - base - recpack - INFO - Evaluation at end of 0 took 26.47 s.\n",
      "2022-11-29 22:23:55,750 - base - recpack - INFO - Processed epoch 1 in 1.08 s.Batch Training Loss = 2006.5076\n",
      "2022-11-29 22:24:17,095 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.016065811222353378, which is worse than previous iterations.\n",
      "2022-11-29 22:24:17,097 - base - recpack - INFO - Evaluation at end of 1 took 21.35 s.\n",
      "2022-11-29 22:24:18,155 - base - recpack - INFO - Processed epoch 2 in 1.06 s.Batch Training Loss = 2010.0359\n",
      "2022-11-29 22:24:39,415 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.022534443779446724, which is better than previous iterations.\n",
      "2022-11-29 22:24:39,416 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-11-29 22:24:39,477 - base - recpack - INFO - Evaluation at end of 2 took 21.32 s.\n",
      "2022-11-29 22:24:40,555 - base - recpack - INFO - Processed epoch 3 in 1.08 s.Batch Training Loss = 1997.8677\n",
      "2022-11-29 22:25:01,570 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.030452604736424093, which is worse than previous iterations.\n",
      "2022-11-29 22:25:01,573 - base - recpack - INFO - Evaluation at end of 3 took 21.02 s.\n",
      "2022-11-29 22:25:02,630 - base - recpack - INFO - Processed epoch 4 in 1.06 s.Batch Training Loss = 2002.7198\n",
      "2022-11-29 22:25:23,575 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.03676796449940759, which is better than previous iterations.\n",
      "2022-11-29 22:25:23,577 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2022-11-29 22:25:23,638 - base - recpack - INFO - Evaluation at end of 4 took 21.01 s.\n",
      "2022-11-29 22:25:24,730 - base - recpack - INFO - Processed epoch 5 in 1.09 s.Batch Training Loss = 1999.3265\n",
      "2022-11-29 22:25:45,604 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.040385358800339756, which is worse than previous iterations.\n",
      "2022-11-29 22:25:45,607 - base - recpack - INFO - Evaluation at end of 5 took 20.88 s.\n",
      "2022-11-29 22:25:46,679 - base - recpack - INFO - Processed epoch 6 in 1.07 s.Batch Training Loss = 1985.3169\n",
      "2022-11-29 22:26:07,422 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.042148470207066094, which is worse than previous iterations.\n",
      "2022-11-29 22:26:07,425 - base - recpack - INFO - Evaluation at end of 6 took 20.75 s.\n",
      "2022-11-29 22:26:08,514 - base - recpack - INFO - Processed epoch 7 in 1.09 s.Batch Training Loss = 1978.7941\n",
      "2022-11-29 22:26:28,938 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0432391082093931, which is worse than previous iterations.\n",
      "2022-11-29 22:26:28,940 - base - recpack - INFO - Evaluation at end of 7 took 20.42 s.\n",
      "2022-11-29 22:26:30,007 - base - recpack - INFO - Processed epoch 8 in 1.07 s.Batch Training Loss = 1960.7520\n",
      "2022-11-29 22:26:51,214 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043072549175781474, which is worse than previous iterations.\n",
      "2022-11-29 22:26:51,217 - base - recpack - INFO - Evaluation at end of 8 took 21.21 s.\n",
      "2022-11-29 22:26:52,273 - base - recpack - INFO - Processed epoch 9 in 1.05 s.Batch Training Loss = 1968.8661\n",
      "2022-11-29 22:27:13,265 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04327483030443536, which is worse than previous iterations.\n",
      "2022-11-29 22:27:13,267 - base - recpack - INFO - Evaluation at end of 9 took 20.99 s.\n",
      "2022-11-29 22:27:14,330 - base - recpack - INFO - Processed epoch 10 in 1.06 s.Batch Training Loss = 1969.3723\n",
      "2022-11-29 22:27:35,431 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043219867479096674, which is worse than previous iterations.\n",
      "2022-11-29 22:27:35,434 - base - recpack - INFO - Evaluation at end of 10 took 21.10 s.\n",
      "2022-11-29 22:27:36,530 - base - recpack - INFO - Processed epoch 11 in 1.09 s.Batch Training Loss = 1963.2532\n",
      "2022-11-29 22:27:57,353 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0432219781329269, which is worse than previous iterations.\n",
      "2022-11-29 22:27:57,356 - base - recpack - INFO - Evaluation at end of 11 took 20.82 s.\n",
      "2022-11-29 22:27:58,427 - base - recpack - INFO - Processed epoch 12 in 1.07 s.Batch Training Loss = 1969.0776\n",
      "2022-11-29 22:28:19,378 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043223293551495484, which is worse than previous iterations.\n",
      "2022-11-29 22:28:19,380 - base - recpack - INFO - Evaluation at end of 12 took 20.95 s.\n",
      "2022-11-29 22:28:20,461 - base - recpack - INFO - Processed epoch 13 in 1.08 s.Batch Training Loss = 1972.4986\n",
      "2022-11-29 22:28:41,172 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043291241882228985, which is worse than previous iterations.\n",
      "2022-11-29 22:28:41,175 - base - recpack - INFO - Evaluation at end of 13 took 20.71 s.\n",
      "2022-11-29 22:28:42,237 - base - recpack - INFO - Processed epoch 14 in 1.06 s.Batch Training Loss = 1966.6413\n",
      "2022-11-29 22:29:03,726 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04319544071712439, which is worse than previous iterations.\n",
      "2022-11-29 22:29:03,729 - base - recpack - INFO - Evaluation at end of 14 took 21.49 s.\n",
      "2022-11-29 22:29:04,828 - base - recpack - INFO - Processed epoch 15 in 1.10 s.Batch Training Loss = 1963.8742\n",
      "2022-11-29 22:29:25,873 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0432884913246231, which is worse than previous iterations.\n",
      "2022-11-29 22:29:25,876 - base - recpack - INFO - Evaluation at end of 15 took 21.05 s.\n",
      "2022-11-29 22:29:26,990 - base - recpack - INFO - Processed epoch 16 in 1.11 s.Batch Training Loss = 1972.7672\n",
      "2022-11-29 22:29:47,821 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04333146245883227, which is worse than previous iterations.\n",
      "2022-11-29 22:29:47,824 - base - recpack - INFO - Evaluation at end of 16 took 20.83 s.\n",
      "2022-11-29 22:29:48,904 - base - recpack - INFO - Processed epoch 17 in 1.08 s.Batch Training Loss = 1974.3188\n",
      "2022-11-29 22:30:10,062 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04326066213139482, which is worse than previous iterations.\n",
      "2022-11-29 22:30:10,064 - base - recpack - INFO - Evaluation at end of 17 took 21.16 s.\n",
      "2022-11-29 22:30:11,137 - base - recpack - INFO - Processed epoch 18 in 1.07 s.Batch Training Loss = 1963.9315\n",
      "2022-11-29 22:30:32,059 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043206157689585786, which is worse than previous iterations.\n",
      "2022-11-29 22:30:32,062 - base - recpack - INFO - Evaluation at end of 18 took 20.92 s.\n",
      "2022-11-29 22:30:33,137 - base - recpack - INFO - Processed epoch 19 in 1.07 s.Batch Training Loss = 1969.9006\n",
      "2022-11-29 22:30:53,932 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04314702548622942, which is worse than previous iterations.\n",
      "2022-11-29 22:30:53,935 - base - recpack - INFO - Evaluation at end of 19 took 20.80 s.\n",
      "2022-11-29 22:30:55,002 - base - recpack - INFO - Processed epoch 20 in 1.07 s.Batch Training Loss = 1968.6074\n",
      "2022-11-29 22:31:15,577 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04324286916854286, which is worse than previous iterations.\n",
      "2022-11-29 22:31:15,579 - base - recpack - INFO - Evaluation at end of 20 took 20.58 s.\n",
      "2022-11-29 22:31:16,662 - base - recpack - INFO - Processed epoch 21 in 1.08 s.Batch Training Loss = 1979.3025\n",
      "2022-11-29 22:31:38,195 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0432228729449399, which is worse than previous iterations.\n",
      "2022-11-29 22:31:38,197 - base - recpack - INFO - Evaluation at end of 21 took 21.53 s.\n",
      "2022-11-29 22:31:39,259 - base - recpack - INFO - Processed epoch 22 in 1.06 s.Batch Training Loss = 1959.7574\n",
      "2022-11-29 22:32:00,580 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04334324398720523, which is worse than previous iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 22:32:00,583 - base - recpack - INFO - Evaluation at end of 22 took 21.32 s.\n",
      "2022-11-29 22:32:01,662 - base - recpack - INFO - Processed epoch 23 in 1.08 s.Batch Training Loss = 1971.4098\n",
      "2022-11-29 22:32:22,770 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043283590875467036, which is worse than previous iterations.\n",
      "2022-11-29 22:32:22,772 - base - recpack - INFO - Evaluation at end of 23 took 21.11 s.\n",
      "2022-11-29 22:32:23,880 - base - recpack - INFO - Processed epoch 24 in 1.11 s.Batch Training Loss = 1970.8116\n",
      "2022-11-29 22:32:45,013 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04325145218707472, which is worse than previous iterations.\n",
      "2022-11-29 22:32:45,016 - base - recpack - INFO - Evaluation at end of 24 took 21.13 s.\n",
      "2022-11-29 22:32:46,091 - base - recpack - INFO - Processed epoch 25 in 1.07 s.Batch Training Loss = 1973.0999\n",
      "2022-11-29 22:33:06,866 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043414652109472346, which is worse than previous iterations.\n",
      "2022-11-29 22:33:06,869 - base - recpack - INFO - Evaluation at end of 25 took 20.78 s.\n",
      "2022-11-29 22:33:07,951 - base - recpack - INFO - Processed epoch 26 in 1.08 s.Batch Training Loss = 1974.5119\n",
      "2022-11-29 22:33:28,625 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043327177379313284, which is worse than previous iterations.\n",
      "2022-11-29 22:33:28,627 - base - recpack - INFO - Evaluation at end of 26 took 20.67 s.\n",
      "2022-11-29 22:33:29,713 - base - recpack - INFO - Processed epoch 27 in 1.09 s.Batch Training Loss = 1981.5722\n",
      "2022-11-29 22:33:50,328 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04332156238729428, which is worse than previous iterations.\n",
      "2022-11-29 22:33:50,331 - base - recpack - INFO - Evaluation at end of 27 took 20.62 s.\n",
      "2022-11-29 22:33:51,417 - base - recpack - INFO - Processed epoch 28 in 1.08 s.Batch Training Loss = 1968.2119\n",
      "2022-11-29 22:34:13,015 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04342718370397855, which is worse than previous iterations.\n",
      "2022-11-29 22:34:13,017 - base - recpack - INFO - Evaluation at end of 28 took 21.60 s.\n",
      "2022-11-29 22:34:14,085 - base - recpack - INFO - Processed epoch 29 in 1.07 s.Batch Training Loss = 1966.3515\n",
      "2022-11-29 22:34:35,295 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04333292751964126, which is worse than previous iterations.\n",
      "2022-11-29 22:34:35,297 - base - recpack - INFO - Evaluation at end of 29 took 21.21 s.\n",
      "2022-11-29 22:34:36,378 - base - recpack - INFO - Processed epoch 30 in 1.08 s.Batch Training Loss = 1963.4477\n",
      "2022-11-29 22:34:57,321 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04346856627579949, which is worse than previous iterations.\n",
      "2022-11-29 22:34:57,323 - base - recpack - INFO - Evaluation at end of 30 took 20.94 s.\n",
      "2022-11-29 22:34:58,399 - base - recpack - INFO - Processed epoch 31 in 1.07 s.Batch Training Loss = 1963.3957\n",
      "2022-11-29 22:35:19,418 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.0433525394423787, which is worse than previous iterations.\n",
      "2022-11-29 22:35:19,421 - base - recpack - INFO - Evaluation at end of 31 took 21.02 s.\n",
      "2022-11-29 22:35:20,501 - base - recpack - INFO - Processed epoch 32 in 1.08 s.Batch Training Loss = 1969.3883\n",
      "2022-11-29 22:35:41,352 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04336532536221467, which is worse than previous iterations.\n",
      "2022-11-29 22:35:41,354 - base - recpack - INFO - Evaluation at end of 32 took 20.85 s.\n",
      "2022-11-29 22:35:42,469 - base - recpack - INFO - Processed epoch 33 in 1.11 s.Batch Training Loss = 1967.1958\n",
      "2022-11-29 22:36:02,902 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04350453750758565, which is worse than previous iterations.\n",
      "2022-11-29 22:36:02,905 - base - recpack - INFO - Evaluation at end of 33 took 20.43 s.\n",
      "2022-11-29 22:36:03,967 - base - recpack - INFO - Processed epoch 34 in 1.06 s.Batch Training Loss = 1974.3492\n",
      "2022-11-29 22:36:24,495 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04343826919258861, which is worse than previous iterations.\n",
      "2022-11-29 22:36:24,498 - base - recpack - INFO - Evaluation at end of 34 took 20.53 s.\n",
      "2022-11-29 22:36:25,579 - base - recpack - INFO - Processed epoch 35 in 1.08 s.Batch Training Loss = 1961.9968\n",
      "2022-11-29 22:36:46,935 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043615362969266616, which is worse than previous iterations.\n",
      "2022-11-29 22:36:46,938 - base - recpack - INFO - Evaluation at end of 35 took 21.36 s.\n",
      "2022-11-29 22:36:48,021 - base - recpack - INFO - Processed epoch 36 in 1.08 s.Batch Training Loss = 1974.9799\n",
      "2022-11-29 22:37:09,137 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04344537863201563, which is worse than previous iterations.\n",
      "2022-11-29 22:37:09,139 - base - recpack - INFO - Evaluation at end of 36 took 21.12 s.\n",
      "2022-11-29 22:37:10,225 - base - recpack - INFO - Processed epoch 37 in 1.08 s.Batch Training Loss = 1968.4891\n",
      "2022-11-29 22:37:31,056 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04350988795252316, which is worse than previous iterations.\n",
      "2022-11-29 22:37:31,059 - base - recpack - INFO - Evaluation at end of 37 took 20.83 s.\n",
      "2022-11-29 22:37:32,124 - base - recpack - INFO - Processed epoch 38 in 1.06 s.Batch Training Loss = 1973.4286\n",
      "2022-11-29 22:37:52,890 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04349432914324595, which is worse than previous iterations.\n",
      "2022-11-29 22:37:52,893 - base - recpack - INFO - Evaluation at end of 38 took 20.77 s.\n",
      "2022-11-29 22:37:53,965 - base - recpack - INFO - Processed epoch 39 in 1.07 s.Batch Training Loss = 1975.9547\n",
      "2022-11-29 22:38:14,711 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04349252813790658, which is worse than previous iterations.\n",
      "2022-11-29 22:38:14,713 - base - recpack - INFO - Evaluation at end of 39 took 20.75 s.\n",
      "2022-11-29 22:38:15,782 - base - recpack - INFO - Processed epoch 40 in 1.07 s.Batch Training Loss = 1963.2132\n",
      "2022-11-29 22:38:37,302 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04365740285446504, which is worse than previous iterations.\n",
      "2022-11-29 22:38:37,304 - base - recpack - INFO - Evaluation at end of 40 took 21.52 s.\n",
      "2022-11-29 22:38:38,376 - base - recpack - INFO - Processed epoch 41 in 1.07 s.Batch Training Loss = 1962.2104\n",
      "2022-11-29 22:38:59,679 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04373063142572141, which is worse than previous iterations.\n",
      "2022-11-29 22:38:59,681 - base - recpack - INFO - Evaluation at end of 41 took 21.30 s.\n",
      "2022-11-29 22:39:00,750 - base - recpack - INFO - Processed epoch 42 in 1.07 s.Batch Training Loss = 1968.7360\n",
      "2022-11-29 22:39:21,634 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043853597171810095, which is worse than previous iterations.\n",
      "2022-11-29 22:39:21,637 - base - recpack - INFO - Evaluation at end of 42 took 20.89 s.\n",
      "2022-11-29 22:39:22,708 - base - recpack - INFO - Processed epoch 43 in 1.07 s.Batch Training Loss = 1967.9404\n",
      "2022-11-29 22:39:43,721 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.043808242843299205, which is worse than previous iterations.\n",
      "2022-11-29 22:39:43,724 - base - recpack - INFO - Evaluation at end of 43 took 21.01 s.\n",
      "2022-11-29 22:39:44,830 - base - recpack - INFO - Processed epoch 44 in 1.10 s.Batch Training Loss = 1972.5283\n",
      "2022-11-29 22:40:05,555 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04414618996354998, which is worse than previous iterations.\n",
      "2022-11-29 22:40:05,557 - base - recpack - INFO - Evaluation at end of 44 took 20.73 s.\n",
      "2022-11-29 22:40:06,629 - base - recpack - INFO - Processed epoch 45 in 1.07 s.Batch Training Loss = 1966.8768\n",
      "2022-11-29 22:40:27,455 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04413570803709935, which is worse than previous iterations.\n",
      "2022-11-29 22:40:27,458 - base - recpack - INFO - Evaluation at end of 45 took 20.83 s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 22:40:28,525 - base - recpack - INFO - Processed epoch 46 in 1.07 s.Batch Training Loss = 1961.9926\n",
      "2022-11-29 22:40:49,390 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04454320905058891, which is worse than previous iterations.\n",
      "2022-11-29 22:40:49,393 - base - recpack - INFO - Evaluation at end of 46 took 20.87 s.\n",
      "2022-11-29 22:40:50,470 - base - recpack - INFO - Processed epoch 47 in 1.08 s.Batch Training Loss = 1968.2176\n",
      "2022-11-29 22:41:12,187 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04484744554171584, which is worse than previous iterations.\n",
      "2022-11-29 22:41:12,190 - base - recpack - INFO - Evaluation at end of 47 took 21.72 s.\n",
      "2022-11-29 22:41:13,255 - base - recpack - INFO - Processed epoch 48 in 1.06 s.Batch Training Loss = 1968.2877\n",
      "2022-11-29 22:41:34,326 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.04490782730311098, which is worse than previous iterations.\n",
      "2022-11-29 22:41:34,329 - base - recpack - INFO - Evaluation at end of 48 took 21.07 s.\n",
      "2022-11-29 22:41:35,399 - base - recpack - INFO - Processed epoch 49 in 1.07 s.Batch Training Loss = 1957.8267\n",
      "2022-11-29 22:41:56,339 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.045168321360900064, which is worse than previous iterations.\n",
      "2022-11-29 22:41:56,341 - base - recpack - INFO - Evaluation at end of 49 took 20.94 s.\n",
      "2022-11-29 22:41:57,447 - base - recpack - INFO - Processed epoch 50 in 1.10 s.Batch Training Loss = 1959.0827\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5198/1955160464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_training_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/recpack/algorithms/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, validation_data)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m                     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Evaluation at end of {epoch} took {end_time-start_time :.2f} s.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/recpack/algorithms/base.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, val_in, val_out)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mval_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_sample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mX_pred_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;31m# StoppingCriterion expects csr_matrix as output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/recpack/algorithms/base.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_top_k_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"shape of response ({results.shape})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/sparse/_lil.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_intXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# Everything else takes the normal path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mIndexMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_mul_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_arrayXarray_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# Make x and i into the same shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/sparse/_lil.py\u001b[0m in \u001b[0;36m_set_arrayXarray_sparse\u001b[0;34m(self, row, col, x)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_arrayXarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/sparse/_lil.py\u001b[0m in \u001b[0;36m_set_arrayXarray\u001b[0;34m(self, row, col, x)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_arrayXarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_prepare_index_for_memoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         _csparsetools.lil_fancy_set(self.shape[0], self.shape[1],\n\u001b[0m\u001b[1;32m    305\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                                     i, j, x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit = algorithm.fit(scenario.full_training_data, (scenario.validation_data_in, scenario.validation_data_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ff5edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1899e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.load(\"MultVAE_loss_0.05672078799998033.trch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc851237",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = algorithm.predict(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd8bce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.902098655700684"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78f84979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.029760837554932"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdc3d120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1441667068197327"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9358cf",
   "metadata": {},
   "source": [
    "The result now contains scores for every item per postal code. This score tells us how interesting this item is for that postal code. In the next sections, I will explore how this affects the candidate generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6f91d",
   "metadata": {},
   "source": [
    "## Baseline generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed44dd6",
   "metadata": {},
   "source": [
    "As a baseline for candidate generation I will use features about popularity and repurchases. With this, we will see whether the score improves and by how much when adding features/candidates taking the postal code results into account. Baseline inspired by https://github.com/radekosmulski/personalized_fashion_recs/blob/main/03c_Basic_Model_Submission.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebef64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_week = transactions.week.max() + 1\n",
    "transactions = transactions[transactions.week > transactions.week.max() - 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1808b",
   "metadata": {},
   "source": [
    "### Repurchase samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f19fc727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all weeks a customer purchased articles in\n",
    "purch_weeks = transactions.groupby('customer_id')['week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b225766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from every week a purchase was made to the next week a purchase was made\n",
    "# the last purchase week is mapped to the test week\n",
    "purch_weeks_next = {}\n",
    "\n",
    "for c_id, weeks in purch_weeks.items():\n",
    "    purch_weeks_next[c_id] = {}\n",
    "    for i in range(weeks.shape[0]-1):\n",
    "        purch_weeks_next[c_id][weeks[i]] = weeks[i+1]\n",
    "    purch_weeks_next[c_id][weeks[-1]] = test_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0bc7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the repurchase samples will be based on the original transactions\n",
    "repurchase_samples = transactions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ce71204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use week mappings to set weeks in repurchase samples\n",
    "weeks = []\n",
    "for i, (c_id, week) in enumerate(zip(transactions['customer_id'], transactions['week'])):\n",
    "    weeks.append(purch_weeks_next[c_id][week])\n",
    "repurchase_samples.week=weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72a20d",
   "metadata": {},
   "source": [
    "### Popularity samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8648d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean price of each article on a weekly basis\n",
    "mean_price = transactions \\\n",
    "    .groupby(['week', 'article_id'])['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3321b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each week get the top 12 items sold, assign them a rank\n",
    "sales = transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(12).rename('bestseller_rank').astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64212cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe stating for each item the bestseller rank of the item in the previous week\n",
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1264e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique transaction for every user and week it was active in\n",
    "unique_transactions = transactions \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a471b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create samples of of items that were sold the most in the week before the sample\n",
    "bestseller_samples = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dd21b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one transactions for each user in the test week\n",
    "test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "test_set_transactions.week = test_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aa47654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bestseller candidates\n",
    "bestseller_candidates = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e00a3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all bestseller samples, drop ranking column\n",
    "bestseller_samples = pd.concat([bestseller_samples, bestseller_candidates])\n",
    "bestseller_samples.drop(columns='bestseller_rank', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a14757",
   "metadata": {},
   "source": [
    "### Combining everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a4d2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['purchased'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e408253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine transactions, negative samples and candidates\n",
    "data = pd.concat([transactions, repurchase_samples, bestseller_samples])\n",
    "data.purchased.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a677c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "524ad606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add article and customer info\n",
    "data = pd.merge(data, articles, on='article_id', how='left')\n",
    "data = pd.merge(data, customers, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df3695aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "220ed4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train = data[data.week != test_week]\n",
    "test = data[data.week==test_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fed53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3ce6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5961ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019b121",
   "metadata": {},
   "source": [
    "### Ranker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bacedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "609b7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed32920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.847855\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.161885\n",
      "[LightGBM] [Debug] init for col-wise cost 0.083216 seconds, init for row-wise cost 0.173942 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 11643599, number of used features: 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n"
     ]
    }
   ],
   "source": [
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bed00952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id 0.2895738969603472\n",
      "graphical_appearance_no 0.2031760352858636\n",
      "department_no 0.1518033461810415\n",
      "product_type_no 0.07518838393666324\n",
      "section_no 0.05930797516241852\n",
      "garment_group_no 0.05875708751234863\n",
      "perceived_colour_master_id 0.0514193307202976\n",
      "perceived_colour_value_id 0.04928437615963122\n",
      "colour_group_code 0.04590556194744773\n",
      "index_group_no 0.01558400613394081\n",
      "index_code 0.0\n",
      "age 0.0\n",
      "FN 0.0\n",
      "Active 0.0\n",
      "club_member_status 0.0\n",
      "fashion_news_frequency 0.0\n",
      "postal_code 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b46d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "# order predicted articles per user\n",
    "user_predicted_articles = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "# get bestsellers from last week before test week\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d7620a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d408814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform predictions to correct format for submission\n",
    "preds = []\n",
    "for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "    pred = user_predicted_articles.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])\n",
    "\n",
    "preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "sub.prediction = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93ad0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline submission\n",
    "sub_name = 'baseline_submission'\n",
    "sub.to_csv(f'{sub_name}.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1434c1f",
   "metadata": {},
   "source": [
    "## Candidates based on postal codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9a776",
   "metadata": {},
   "source": [
    "Based on the interaction matrix we can generate samples/candidates for postal codes using a threshold score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a9d392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with postal codes and items\n",
    "\n",
    "# TODO: this is wrong. I thought the code below would get me the postal codes and article ids, but instead it\n",
    "# returns indices for the interaction matrix\n",
    "\n",
    "# first get all entries for dataframe\n",
    "scores = result.toarray().flatten()\n",
    "postal_codes = np.unique(interaction_matrix.indices[0])\n",
    "articles = np.unique(interaction_matrix.indices[1])\n",
    "\n",
    "# select only the entries passing threshold\n",
    "threshold = 2\n",
    "idx = np.nonzero(scores > threshold)\n",
    "\n",
    "postal_codes_entries = np.repeat(postal_codes, len(articles))[idx]\n",
    "articles_entries = np.tile(articles, len(postal_codes))[idx]\n",
    "score_entries = scores[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fec1fea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.050107653161085"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amount of candidates per postal code\n",
    "postal_codes_entries.size / postal_codes.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a00972bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_scores = pd.DataFrame({\"postal_code\": postal_codes_entries,\n",
    "                             \"article_id\": articles_entries,\n",
    "                             \"score\": score_entries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fca59a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>article_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2.067054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>2.366963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>2.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>2.212671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>2.223141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199502</th>\n",
       "      <td>5108</td>\n",
       "      <td>2939</td>\n",
       "      <td>2.053555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199503</th>\n",
       "      <td>5108</td>\n",
       "      <td>3034</td>\n",
       "      <td>2.028477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199504</th>\n",
       "      <td>5108</td>\n",
       "      <td>3402</td>\n",
       "      <td>2.195340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199505</th>\n",
       "      <td>5108</td>\n",
       "      <td>3422</td>\n",
       "      <td>2.310904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199506</th>\n",
       "      <td>5108</td>\n",
       "      <td>3875</td>\n",
       "      <td>2.436683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199507 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        postal_code  article_id     score\n",
       "0                 0          37  2.067054\n",
       "1                 0          67  2.366963\n",
       "2                 0         204  2.002607\n",
       "3                 0         212  2.212671\n",
       "4                 0         362  2.223141\n",
       "...             ...         ...       ...\n",
       "199502         5108        2939  2.053555\n",
       "199503         5108        3034  2.028477\n",
       "199504         5108        3402  2.195340\n",
       "199505         5108        3422  2.310904\n",
       "199506         5108        3875  2.436683\n",
       "\n",
       "[199507 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postal_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fa5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
