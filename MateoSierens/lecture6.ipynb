{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c95c553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e508cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/h-and-m-personalized-fashion-recommendations/discussion/308635\n",
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)\n",
    "\n",
    "def article_id_str_to_int(series):\n",
    "    return series.astype('int32')\n",
    "\n",
    "def article_id_int_to_str(series):\n",
    "    return '0' + series.astype('str')\n",
    "\n",
    "class Categorize(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_examples=0):\n",
    "        self.min_examples = min_examples\n",
    "        self.categories = []\n",
    "        \n",
    "    def fit(self, X):\n",
    "        for i in range(X.shape[1]):\n",
    "            vc = X.iloc[:, i].value_counts()\n",
    "            self.categories.append(vc[vc > self.min_examples].index.tolist())\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = {X.columns[i]: pd.Categorical(X.iloc[:, i], categories=self.categories[i]).codes for i in range(X.shape[1])}\n",
    "        return pd.DataFrame(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b318e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data with parquet\n",
    "transactions = pd.read_parquet('transactions_train.parquet')\n",
    "customers = pd.read_parquet('customers.parquet')\n",
    "articles = pd.read_parquet('articles.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f511f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352899"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers[\"postal_code\"].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fedd468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105542 entries, 0 to 105541\n",
      "Data columns (total 25 columns):\n",
      " #   Column                        Non-Null Count   Dtype\n",
      "---  ------                        --------------   -----\n",
      " 0   article_id                    105542 non-null  int32\n",
      " 1   product_code                  105542 non-null  int32\n",
      " 2   prod_name                     105542 non-null  int32\n",
      " 3   product_type_no               105542 non-null  int32\n",
      " 4   product_type_name             105542 non-null  int16\n",
      " 5   product_group_name            105542 non-null  int8 \n",
      " 6   graphical_appearance_no       105542 non-null  int32\n",
      " 7   graphical_appearance_name     105542 non-null  int8 \n",
      " 8   colour_group_code             105542 non-null  int32\n",
      " 9   colour_group_name             105542 non-null  int8 \n",
      " 10  perceived_colour_value_id     105542 non-null  int32\n",
      " 11  perceived_colour_value_name   105542 non-null  int8 \n",
      " 12  perceived_colour_master_id    105542 non-null  int32\n",
      " 13  perceived_colour_master_name  105542 non-null  int8 \n",
      " 14  department_no                 105542 non-null  int32\n",
      " 15  department_name               105542 non-null  int16\n",
      " 16  index_code                    105542 non-null  int8 \n",
      " 17  index_name                    105542 non-null  int8 \n",
      " 18  index_group_no                105542 non-null  int32\n",
      " 19  index_group_name              105542 non-null  int8 \n",
      " 20  section_no                    105542 non-null  int32\n",
      " 21  section_name                  105542 non-null  int8 \n",
      " 22  garment_group_no              105542 non-null  int32\n",
      " 23  garment_group_name            105542 non-null  int8 \n",
      " 24  detail_desc                   105542 non-null  int32\n",
      "dtypes: int16(2), int32(13), int8(10)\n",
      "memory usage: 6.6 MB\n"
     ]
    }
   ],
   "source": [
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "108cbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_articles = transactions.merge(customers, on=\"customer_id\", how=\"inner\")[[\"article_id\", \"postal_code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52773e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31788324 entries, 0 to 31788323\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Dtype\n",
      "---  ------       -----\n",
      " 0   article_id   int32\n",
      " 1   postal_code  int32\n",
      "dtypes: int32(2)\n",
      "memory usage: 485.1 MB\n"
     ]
    }
   ],
   "source": [
    "postal_articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bda7250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.matrix import InteractionMatrix\n",
    "from recpack.scenarios import WeakGeneralization\n",
    "from recpack.algorithms import MultVAE\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "from recpack.preprocessing.filters import MinItemsPerUser, MinUsersPerItem, MaxItemsPerUser, Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fbe632b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1bc646865549a58ffc2ddabeb1ed53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1429465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c14b31c7c24031a80e5d22f37c4ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1429465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define preprocess pipeline\n",
    "preprocess = DataFramePreprocessor(\"article_id\", \"postal_code\")\n",
    "\n",
    "preprocess.add_filter(\n",
    "    Deduplicate(\"article_id\", \"postal_code\")\n",
    ")\n",
    "preprocess.add_filter(\n",
    "    MinItemsPerUser(400, \"article_id\", \"postal_code\")\n",
    ")\n",
    "preprocess.add_filter(\n",
    "    MinUsersPerItem(100, \"article_id\", \"postal_code\")\n",
    ")\n",
    "preprocess.add_filter(\n",
    "    MaxItemsPerUser(5000, \"article_id\", \"postal_code\")\n",
    ")\n",
    "interaction_matrix = preprocess.process(postal_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aba5a183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a634f161e4ad4da88c1a11e9394aab72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe0bee7f80a4cffbedea71ef155efdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = WeakGeneralization(0.8, validation=True)\n",
    "scenario.split(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9221306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5109, 7582)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db4c632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = MultVAE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc94986",
   "metadata": {},
   "source": [
    "Instead of fitting algorithm every time, it is saved the first time and loaded from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit = algorithm.fit(scenario.full_training_data, (scenario.validation_data_in, scenario.validation_data_out))\n",
    "# fit.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1899e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.load(\"MultVAE_loss_0.05672078799998033.trch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc851237",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = algorithm.predict(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd8bce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.902098655700684"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78f84979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.029760837554932"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdc3d120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1441667068197327"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9358cf",
   "metadata": {},
   "source": [
    "The result now contains scores for every item per postal code. This score tells us how interesting this item is for that postal code. In the next sections, I will explore how this affects the candidate generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6f91d",
   "metadata": {},
   "source": [
    "## Baseline generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed44dd6",
   "metadata": {},
   "source": [
    "As a baseline for candidate generation I will use features about popularity and repurchases. With this, we will see whether the score improves and by how much when adding features/candidates taking the postal code results into account. Baseline inspired by https://github.com/radekosmulski/personalized_fashion_recs/blob/main/03c_Basic_Model_Submission.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebef64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_week = transactions.week.max() + 1\n",
    "transactions = transactions[transactions.week > transactions.week.max() - 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1808b",
   "metadata": {},
   "source": [
    "### Repurchase samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f19fc727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all weeks a customer purchased articles in\n",
    "purch_weeks = transactions.groupby('customer_id')['week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b225766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from every week a purchase was made to the next week a purchase was made\n",
    "# the last purchase week is mapped to the test week\n",
    "purch_weeks_next = {}\n",
    "\n",
    "for c_id, weeks in purch_weeks.items():\n",
    "    purch_weeks_next[c_id] = {}\n",
    "    for i in range(weeks.shape[0]-1):\n",
    "        purch_weeks_next[c_id][weeks[i]] = weeks[i+1]\n",
    "    purch_weeks_next[c_id][weeks[-1]] = test_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0bc7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the repurchase samples will be based on the original transactions\n",
    "repurchase_samples = transactions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ce71204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use week mappings to set weeks in repurchase samples\n",
    "weeks = []\n",
    "for i, (c_id, week) in enumerate(zip(transactions['customer_id'], transactions['week'])):\n",
    "    weeks.append(purch_weeks_next[c_id][week])\n",
    "repurchase_samples.week=weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72a20d",
   "metadata": {},
   "source": [
    "### Popularity samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8648d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean price of each article on a weekly basis\n",
    "mean_price = transactions \\\n",
    "    .groupby(['week', 'article_id'])['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3321b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each week get the top 12 items sold, assign them a rank\n",
    "sales = transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(12).rename('bestseller_rank').astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64212cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe stating for each item the bestseller rank of the item in the previous week\n",
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1264e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique transaction for every user and week it was active in\n",
    "unique_transactions = transactions \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a471b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create samples of of items that were sold the most in the week before the sample\n",
    "bestseller_samples = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2dd21b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one transactions for each user in the test week\n",
    "test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "test_set_transactions.week = test_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8aa47654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bestseller candidates\n",
    "bestseller_candidates = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e00a3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all bestseller samples, drop ranking column\n",
    "bestseller_samples = pd.concat([bestseller_samples, bestseller_candidates])\n",
    "bestseller_samples.drop(columns='bestseller_rank', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a14757",
   "metadata": {},
   "source": [
    "### Combining everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4a4d2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['purchased'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7e408253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine transactions, negative samples and candidates\n",
    "data = pd.concat([transactions, repurchase_samples, bestseller_samples])\n",
    "data.purchased.fillna(0, inplace=True)\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "    on=['week', 'article_id'],\n",
    "    how='left'\n",
    ")\n",
    "data.fillna(999, inplace=True)\n",
    "data = data[data.week != data.week.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7a677c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "524ad606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add article and customer info\n",
    "data = pd.merge(data, articles, on='article_id', how='left')\n",
    "data = pd.merge(data, customers, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "df3695aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "220ed4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train = data[data.week != test_week]\n",
    "test = data[data.week==test_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8fed53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e3ce6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'bestseller_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5961ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019b121",
   "metadata": {},
   "source": [
    "### Ranker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "74ee580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in ./anaconda3/lib/python3.9/site-packages (3.3.3)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.9/site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.9/site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in ./anaconda3/lib/python3.9/site-packages (from lightgbm) (1.1.3)\n",
      "Requirement already satisfied: wheel in ./anaconda3/lib/python3.9/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in ./anaconda3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2bacedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "609b7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ed32920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.848850\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.153099\n",
      "[LightGBM] [Debug] init for col-wise cost 0.203516 seconds, init for row-wise cost 0.424966 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.303681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 11381612, number of used features: 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n"
     ]
    }
   ],
   "source": [
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bed00952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestseller_rank 0.9989805519216203\n",
      "age 0.00024136038957903926\n",
      "article_id 0.00017160828400263902\n",
      "garment_group_no 0.0001448188543340445\n",
      "department_no 9.637421875769266e-05\n",
      "product_type_no 9.014783292439592e-05\n",
      "section_no 7.067204716548531e-05\n",
      "postal_code 6.792197441369627e-05\n",
      "club_member_status 6.519780240033951e-05\n",
      "colour_group_code 5.358754121027148e-05\n",
      "perceived_colour_value_id 1.775913359216025e-05\n",
      "fashion_news_frequency 0.0\n",
      "Active 0.0\n",
      "FN 0.0\n",
      "index_code 0.0\n",
      "perceived_colour_master_id 0.0\n",
      "graphical_appearance_no 0.0\n",
      "index_group_no 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5b46d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "# order predicted articles per user\n",
    "user_predicted_articles = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "# get bestsellers from last week before test week\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9d7620a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0d408814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform predictions to correct format for submission\n",
    "preds = []\n",
    "for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "    pred = user_predicted_articles.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])\n",
    "\n",
    "preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "sub.prediction = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "93ad0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline submission\n",
    "sub_name = 'baseline_submission'\n",
    "sub.to_csv(f'{sub_name}.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1434c1f",
   "metadata": {},
   "source": [
    "## Candidates based on postal codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9a776",
   "metadata": {},
   "source": [
    "Based on the interaction matrix we can generate samples/candidates for postal codes using a threshold score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9234837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5109"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_postal = list(preprocess.user_id_mapping.keys())\n",
    "len(sel_postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "db2559fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7582"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_articles = list(preprocess.item_id_mapping.keys())\n",
    "len(sel_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a9d392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with postal codes and items\n",
    "\n",
    "# first get all entries for dataframe\n",
    "scores = result.toarray().flatten()\n",
    "\n",
    "# select only the entries passing threshold\n",
    "threshold = 1.5\n",
    "idx = np.nonzero(scores > threshold)\n",
    "\n",
    "postal_codes_entries = np.repeat(sel_postal, len(articles))[idx]\n",
    "articles_entries = np.tile(sel_articles, len(sel_postal))[idx]\n",
    "score_entries = scores[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fec1fea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163.75611665688"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amount of candidates per postal code\n",
    "postal_codes_entries.size / len(sel_postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a00972bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe that contains most interesting articles per postal code, by score\n",
    "postal_scores = pd.DataFrame({\"postal_code\": postal_codes_entries,\n",
    "                             \"article_id\": articles_entries,\n",
    "                             \"score\": score_entries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dc2b7991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get customer postal code pairs\n",
    "customer_postal = customers[[\"customer_id\", \"postal_code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa420d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a unique transaction per user with postal code information\n",
    "unique_transactions_postal = pd.merge(test_set_transactions, customer_postal, on=\"customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1a069389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate candidates: for each postal code, assign article candidates with score\n",
    "postal_candidates = pd.merge(unique_transactions_postal, postal_scores, on=\"postal_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1131caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean price and add info to candidates\n",
    "overall_mean_price = transactions \\\n",
    "    .groupby('article_id')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ca91c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add price information, temporarily drop score and postal code for concatenation\n",
    "postal_candidates = pd.merge(postal_candidates, overall_mean_price, on=\"article_id\")\n",
    "postal_candidates.drop(columns=[\"score\", \"postal_code\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5d9881c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>week</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>48202911737860740</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>372860024</td>\n",
       "      <td>0.012065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>48202911737860740</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>372860024</td>\n",
       "      <td>0.012065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>48202911737860740</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>372860024</td>\n",
       "      <td>0.012065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>48202911737860740</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>372860024</td>\n",
       "      <td>0.012065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>263518441120604598</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>372860024</td>\n",
       "      <td>0.012065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638560</th>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>2113435388202881281</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>638899001</td>\n",
       "      <td>0.030492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638561</th>\n",
       "      <td>2020-08-29</td>\n",
       "      <td>4137185423853919351</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>638899001</td>\n",
       "      <td>0.030492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638562</th>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>14811029570079169435</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>560047002</td>\n",
       "      <td>0.012792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638563</th>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>3279808540341119399</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>560047002</td>\n",
       "      <td>0.012792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638564</th>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>12622464298019681449</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>560047002</td>\n",
       "      <td>0.012792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6638565 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             t_dat           customer_id  sales_channel_id  week  article_id  \\\n",
       "0       2020-07-15     48202911737860740                 2   105   372860024   \n",
       "1       2020-07-15     48202911737860740                 2   105   372860024   \n",
       "2       2020-07-15     48202911737860740                 2   105   372860024   \n",
       "3       2020-07-15     48202911737860740                 2   105   372860024   \n",
       "4       2020-07-16    263518441120604598                 2   105   372860024   \n",
       "...            ...                   ...               ...   ...         ...   \n",
       "6638560 2020-08-23   2113435388202881281                 2   105   638899001   \n",
       "6638561 2020-08-29   4137185423853919351                 2   105   638899001   \n",
       "6638562 2020-08-14  14811029570079169435                 1   105   560047002   \n",
       "6638563 2020-08-19   3279808540341119399                 2   105   560047002   \n",
       "6638564 2020-09-07  12622464298019681449                 2   105   560047002   \n",
       "\n",
       "            price  \n",
       "0        0.012065  \n",
       "1        0.012065  \n",
       "2        0.012065  \n",
       "3        0.012065  \n",
       "4        0.012065  \n",
       "...           ...  \n",
       "6638560  0.030492  \n",
       "6638561  0.030492  \n",
       "6638562  0.012792  \n",
       "6638563  0.012792  \n",
       "6638564  0.012792  \n",
       "\n",
       "[6638565 rows x 6 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postal_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc731c",
   "metadata": {},
   "source": [
    "### Combine with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6682a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['purchased'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9ccda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine transactions, negative samples and candidates\n",
    "data = pd.concat([transactions, repurchase_samples, bestseller_samples, postal_candidates])\n",
    "data.purchased.fillna(0, inplace=True)\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "    on=['week', 'article_id'],\n",
    "    how='left'\n",
    ")\n",
    "data.fillna(999, inplace=True)\n",
    "data = data[data.week != data.week.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ea45d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ae22a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add article and customer info\n",
    "data = pd.merge(data, articles, on='article_id', how='left')\n",
    "data = pd.merge(data, customers, on='customer_id', how='left')\n",
    "data = pd.merge(data, postal_scores, on=[\"postal_code\", \"article_id\"], how=\"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8b7dca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "367abbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train = data[data.week != test_week]\n",
    "test = data[data.week==test_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2bd84c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9eeb1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'score', 'bestseller_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1694763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9cb9b5",
   "metadata": {},
   "source": [
    "### Baseline and postal scores with ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "82ceb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "077e4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a41d7d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.893460\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.196473\n",
      "[LightGBM] [Debug] init for col-wise cost 0.236309 seconds, init for row-wise cost 0.387230 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.362414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1338\n",
      "[LightGBM] [Info] Number of data points in the train set: 11638535, number of used features: 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n"
     ]
    }
   ],
   "source": [
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bc81b58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestseller_rank 0.9990015743165809\n",
      "age 0.0002330120343692021\n",
      "article_id 0.00016838111819779592\n",
      "garment_group_no 0.00014286846237975996\n",
      "department_no 9.392537128593108e-05\n",
      "product_type_no 8.760091539015257e-05\n",
      "section_no 7.22913140521762e-05\n",
      "postal_code 6.847171178016363e-05\n",
      "club_member_status 6.311055935375977e-05\n",
      "colour_group_code 5.1134378800232604e-05\n",
      "perceived_colour_value_id 1.7629817809927905e-05\n",
      "fashion_news_frequency 0.0\n",
      "Active 0.0\n",
      "FN 0.0\n",
      "score 0.0\n",
      "index_group_no 0.0\n",
      "index_code 0.0\n",
      "perceived_colour_master_id 0.0\n",
      "graphical_appearance_no 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6559e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "# order predicted articles per user\n",
    "user_predicted_articles = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "# get bestsellers from last week before test week\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9349ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fc78e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform predictions to correct format for submission\n",
    "preds = []\n",
    "for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "    pred = user_predicted_articles.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])\n",
    "\n",
    "preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "sub.prediction = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1fa89b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline submission\n",
    "sub_name = 'postal_scores_submission'\n",
    "sub.to_csv(f'{sub_name}.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e4f46",
   "metadata": {},
   "source": [
    "## Postal score rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f54c18",
   "metadata": {},
   "source": [
    "The previous section only made a small improvement on the baseline, so small it can be dismissed. The problem here is that only for 372 postal codes candidates extra candidates are being generated because of the threshold. Besides that, all the postal codes/item pairs that have been filtered during preprocessing receive a placeholder score of 0. What might be more interesting is to instead include a rank per postal code of the 12 best items based on their score from the interaction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cf090832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 12 articles per postal code\n",
    "scores = result.toarray()\n",
    "idx = np.argpartition(scores, -12)[:, -12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fc860505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort every row so that best score comes first\n",
    "sorted_idx = []\n",
    "for i, row in enumerate(idx):\n",
    "    idx_row = np.argsort(scores[i, row])\n",
    "    sorted_idx.append(idx_row[::-1])\n",
    "sorted_idx = np.array(sorted_idx)\n",
    "rows = [[_ for i in range(12)] for _ in range(len(scores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "258acde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flattened list of scores\n",
    "scores = scores[rows, idx[rows, sorted_idx]].flatten()\n",
    "postal_codes_entries = np.repeat(sel_postal, 12)\n",
    "articles_entries = np.array(sel_articles)[idx.flatten()]\n",
    "ranks = np.array([_ for _ in range(1, 13)] * len(sel_postal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a933eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into dataframe\n",
    "postal_ranks = pd.DataFrame({\"postal_code\": postal_codes_entries,\n",
    "                             \"article_id\": articles_entries,\n",
    "                             \"score\": scores,\n",
    "                             \"postal_rank\": ranks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9f73e674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>article_id</th>\n",
       "      <th>score</th>\n",
       "      <th>postal_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5499</td>\n",
       "      <td>751471001</td>\n",
       "      <td>2.416172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5499</td>\n",
       "      <td>759871002</td>\n",
       "      <td>2.408906</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5499</td>\n",
       "      <td>685814001</td>\n",
       "      <td>2.366963</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5499</td>\n",
       "      <td>372860001</td>\n",
       "      <td>2.223141</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5499</td>\n",
       "      <td>484398001</td>\n",
       "      <td>2.212671</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61303</th>\n",
       "      <td>298429</td>\n",
       "      <td>760084003</td>\n",
       "      <td>2.436683</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61304</th>\n",
       "      <td>298429</td>\n",
       "      <td>610776002</td>\n",
       "      <td>2.407167</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61305</th>\n",
       "      <td>298429</td>\n",
       "      <td>706016001</td>\n",
       "      <td>2.403442</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61306</th>\n",
       "      <td>298429</td>\n",
       "      <td>759871002</td>\n",
       "      <td>2.346993</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61307</th>\n",
       "      <td>298429</td>\n",
       "      <td>179123001</td>\n",
       "      <td>2.310904</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61308 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       postal_code  article_id     score  postal_rank\n",
       "0             5499   751471001  2.416172            1\n",
       "1             5499   759871002  2.408906            2\n",
       "2             5499   685814001  2.366963            3\n",
       "3             5499   372860001  2.223141            4\n",
       "4             5499   484398001  2.212671            5\n",
       "...            ...         ...       ...          ...\n",
       "61303       298429   760084003  2.436683            8\n",
       "61304       298429   610776002  2.407167            9\n",
       "61305       298429   706016001  2.403442           10\n",
       "61306       298429   759871002  2.346993           11\n",
       "61307       298429   179123001  2.310904           12\n",
       "\n",
       "[61308 rows x 4 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postal_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ba3f8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate candidates: for each postal code, assign article candidates with score\n",
    "postal_candidates = pd.merge(unique_transactions_postal, postal_ranks, on=\"postal_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "adbae841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean price and add info to candidates\n",
    "overall_mean_price = transactions \\\n",
    "    .groupby('article_id')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9d4a482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add price information, temporarily drop score and postal code for concatenation\n",
    "postal_candidates = pd.merge(postal_candidates, overall_mean_price, on=\"article_id\")\n",
    "postal_candidates.drop(columns=[\"score\", \"postal_code\", \"postal_rank\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a0dcc786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>week</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>1456826891333599</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>711053003</td>\n",
       "      <td>0.013172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>3729806434627100156</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>711053003</td>\n",
       "      <td>0.013172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>6764689423798104216</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>711053003</td>\n",
       "      <td>0.013172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>13035302529127383758</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>711053003</td>\n",
       "      <td>0.013172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-25</td>\n",
       "      <td>938841704694046555</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>711053003</td>\n",
       "      <td>0.013172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396480</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>9320718993689417505</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>550309001</td>\n",
       "      <td>0.014995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396481</th>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>17875119368269053830</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>777148006</td>\n",
       "      <td>0.020181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396482</th>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>17875119368269053830</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>790167001</td>\n",
       "      <td>0.038328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396483</th>\n",
       "      <td>2020-09-06</td>\n",
       "      <td>3267368325910590416</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>707135001</td>\n",
       "      <td>0.022017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396484</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>10983990250086887848</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>774148004</td>\n",
       "      <td>0.018279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396485 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_dat           customer_id  sales_channel_id  week  article_id  \\\n",
       "0      2020-07-15      1456826891333599                 1   105   711053003   \n",
       "1      2020-07-16   3729806434627100156                 1   105   711053003   \n",
       "2      2020-07-21   6764689423798104216                 2   105   711053003   \n",
       "3      2020-07-21  13035302529127383758                 2   105   711053003   \n",
       "4      2020-07-25    938841704694046555                 1   105   711053003   \n",
       "...           ...                   ...               ...   ...         ...   \n",
       "396480 2020-08-31   9320718993689417505                 2   105   550309001   \n",
       "396481 2020-09-05  17875119368269053830                 2   105   777148006   \n",
       "396482 2020-09-05  17875119368269053830                 2   105   790167001   \n",
       "396483 2020-09-06   3267368325910590416                 2   105   707135001   \n",
       "396484 2020-09-14  10983990250086887848                 2   105   774148004   \n",
       "\n",
       "           price  \n",
       "0       0.013172  \n",
       "1       0.013172  \n",
       "2       0.013172  \n",
       "3       0.013172  \n",
       "4       0.013172  \n",
       "...          ...  \n",
       "396480  0.014995  \n",
       "396481  0.020181  \n",
       "396482  0.038328  \n",
       "396483  0.022017  \n",
       "396484  0.018279  \n",
       "\n",
       "[396485 rows x 6 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postal_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46f065",
   "metadata": {},
   "source": [
    "### Combine again with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "882516cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['purchased'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0ada6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine transactions, negative samples and candidates\n",
    "data = pd.concat([transactions, repurchase_samples, bestseller_samples, postal_candidates])\n",
    "data.purchased.fillna(0, inplace=True)\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "    on=['week', 'article_id'],\n",
    "    how='left'\n",
    ")\n",
    "data.fillna(999, inplace=True)\n",
    "data = data[data.week != data.week.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bef35fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6580e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add article and customer info\n",
    "data = pd.merge(data, articles, on='article_id', how='left')\n",
    "data = pd.merge(data, customers, on='customer_id', how='left')\n",
    "data = pd.merge(data, postal_ranks, on=[\"postal_code\", \"article_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bcfb548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.score.fillna(0, inplace=True)\n",
    "data[\"postal_rank\"].fillna(999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "96ff3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4ad994bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train = data[data.week != test_week]\n",
    "test = data[data.week==test_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4ab5e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3bfa735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'score', 'postal_rank', 'bestseller_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6bf5a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c447acf",
   "metadata": {},
   "source": [
    "### Baseline and postal scores with ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a53343e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0c51d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1e2c9828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.920645\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.237033\n",
      "[LightGBM] [Debug] init for col-wise cost 0.225499 seconds, init for row-wise cost 0.392378 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.325940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1348\n",
      "[LightGBM] [Info] Number of data points in the train set: 11381612, number of used features: 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n"
     ]
    }
   ],
   "source": [
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9bd217bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestseller_rank 0.9989805519216203\n",
      "age 0.00024136038957903926\n",
      "article_id 0.00017160828400263902\n",
      "garment_group_no 0.0001448188543340445\n",
      "department_no 9.637421875769266e-05\n",
      "product_type_no 9.014783292439592e-05\n",
      "section_no 7.067204716548531e-05\n",
      "postal_code 6.792197441369627e-05\n",
      "club_member_status 6.519780240033951e-05\n",
      "colour_group_code 5.358754121027148e-05\n",
      "perceived_colour_value_id 1.775913359216025e-05\n",
      "FN 0.0\n",
      "Active 0.0\n",
      "postal_rank 0.0\n",
      "score 0.0\n",
      "index_code 0.0\n",
      "perceived_colour_master_id 0.0\n",
      "graphical_appearance_no 0.0\n",
      "fashion_news_frequency 0.0\n",
      "index_group_no 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "700a1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "# order predicted articles per user\n",
    "user_predicted_articles = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "# get bestsellers from last week before test week\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "47151a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "108f053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform predictions to correct format for submission\n",
    "preds = []\n",
    "for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "    pred = user_predicted_articles.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])\n",
    "\n",
    "preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "sub.prediction = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9092542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline submission\n",
    "sub_name = 'postal_ranks_submission'\n",
    "sub.to_csv(f'{sub_name}.csv.gz', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
