{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This code is from [https://github.com/radekosmulski/personalized_fashion_recs](https://github.com/radekosmulski/personalized_fashion_recs) with extra options and some improvements.\n",
    "Comments explaining the original notebook code were added by me and Arno Troch\n",
    "\n",
    "First code cell contains hardcoded variables that you can change.\n",
    "\n",
    "Added functionality:\n",
    " 1. Optionally train on past X weeks and past X weeks of last year (not recommended)\n",
    "2. If a sample is generated by multiple methods, count by how many methods it was generated\n",
    "3. Scale data\n",
    "\n",
    "Results:\n",
    "1. 0.02087 -> 0.01397\n",
    "2. 0.02087 -> 0.02114\n",
    "3. No difference\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "LGBMBoostingType = 'dart'\n",
    "preprocess = '-1'  # If you get an error saying that the dataset is not found, make sure to first run part 1 with the same type of preprocessing as indicated here\n",
    "bestsellerFiller = 999  # If item not in top 12 bestsellers of a week, fill with this value\n",
    "transactionBackXWeeks = 10  # Size of train+test set\n",
    "prevYear = ''  # if SkipYear, train on transactionBackXWeeks and transactionBackXWeeks but last year. Very poor results, not recommended.\n",
    "assert LGBMBoostingType in ['gbdt','dart','goss','rf']\n",
    "assert preprocess in ['-1','edited']\n",
    "assert prevYear in [\"\",\"SkipYear\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ad823629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5687e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "13fc4a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.28 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transactions = pd.read_parquet(f'../data/transactions_train_{preprocess}.parquet')\n",
    "customers = pd.read_parquet(f'../data/customers_{preprocess}.parquet')\n",
    "articles = pd.read_parquet(f'../data/articles_{preprocess}.parquet')\n",
    "# sample = 0.05\n",
    "# transactions = pd.read_parquet(f'../data/transactions_train_sample_{sample}.parquet')\n",
    "# customers = pd.read_parquet(f'../data/customers_sample_{sample}.parquet')\n",
    "# articles = pd.read_parquet(f'../data/articles_train_sample_{sample}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "36a4cad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 95  96  97  98  99 100 101 102 103 104]\n",
      "[43 44 45 46 47 48 49 50 51 52]\n"
     ]
    }
   ],
   "source": [
    "test_week = transactions.week.max() + 1\n",
    "if prevYear == 'SkipYear':\n",
    "    transactions3 = transactions[transactions.week > transactions.week.max() - transactionBackXWeeks]\n",
    "    transactions2 = transactions[(transactions.week.max()-52>=transactions.week) & (transactions.week >transactions.week.max() - transactionBackXWeeks-52)] # EDITED\n",
    "    print(transactions3['week'].unique())\n",
    "    print(transactions2['week'].unique())\n",
    "    transactions = pd.concat([transactions3,transactions2])\n",
    "else:\n",
    "    transactions = transactions[transactions.week > transactions.week.max() - transactionBackXWeeks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56263b7a",
   "metadata": {},
   "source": [
    "# Generating candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd43fcd",
   "metadata": {},
   "source": [
    "### Last purchase candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ca3b5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c2weeks = transactions.groupby('customer_id')['week'].unique()\n",
    "\n",
    "c2weeks2shifted_weeks = {}\n",
    "\n",
    "for c_id, weeks in c2weeks.items():\n",
    "    c2weeks2shifted_weeks[c_id] = {}\n",
    "    for i in range(weeks.shape[0]-1):\n",
    "        c2weeks2shifted_weeks[c_id][weeks[i]] = weeks[i+1]\n",
    "    c2weeks2shifted_weeks[c_id][weeks[-1]] = test_week\n",
    "\n",
    "candidates_last_purchase = transactions.copy()\n",
    "\n",
    "weeks = []\n",
    "for i, (c_id, week) in enumerate(zip(transactions['customer_id'], transactions['week'])):\n",
    "    weeks.append(c2weeks2shifted_weeks[c_id][week])\n",
    "\n",
    "# Candidate for week X: item bought in previous purchase week\n",
    "candidates_last_purchase.week=weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              t_dat           customer_id  article_id     price  \\\n",
      "29030503 2020-07-15       272412481300040   778064028  0.008458   \n",
      "29030504 2020-07-15       272412481300040   816592008  0.016932   \n",
      "29030505 2020-07-15       272412481300040   621381021  0.033881   \n",
      "29030506 2020-07-15       272412481300040   817477003  0.025407   \n",
      "29030507 2020-07-15       272412481300040   899088002  0.025407   \n",
      "...             ...                   ...         ...       ...   \n",
      "16957605 2019-09-24  18443039671924470908   792521006  0.016932   \n",
      "16943168 2019-09-24  18445164350380731040   733099001  0.016932   \n",
      "16928374 2019-09-24  18445187566593112488   787028001  0.101678   \n",
      "16928375 2019-09-24  18445187566593112488   787028001  0.101678   \n",
      "16928376 2019-09-24  18445187566593112488   786818001  0.101678   \n",
      "\n",
      "          sales_channel_id  week  \n",
      "29030503                 1    96  \n",
      "29030504                 1    96  \n",
      "29030505                 1    96  \n",
      "29030506                 1    96  \n",
      "29030507                 1    96  \n",
      "...                    ...   ...  \n",
      "16957605                 2   105  \n",
      "16943168                 1   105  \n",
      "16928374                 2   105  \n",
      "16928375                 2   105  \n",
      "16928376                 2   105  \n",
      "\n",
      "[5757868 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(candidates_last_purchase)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "4077cf9c",
   "metadata": {},
   "source": [
    "### Bestsellers candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b794ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   customer_id  article_id  week  importance\n",
      "0               23962613628581   448509014   105           1\n",
      "1               23962613628581   484398001    45           1\n",
      "2               23962613628581   554811008    45           1\n",
      "3               23962613628581   564786001    45           1\n",
      "4               23962613628581   594264006    43           1\n",
      "...                        ...         ...   ...         ...\n",
      "33686305  18446737527580148316   923758001   104           1\n",
      "33686306  18446737527580148316   923758001   105           1\n",
      "33686307  18446737527580148316   924243001   104           1\n",
      "33686308  18446737527580148316   924243001   105           1\n",
      "33686309  18446737527580148316   924243002   105           1\n",
      "\n",
      "[33686310 rows x 4 columns]\n",
      "0\n",
      "74\n",
      "1.0424481636605494\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": "       t_dat      customer_id  article_id     price  sales_channel_id  week  \\\n0 2020-07-15  272412481300040   778064028  0.008458                 1    95   \n1 2020-07-15  272412481300040   816592008  0.016932                 1    95   \n2 2020-07-15  272412481300040   621381021  0.033881                 1    95   \n3 2020-07-15  272412481300040   817477003  0.025407                 1    95   \n4 2020-07-15  272412481300040   899088002  0.025407                 1    95   \n\n   purchased  importance  \n0        1.0           1  \n1        1.0           1  \n2        1.0           1  \n3        1.0           1  \n4        1.0           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean price PER ITEM PER WEEK\n",
    "mean_price = transactions \\\n",
    "    .groupby(['week', 'article_id'])['price'].mean()\n",
    "\n",
    "# bestseller rank doet niets: ranking is belangrijk om de bestsellers te vinden, maar de kolom zelf mag weg\n",
    "# For each week, list of ranked 12 bestsellers\n",
    "sales = transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1\n",
    "# Per week lijst van customers die IETS gekocht hebben\n",
    "unique_transactions = transactions \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()\n",
    "\n",
    "# Per week lijst van customers die IETS gekocht hebben\n",
    "# MERGE\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "\n",
    "# Per week, per customer die iets gekocht heeft, de 12 bestverkochte uit DE (algemeen) vorige week\n",
    "candidates_bestsellers = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")\n",
    "\n",
    "# unique_transactions = Per week lijst van customers die IETS gekocht hebben\n",
    "# Voor elke customer waar we iets over weten en dus een voorspelling van willen doen, houden we 1 keer de customer id over en zetten we de week op test_week, want dat is wanneer we willen voorspellen wat hij koopt\n",
    "test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "test_set_transactions.week = test_week\n",
    "\n",
    "\n",
    "# Voor elke customer waar we iets over weten en dus een voorspelling van willen doen, houden we 1 keer de customer id over en zetten we de week op test_week, want dat is wanneer we willen voorspellen wat hij koopt\n",
    "# MERGE\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "\n",
    "# Resultaat: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek\n",
    "candidates_bestsellers_test_week = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")\n",
    "\n",
    "# bestseller rank doet niets: ranking is belangrijk om de bestsellers te vinden, maar de kolom zelf mag weg\n",
    "\n",
    "# Per week, per customer die iets gekocht heeft, de 12 bestverkochte uit DE (algemeen) vorige week\n",
    "# Resultaat: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek\n",
    "\n",
    "candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)\n",
    "\n",
    "# Combining transactions and candidates / negative examples\n",
    "\n",
    "transactions['purchased'] = 1\n",
    "\n",
    "\n",
    "# candidates_last_purchase: Candidate for week X: item bought in previous purchase week\n",
    "# candidates_bestsellers: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek\n",
    "# transactions: letterlijk gewoon transactions\n",
    "data = pd.concat([transactions, candidates_last_purchase, candidates_bestsellers])\n",
    "data.purchased.fillna(0, inplace=True)\n",
    "\n",
    "# Voor elke week: kijk alle keren dat customer het artikel koopt OF voorgesteld krijgt, en hou indien gekocht enkel de rij met purchased 1\n",
    "# Opmerking: candidates voor week 105 zijn allemaal purchased==0\n",
    "brak = data.groupby(['customer_id', 'article_id', 'week']).size().reset_index(name=\"importance\")\n",
    "print(brak)\n",
    "data.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    brak,\n",
    "    on=['customer_id', 'article_id', 'week']\n",
    ")\n",
    "\n",
    "data.purchased.mean()\n",
    "print(data[\"importance\"].isna().sum())\n",
    "print(data[\"importance\"].max())\n",
    "print(data[\"importance\"].mean())\n",
    "print(data[\"importance\"].min())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22588375",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac183274",
   "metadata": {},
   "source": [
    "### Add bestseller information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f28957eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# van echte transacties: bestseller onbekend, check candidates om te kijken of er toen wel bestseller rank was. Zo nee, vul later met fillna\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "    on=['week', 'article_id'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3e7d3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijder eerste week omdat er voor eerste week geen bestsellers_previous_week is\n",
    "data = data[data.week != data.week.min()]  # Presumably to make sure no data of an incomplete week is included?\n",
    "# Indien geen bestseller: keislecht verkocht\n",
    "data.bestseller_rank.fillna(bestsellerFiller, inplace=True)  # EDITED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b5fdc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per customer per week alle transacties en/of candidates\n",
    "\n",
    "# Steek bij elke aankoop alle info over gekocht article erbij\n",
    "data = pd.merge(data, articles, on='article_id', how='left')\n",
    "# Steek bij elke aankoop alle info over customer erbij\n",
    "data = pd.merge(data, customers, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9e3a737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorteer eerst op week, dan per week op customer\n",
    "data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "data.head()\n",
    "\n",
    "columns_to_use = ['product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'bestseller_rank','importance']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "data[columns_to_use] = scaler.fit_transform(data[columns_to_use])\n",
    "\n",
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'bestseller_rank','importance']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d83b869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              t_dat     customer_id  article_id     price  sales_channel_id  \\\n23285066 2019-08-03  23962613628581   732842001  0.067780                 1   \n23285067 2019-07-18  23962613628581   924243001  0.041535                 2   \n23285068 2019-07-18  23962613628581   924243002  0.041877                 2   \n23285069 2019-07-18  23962613628581   918522001  0.041435                 2   \n23285070 2019-07-18  23962613628581   923758001  0.033462                 2   \n\n          week  purchased  importance  bestseller_rank  product_code  ...  \\\n23285066   105        0.0   -0.157588         1.569887        732842  ...   \n23285067   105        0.0   -0.157588        -0.649132        924243  ...   \n23285068   105        0.0   -0.157588        -0.646908        924243  ...   \n23285069   105        0.0   -0.157588        -0.644685        918522  ...   \n23285070   105        0.0   -0.157588        -0.642462        923758  ...   \n\n          section_name  garment_group_no  garment_group_name  detail_desc  \\\n23285066            37          0.992958                  11          780   \n23285067             0         -0.989949                   3        13007   \n23285068             0         -0.989949                   3        13007   \n23285069             0         -0.989949                   3        28633   \n23285070             0          0.077770                   6        27869   \n\n                FN    Active  club_member_status  fashion_news_frequency  \\\n23285066 -0.877122 -0.865376           -0.119615               -0.852173   \n23285067 -0.877122 -0.865376           -0.119615               -0.852173   \n23285068 -0.877122 -0.865376           -0.119615               -0.852173   \n23285069 -0.877122 -0.865376           -0.119615               -0.852173   \n23285070 -0.877122 -0.865376           -0.119615               -0.852173   \n\n               age  postal_code  \n23285066 -0.108947     -0.67849  \n23285067 -0.108947     -0.67849  \n23285068 -0.108947     -0.67849  \n23285069 -0.108947     -0.67849  \n23285070 -0.108947     -0.67849  \n\n[5 rows x 39 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n      <th>importance</th>\n      <th>bestseller_rank</th>\n      <th>product_code</th>\n      <th>...</th>\n      <th>section_name</th>\n      <th>garment_group_no</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n      <th>FN</th>\n      <th>Active</th>\n      <th>club_member_status</th>\n      <th>fashion_news_frequency</th>\n      <th>age</th>\n      <th>postal_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23285066</th>\n      <td>2019-08-03</td>\n      <td>23962613628581</td>\n      <td>732842001</td>\n      <td>0.067780</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>-0.157588</td>\n      <td>1.569887</td>\n      <td>732842</td>\n      <td>...</td>\n      <td>37</td>\n      <td>0.992958</td>\n      <td>11</td>\n      <td>780</td>\n      <td>-0.877122</td>\n      <td>-0.865376</td>\n      <td>-0.119615</td>\n      <td>-0.852173</td>\n      <td>-0.108947</td>\n      <td>-0.67849</td>\n    </tr>\n    <tr>\n      <th>23285067</th>\n      <td>2019-07-18</td>\n      <td>23962613628581</td>\n      <td>924243001</td>\n      <td>0.041535</td>\n      <td>2</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>-0.157588</td>\n      <td>-0.649132</td>\n      <td>924243</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-0.989949</td>\n      <td>3</td>\n      <td>13007</td>\n      <td>-0.877122</td>\n      <td>-0.865376</td>\n      <td>-0.119615</td>\n      <td>-0.852173</td>\n      <td>-0.108947</td>\n      <td>-0.67849</td>\n    </tr>\n    <tr>\n      <th>23285068</th>\n      <td>2019-07-18</td>\n      <td>23962613628581</td>\n      <td>924243002</td>\n      <td>0.041877</td>\n      <td>2</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>-0.157588</td>\n      <td>-0.646908</td>\n      <td>924243</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-0.989949</td>\n      <td>3</td>\n      <td>13007</td>\n      <td>-0.877122</td>\n      <td>-0.865376</td>\n      <td>-0.119615</td>\n      <td>-0.852173</td>\n      <td>-0.108947</td>\n      <td>-0.67849</td>\n    </tr>\n    <tr>\n      <th>23285069</th>\n      <td>2019-07-18</td>\n      <td>23962613628581</td>\n      <td>918522001</td>\n      <td>0.041435</td>\n      <td>2</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>-0.157588</td>\n      <td>-0.644685</td>\n      <td>918522</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-0.989949</td>\n      <td>3</td>\n      <td>28633</td>\n      <td>-0.877122</td>\n      <td>-0.865376</td>\n      <td>-0.119615</td>\n      <td>-0.852173</td>\n      <td>-0.108947</td>\n      <td>-0.67849</td>\n    </tr>\n    <tr>\n      <th>23285070</th>\n      <td>2019-07-18</td>\n      <td>23962613628581</td>\n      <td>923758001</td>\n      <td>0.033462</td>\n      <td>2</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>-0.157588</td>\n      <td>-0.642462</td>\n      <td>923758</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.077770</td>\n      <td>6</td>\n      <td>27869</td>\n      <td>-0.877122</td>\n      <td>-0.865376</td>\n      <td>-0.119615</td>\n      <td>-0.852173</td>\n      <td>-0.108947</td>\n      <td>-0.67849</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 39 columns</p>\n</div>"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Niet trainen op laatste week want anders hebben we geen test set\n",
    "train = data[data.week != test_week]\n",
    "# Laatste week, indien item in beide candidate sets, drop duplicates.\n",
    "test = data[data.week==test_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "71d57fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              t_dat           customer_id  article_id     price  \\\n",
      "0        2019-07-27        77117344919861   471714008  0.007983   \n",
      "1        2019-07-27        77117344919861   763037001  0.040034   \n",
      "2        2019-07-22        77117344919861   780918001  0.013203   \n",
      "3        2019-07-22        77117344919861   663498003  0.033034   \n",
      "4        2019-07-22        77117344919861   755458008  0.041288   \n",
      "...             ...                   ...         ...       ...   \n",
      "23285050 2020-09-21  18446737527580148316   547780001  0.023712   \n",
      "23285051 2020-09-21  18446737527580148316   763988001  0.023712   \n",
      "23285052 2020-09-21  18446737527580148316   763988003  0.023712   \n",
      "23285053 2020-09-21  18446737527580148316   547780040  0.023712   \n",
      "23285054 2020-09-21  18446737527580148316   909370001  0.032947   \n",
      "\n",
      "          sales_channel_id  week  purchased  importance  bestseller_rank  \\\n",
      "0                        2    44        1.0    3.663422         1.569887   \n",
      "1                        2    44        1.0    7.484431         1.569887   \n",
      "2                        2    44        0.0    3.663422         1.569887   \n",
      "3                        2    44        0.0   -0.157588         1.569887   \n",
      "4                        2    44        0.0   -0.157588         1.569887   \n",
      "...                    ...   ...        ...         ...              ...   \n",
      "23285050                 2   104        1.0   -0.157588         1.569887   \n",
      "23285051                 2   104        1.0   -0.157588         1.569887   \n",
      "23285052                 2   104        1.0   -0.157588         1.569887   \n",
      "23285053                 2   104        1.0   -0.157588         1.569887   \n",
      "23285054                 2   104        0.0   -0.157588        -0.649132   \n",
      "\n",
      "          product_code  ...  section_name  garment_group_no  \\\n",
      "0               471714  ...            33          2.365741   \n",
      "1               763037  ...             7          0.077770   \n",
      "2               780918  ...             9          1.450552   \n",
      "3               663498  ...            13         -0.074761   \n",
      "4               755458  ...            10          2.365741   \n",
      "...                ...  ...           ...               ...   \n",
      "23285050        547780  ...            27         -1.142481   \n",
      "23285051        763988  ...            16         -1.142481   \n",
      "23285052        763988  ...            16         -1.142481   \n",
      "23285053        547780  ...            27         -1.142481   \n",
      "23285054        909370  ...             0          2.060678   \n",
      "\n",
      "          garment_group_name  detail_desc        FN    Active  \\\n",
      "0                         16          635 -0.877122 -0.865376   \n",
      "1                          6         8832 -0.877122 -0.865376   \n",
      "2                          1        38528 -0.877122 -0.865376   \n",
      "3                          5         5579 -0.877122 -0.865376   \n",
      "4                         16        17103 -0.877122 -0.865376   \n",
      "...                      ...          ...       ...       ...   \n",
      "23285050                   2          271  1.140093  1.155568   \n",
      "23285051                   2         1107  1.140093  1.155568   \n",
      "23285052                   2         1107  1.140093  1.155568   \n",
      "23285053                   2          271  1.140093  1.155568   \n",
      "23285054                  19        28617  1.140093  1.155568   \n",
      "\n",
      "          club_member_status  fashion_news_frequency       age  postal_code  \n",
      "0                  -0.119615               -0.852173  0.757471    -0.849414  \n",
      "1                  -0.119615               -0.852173  0.757471    -0.849414  \n",
      "2                  -0.119615               -0.852173  0.757471    -0.849414  \n",
      "3                  -0.119615               -0.852173  0.757471    -0.849414  \n",
      "4                  -0.119615               -0.852173  0.757471    -0.849414  \n",
      "...                      ...                     ...       ...          ...  \n",
      "23285050           -0.119615                1.123677  1.768291    -0.029775  \n",
      "23285051           -0.119615                1.123677  1.768291    -0.029775  \n",
      "23285052           -0.119615                1.123677  1.768291    -0.029775  \n",
      "23285053           -0.119615                1.123677  1.768291    -0.029775  \n",
      "23285054           -0.119615                1.123677  1.768291    -0.029775  \n",
      "\n",
      "[6811288 rows x 39 columns]\n",
      "[20 18 22 ... 14 19 16]\n",
      "1\n",
      "162\n",
      "1396869\n"
     ]
    }
   ],
   "source": [
    "print(train.groupby(['week', 'customer_id']).head())\n",
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values\n",
    "print(train_baskets)\n",
    "print(train_baskets.min())\n",
    "print(train_baskets.max())\n",
    "print(len(train_baskets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "562146df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 978 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b26b0a",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "17079af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "00b6186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker=LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=LGBMBoostingType,\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "31408339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.972335\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.102351\n",
      "[LightGBM] [Debug] init for col-wise cost 0.127235 seconds, init for row-wise cost 0.334982 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.352834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1111\n",
      "[LightGBM] [Info] Number of data points in the train set: 23285066, number of used features: 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "CPU times: total: 36.5 s\n",
      "Wall time: 9.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b7396bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestseller_rank 0.9607124084765173\n",
      "importance 0.03801438353073763\n",
      "age 0.00034996033614452917\n",
      "product_type_no 0.00030221364492572135\n",
      "article_id 0.00021790279307392274\n",
      "department_no 0.00013071359975942156\n",
      "postal_code 0.00010661712071155978\n",
      "club_member_status 0.00010304844956410496\n",
      "garment_group_no 6.275204856586346e-05\n",
      "Active 0.0\n",
      "FN 0.0\n",
      "fashion_news_frequency 0.0\n",
      "index_group_no 0.0\n",
      "index_code 0.0\n",
      "perceived_colour_master_id 0.0\n",
      "perceived_colour_value_id 0.0\n",
      "colour_group_code 0.0\n",
      "graphical_appearance_no 0.0\n",
      "section_no 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb34139",
   "metadata": {},
   "source": [
    "# Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9fa10874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.62 s\n",
      "Wall time: 9.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "c_id2predicted_article_ids = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e576d90",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "eb1c56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "03d79b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.8 s\n",
      "Wall time: 8.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = []\n",
    "\n",
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)\n",
    "\n",
    "\n",
    "for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "    pred = c_id2predicted_article_ids.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e4ed109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "sub.prediction = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "245ce774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "basic_model_submission_dart_fillna-1bestsellerFiller999_weeks10_importanceSkipYear\n"
     ]
    }
   ],
   "source": [
    "sub_name = 'basic_model_submission_' +  str(LGBMBoostingType) + '_fillna' + str(preprocess) + 'bestsellerFiller' + str(bestsellerFiller) + \"_weeks\" + str(transactionBackXWeeks) + \"_importance\" + str(prevYear)\n",
    "sub.to_csv(f'../data/subs/{sub_name}.csv.gz', index=False)\n",
    "sub.to_csv(f'../data/subs/{sub_name}.csv', index=False)\n",
    "print(\"Done\")\n",
    "print(sub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fbb16d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c h-and-m-personalized-fashion-recommendations -f 'data/subs/{sub_name}.csv.gz' -m {sub_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
