{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This code is from [https://github.com/radekosmulski/personalized_fashion_recs](https://github.com/radekosmulski/personalized_fashion_recs) with some preprocessing changes/options. Cells that either gave general comments on the competition or ran a code cell only to view a variable have been removed.\n",
    "\n",
    "This notebook implements mostly memory-saving processing discussed in the early presentations: the data is converted to smaller data types."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# -1 fills customer na values with -1\n",
    "# edited instead fills them with zeros, or in case of age with the median\n",
    "fillna_values = 'edited'  # '-1' or 'edited'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# EDITED: the original code fetched this through\n",
    "# !wget https://raw.githubusercontent.com/benhamner/Metrics/master/Python/ml_metrics/average_precision.py\n",
    "# But windows doesn't have wget, so I copy-pasted it.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "# EDITED: k=10 to k=12\n",
    "def mapk(actual, predicted, k=12):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average precision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted\n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3ac989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# https://www.kaggle.com/c/h-and-m-personalized-fashion-recommendations/discussion/308635\n",
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)\n",
    "\n",
    "def article_id_str_to_int(series):\n",
    "    return series.astype('int32')\n",
    "\n",
    "def article_id_int_to_str(series):\n",
    "    return '0' + series.astype('str')\n",
    "\n",
    "class Categorize(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_examples=0):\n",
    "        self.min_examples = min_examples\n",
    "        self.categories = []\n",
    "        \n",
    "    def fit(self, X):\n",
    "        for i in range(X.shape[1]):\n",
    "            vc = X.iloc[:, i].value_counts()\n",
    "            self.categories.append(vc[vc > self.min_examples].index.tolist())\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = {X.columns[i]: pd.Categorical(X.iloc[:, i], categories=self.categories[i]).codes for i in range(X.shape[1])}\n",
    "        return pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cd3410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['article_id', 'product_code', 'prod_name', 'product_type_no',\n",
      "       'product_type_name', 'product_group_name', 'graphical_appearance_no',\n",
      "       'graphical_appearance_name', 'colour_group_code', 'colour_group_name',\n",
      "       'perceived_colour_value_id', 'perceived_colour_value_name',\n",
      "       'perceived_colour_master_id', 'perceived_colour_master_name',\n",
      "       'department_no', 'department_name', 'index_code', 'index_name',\n",
      "       'index_group_no', 'index_group_name', 'section_no', 'section_name',\n",
      "       'garment_group_no', 'garment_group_name', 'detail_desc'],\n",
      "      dtype='object')\n",
      "['Dark' 'Light' 'Dusty Light' 'Medium Dusty' 'Bright' 'Medium' 'Undefined'\n",
      " 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transactions = pd.read_csv('../data/transactions_train.csv', dtype={\"article_id\": \"str\"})\n",
    "customers = pd.read_csv('../data/customers.csv')\n",
    "articles = pd.read_csv('../data/articles.csv', dtype={\"article_id\": \"str\"})\n",
    "print(articles.columns)\n",
    "print(articles[\"perceived_colour_value_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dark' 'Light' 'Dusty Light' 'Medium Dusty' 'Bright' 'Medium' 'Undefined'\n",
      " 'Unknown']\n",
      "['Black' 'White' 'Off White' 'Light Beige' 'Beige' 'Grey' 'Light Blue'\n",
      " 'Light Grey' 'Dark Blue' 'Dark Grey' 'Pink' 'Dark Red' 'Greyish Beige'\n",
      " 'Light Orange' 'Silver' 'Gold' 'Light Pink' 'Dark Pink' 'Yellowish Brown'\n",
      " 'Blue' 'Light Turquoise' 'Yellow' 'Greenish Khaki' 'Dark Yellow'\n",
      " 'Other Pink' 'Dark Purple' 'Red' 'Transparent' 'Dark Green' 'Other Red'\n",
      " 'Turquoise' 'Dark Orange' 'Other' 'Orange' 'Dark Beige' 'Other Yellow'\n",
      " 'Light Green' 'Other Orange' 'Purple' 'Light Red' 'Light Yellow' 'Green'\n",
      " 'Light Purple' 'Dark Turquoise' 'Other Purple' 'Bronze/Copper'\n",
      " 'Other Turquoise' 'Other Green' 'Other Blue' 'Unknown']\n",
      "['Solid' 'Stripe' 'All over pattern' 'Melange' 'Transparent' 'Metallic'\n",
      " 'Application/3D' 'Denim' 'Colour blocking' 'Dot' 'Other structure'\n",
      " 'Contrast' 'Treatment' 'Check' 'Chambray' 'Front print'\n",
      " 'Glittering/Metallic' 'Mixed solid/pattern' 'Placement print'\n",
      " 'Other pattern' 'Neps' 'Embroidery' 'Lace' 'Jacquard' 'Unknown' 'Argyle'\n",
      " 'Slub' 'Mesh' 'Sequin' 'Hologram']\n",
      "['Jersey Basic' 'Under-, Nightwear' 'Socks and Tights' 'Jersey Fancy'\n",
      " 'Accessories' 'Trousers Denim' 'Outdoor' 'Shoes' 'Swimwear' 'Knitwear'\n",
      " 'Shirts' 'Trousers' 'Dressed' 'Shorts' 'Dresses Ladies' 'Skirts'\n",
      " 'Special Offers' 'Blouses' 'Unknown' 'Woven/Jersey/Knitted mix Baby'\n",
      " 'Dresses/Skirts girls']\n"
     ]
    }
   ],
   "source": [
    "print(articles[\"perceived_colour_value_name\"].unique())\n",
    "print(articles[\"colour_group_name\"].unique())\n",
    "print(articles[\"graphical_appearance_name\"].unique())\n",
    "print(articles[\"garment_group_name\"].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b0ef4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['customer_id'] = customer_hex_id_to_int(transactions['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0d9a0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.t_dat = pd.to_datetime(transactions.t_dat, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2bfae010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "transactions['week'] = (104 - (transactions.t_dat.max() - transactions.t_dat).dt.days // 7).astype(np.int8)\n",
    "print(transactions[\"week\"].max())\n",
    "print(transactions[\"week\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b094879d",
   "metadata": {},
   "source": [
    "Let's do something about the `article_id` (both here and on `articles`) and let's take a closer look at `price`, `sales_channel_id` and `week`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7390ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.article_id = article_id_str_to_int(transactions.article_id)\n",
    "articles.article_id = article_id_str_to_int(articles.article_id)\n",
    "\n",
    "transactions.week = transactions.week.astype('int8')  # EDITED: added astype\n",
    "transactions.sales_channel_id = transactions.sales_channel_id.astype('int8')\n",
    "transactions.price = transactions.price.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "10623914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31788324 entries, 0 to 31788323\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   customer_id       uint64 \n",
      " 1   article_id        int32  \n",
      " 2   price             float32\n",
      " 3   sales_channel_id  int8   \n",
      " 4   week              int8   \n",
      "dtypes: float32(1), int32(1), int8(2), uint64(1)\n",
      "memory usage: 545.7 MB\n"
     ]
    }
   ],
   "source": [
    "transactions.drop(columns='t_dat').info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f874dac4",
   "metadata": {},
   "source": [
    "Well, this is interesting. There are very few unique `t_dat` values hence despite it being a scary `datetime64` it takes up very little memory!\n",
    "\n",
    "Keeping it for convenience is definitely the way to go.\n",
    "\n",
    "Let's take a brief look at the `customers` and `articles` dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['ACTIVE', nan, 'PRE-CREATE', 'LEFT CLUB'], dtype=object)"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers['club_member_status'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "61bf9df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edited\n"
     ]
    }
   ],
   "source": [
    "customers.customer_id = customer_hex_id_to_int(customers.customer_id)\n",
    "print(fillna_values)\n",
    "if fillna_values == '-1':\n",
    "    customers['fashion_news_frequency'] = customers['fashion_news_frequency'].replace('none','NONE')  # EDITED: added this\n",
    "    for col in ['FN', 'Active', 'age']:\n",
    "        customers[col].fillna(-1, inplace=True)\n",
    "        customers[col] = customers[col].astype('int8')\n",
    "# EDITED: added alternate preprocessing\n",
    "elif fillna_values == 'edited':\n",
    "    articles['detail_desc'] = articles['detail_desc'].fillna(\"\")\n",
    "    customers['FN'] = customers['FN'].fillna(0)\n",
    "    customers['Active'] = customers['Active'].fillna(0)\n",
    "    customers['age'] = customers['age'].fillna(int(customers['age'].mean()))\n",
    "    customers['fashion_news_frequency'] = customers['fashion_news_frequency'].fillna('NONE')\n",
    "    customers['fashion_news_frequency'] = customers['fashion_news_frequency'].replace('none','NONE')\n",
    "    customers['club_member_status'] = customers['club_member_status'].fillna('PRE-CREATE')\n",
    "else:\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "758411dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check out how Categorize works\n",
    "customers.club_member_status = Categorize().fit_transform(customers[['club_member_status']]).club_member_status\n",
    "customers.postal_code = Categorize().fit_transform(customers[['postal_code']]).postal_code\n",
    "customers.fashion_news_frequency = Categorize().fit_transform(customers[['fashion_news_frequency']]).fashion_news_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6cb4fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check out how Categorize works\n",
    "for col in articles.columns:\n",
    "    if articles[col].dtype == 'object':\n",
    "        articles[col] = Categorize().fit_transform(articles[[col]])[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b3596527",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in articles.columns:\n",
    "    if articles[col].dtype == 'int64':\n",
    "        articles[col] = articles[col].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc411fb5",
   "metadata": {},
   "source": [
    "And this concludes our raw data preparation step! Let's now write everything back to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "86f4e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.sort_values(['t_dat', 'customer_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "682b1125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.78 s\n",
      "Wall time: 7.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transactions.to_parquet(f'../data/transactions_train_{fillna_values}.parquet')\n",
    "customers.to_parquet(f'../data/customers_{fillna_values}.parquet')\n",
    "articles.to_parquet(f'../data/articles_{fillna_values}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930753b7",
   "metadata": {},
   "source": [
    "Let's also generate a sample we will be able to use to speed up development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3fd97303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # let's create a 5% sample of the entirity of the data to speed up dev\n",
    "#\n",
    "# sample = 0.05\n",
    "# customers_sample = customers.sample(frac=sample, replace=False)\n",
    "# customers_sample_ids = set(customers_sample['customer_id'])\n",
    "# transactions_sample = transactions[transactions[\"customer_id\"].isin(customers_sample_ids)]\n",
    "# articles_sample_ids = set(transactions_sample[\"article_id\"])\n",
    "# articles_sample = articles[articles[\"article_id\"].isin(articles_sample_ids)]\n",
    "#\n",
    "# customers_sample.to_parquet(f'../data/customers_sample_{sample}_{fillna_values}.parquet', index=False)\n",
    "# transactions_sample.to_parquet(f'../data/transactions_train_sample_{sample}_{fillna_values}.parquet', index=False)\n",
    "# articles_sample.to_parquet(f'../data/articles_train_sample_{sample}_{fillna_values.parquet}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f8dc2",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3cc90c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "val_week_purchases_by_cust = defaultdict(list)\n",
    "\n",
    "val_week_purchases_by_cust.update(\n",
    "    transactions[transactions.week == transactions.week.max()] \\\n",
    "        .groupby('customer_id')['article_id'] \\\n",
    "        .apply(list) \\\n",
    "        .to_dict()\n",
    ")\n",
    "\n",
    "pd.to_pickle(dict(val_week_purchases_by_cust), '../data/val_week_purchases_by_cust.pkl')\n",
    "\n",
    "sample_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "valid_gt = customer_hex_id_to_int(sample_sub.customer_id) \\\n",
    "    .map(val_week_purchases_by_cust) \\\n",
    "    .apply(lambda xx: ' '.join('0' + str(x) for x in xx))\n",
    "\n",
    "sample_sub.prediction = valid_gt\n",
    "sample_sub.to_parquet(f'../data/validation_ground_truth_{fillna_values}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "73bdc7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_apk(list_of_preds, list_of_gts):\n",
    "    # for fast validation this can be changed to operate on dicts of {'cust_id_int': [art_id_int, ...]}\n",
    "    # using 'data/val_week_purchases_by_cust.pkl'\n",
    "    apks = []\n",
    "    for preds, gt in zip(list_of_preds, list_of_gts):\n",
    "        apks.append(apk(gt, preds, k=12))\n",
    "    return np.mean(apks)\n",
    "\n",
    "def eval_sub(sub_csv, skip_cust_with_no_purchases=True):\n",
    "    sub=pd.read_csv(sub_csv)\n",
    "    validation_set=pd.read_parquet('../data/validation_ground_truth.parquet')\n",
    "\n",
    "    apks = []\n",
    "\n",
    "    no_purchases_pattern = []\n",
    "    for pred, gt in zip(sub.prediction.str.split(), validation_set.prediction.str.split()):\n",
    "        if skip_cust_with_no_purchases and (gt == no_purchases_pattern): continue\n",
    "        apks.append(mapk(gt, pred, k=12))  # Changed to mapk, was apk\n",
    "    return np.mean(apks)\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
