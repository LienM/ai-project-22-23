{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This code is from [https://github.com/radekosmulski/personalized_fashion_recs](https://github.com/radekosmulski/personalized_fashion_recs) with extra options and some improvements.\n",
    "Comments explaining the original notebooks code were added by me and Arno Troch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "LGBMBoostingType = 'dart'\n",
    "preprocess = '-1'\n",
    "bestsellerFiller = 999\n",
    "transactionBackXWeeks = 10\n",
    "prevYear = ''\n",
    "assert LGBMBoostingType in ['gbdt','dart','goss','rf']\n",
    "assert preprocess in ['-1','edited']\n",
    "assert prevYear in [\"\",\"SkipYear\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad823629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5687e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fc4a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.47 s\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transactions = pd.read_parquet(f'../data/transactions_train_{preprocess}.parquet')\n",
    "transactions_full = pd.read_parquet(f'../data/transactions_train_{preprocess}.parquet')\n",
    "customers = pd.read_parquet(f'../data/customers_{preprocess}.parquet')\n",
    "articles = pd.read_parquet(f'../data/articles_{preprocess}.parquet')\n",
    "# sample = 0.05\n",
    "# transactions = pd.read_parquet(f'../data/transactions_train_sample_{sample}.parquet')\n",
    "# customers = pd.read_parquet(f'../data/customers_sample_{sample}.parquet')\n",
    "# articles = pd.read_parquet(f'../data/articles_train_sample_{sample}.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a4cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_week = transactions.week.max() + 1\n",
    "if prevYear == 'SkipYear':\n",
    "    transactions3 = transactions[transactions.week > transactions.week.max() - transactionBackXWeeks]\n",
    "    transactions2 = transactions[(transactions.week.max()-52>=transactions.week) & (transactions.week >transactions.week.max() - transactionBackXWeeks-52)] # EDITED\n",
    "    print(transactions3['week'].unique())\n",
    "    print(transactions2['week'].unique())\n",
    "    transactions = pd.concat([transactions3,transactions2])\n",
    "else:\n",
    "    transactions = transactions[transactions.week > transactions.week.max() - transactionBackXWeeks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import copy\n",
    "# Given customer ids and arbitrary article features (except article id), returns a df with rows containing each combination of customer_id and combination of\n",
    "def get_purchase_count_df_of_attributes(transactions,articles,attributes_columns_names,feature_name):\n",
    "    attributes_columns_names_plus_article_id = copy.deepcopy(attributes_columns_names)\n",
    "    attributes_columns_names_plus_article_id.insert(0,\"article_id\")\n",
    "    attributes_columns_names_plus_customer_id = copy.deepcopy(attributes_columns_names)\n",
    "    attributes_columns_names_plus_customer_id.insert(0,\"customer_id\")\n",
    "    articles_selected = articles[attributes_columns_names_plus_article_id]\n",
    "    big_df = pd.merge(articles_selected,transactions[[\"customer_id\",\"article_id\"]],on=[\"article_id\"])\n",
    "    return big_df.groupby(attributes_columns_names_plus_customer_id).size().reset_index(name=feature_name)\n",
    "\n",
    "def get_purchase_rank_df_of_attributes(transactions,articles,attributes_columns_names,feature_name):\n",
    "    attributes_columns_names_plus_article_id = copy.deepcopy(attributes_columns_names)\n",
    "    attributes_columns_names_plus_article_id.insert(0,\"article_id\")\n",
    "    attributes_columns_names_plus_customer_id = copy.deepcopy(attributes_columns_names)\n",
    "    attributes_columns_names_plus_customer_id.insert(0,\"customer_id\")\n",
    "    articles_selected = articles[attributes_columns_names_plus_article_id]\n",
    "    big_df = pd.merge(articles_selected,transactions[[\"customer_id\",\"article_id\"]],on=[\"article_id\"])\n",
    "    big_df = big_df.groupby(attributes_columns_names_plus_customer_id).size().reset_index(name=feature_name)\n",
    "    big_df[feature_name + \"_rank\"] =  big_df.groupby(\"customer_id\")[feature_name].rank(method=\"dense\",ascending=False)\n",
    "    return big_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      customer_id  garment_group_no  colour_code_amount\n0  28847241659200              1005                   1\n1  28847241659200              1007                   1\n2  28847241659200              1009                   1\n3  28847241659200              1010                   2\n4  41318098387474              1013                   1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>garment_group_no</th>\n      <th>colour_code_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28847241659200</td>\n      <td>1005</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28847241659200</td>\n      <td>1007</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28847241659200</td>\n      <td>1009</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28847241659200</td>\n      <td>1010</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41318098387474</td>\n      <td>1013</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_1 = get_purchase_count_df_of_attributes(transactions,articles,[\"garment_group_no\"],\"colour_code_amount\")\n",
    "temp_1.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "      customer_id  garment_group_no  amount_of_garment_group_no  \\\n0  28847241659200              1005                           1   \n1  28847241659200              1007                           1   \n2  28847241659200              1009                           1   \n3  28847241659200              1010                           2   \n4  41318098387474              1013                           1   \n\n   amount_of_garment_group_no_rank  \n0                              2.0  \n1                              2.0  \n2                              2.0  \n3                              1.0  \n4                              1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>garment_group_no</th>\n      <th>amount_of_garment_group_no</th>\n      <th>amount_of_garment_group_no_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28847241659200</td>\n      <td>1005</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28847241659200</td>\n      <td>1007</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28847241659200</td>\n      <td>1009</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28847241659200</td>\n      <td>1010</td>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41318098387474</td>\n      <td>1013</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = get_purchase_rank_df_of_attributes(transactions,articles,[\"garment_group_no\"],\"amount_of_garment_group_no\")\n",
    "temp2.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "56263b7a",
   "metadata": {},
   "source": [
    "# Generating candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd43fcd",
   "metadata": {},
   "source": [
    "### Last purchase candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca3b5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c2weeks = transactions.groupby('customer_id')['week'].unique()\n",
    "\n",
    "c2weeks2shifted_weeks = {}\n",
    "\n",
    "for c_id, weeks in c2weeks.items():\n",
    "    c2weeks2shifted_weeks[c_id] = {}\n",
    "    for i in range(weeks.shape[0]-1):\n",
    "        c2weeks2shifted_weeks[c_id][weeks[i]] = weeks[i+1]\n",
    "    c2weeks2shifted_weeks[c_id][weeks[-1]] = test_week\n",
    "\n",
    "candidates_last_purchase = transactions.copy()\n",
    "\n",
    "weeks = []\n",
    "for i, (c_id, week) in enumerate(zip(transactions['customer_id'], transactions['week'])):\n",
    "    weeks.append(c2weeks2shifted_weeks[c_id][week])\n",
    "\n",
    "# Candidate for week X: item bought in previous purchase week\n",
    "candidates_last_purchase.week=weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              t_dat           customer_id  article_id     price  \\\n",
      "29030503 2020-07-15       272412481300040   778064028  0.008458   \n",
      "29030504 2020-07-15       272412481300040   816592008  0.016932   \n",
      "29030505 2020-07-15       272412481300040   621381021  0.033881   \n",
      "29030506 2020-07-15       272412481300040   817477003  0.025407   \n",
      "29030507 2020-07-15       272412481300040   899088002  0.025407   \n",
      "...             ...                   ...         ...       ...   \n",
      "31774722 2020-09-22  18439937050817258297   891591003  0.084729   \n",
      "31774723 2020-09-22  18439937050817258297   869706005  0.084729   \n",
      "31779097 2020-09-22  18440902715633436014   918894002  0.016932   \n",
      "31779098 2020-09-22  18440902715633436014   761269001  0.016932   \n",
      "31780475 2020-09-22  18443633011701112574   914868002  0.033881   \n",
      "\n",
      "          sales_channel_id  week  \n",
      "29030503                 1    96  \n",
      "29030504                 1    96  \n",
      "29030505                 1    96  \n",
      "29030506                 1    96  \n",
      "29030507                 1    96  \n",
      "...                    ...   ...  \n",
      "31774722                 2   105  \n",
      "31774723                 2   105  \n",
      "31779097                 1   105  \n",
      "31779098                 1   105  \n",
      "31780475                 1   105  \n",
      "\n",
      "[2762872 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(candidates_last_purchase)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "4077cf9c",
   "metadata": {},
   "source": [
    "### Bestsellers candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b794ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   customer_id  article_id  week  importance\n",
      "0               28847241659200   372860002    96           1\n",
      "1               28847241659200   448509014   105           1\n",
      "2               28847241659200   547780003    96           1\n",
      "3               28847241659200   600886001    96           1\n",
      "4               28847241659200   610776002    96           1\n",
      "...                        ...         ...   ...         ...\n",
      "18253744  18446737527580148316   923758001   104           1\n",
      "18253745  18446737527580148316   923758001   105           1\n",
      "18253746  18446737527580148316   924243001   104           1\n",
      "18253747  18446737527580148316   924243001   105           1\n",
      "18253748  18446737527580148316   924243002   105           1\n",
      "\n",
      "[18253749 rows x 4 columns]\n",
      "0\n",
      "74\n",
      "1.0362430205433415\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": "       t_dat      customer_id  article_id     price  sales_channel_id  week  \\\n0 2020-07-15  272412481300040   778064028  0.008458                 1    95   \n1 2020-07-15  272412481300040   816592008  0.016932                 1    95   \n2 2020-07-15  272412481300040   621381021  0.033881                 1    95   \n3 2020-07-15  272412481300040   817477003  0.025407                 1    95   \n4 2020-07-15  272412481300040   899088002  0.025407                 1    95   \n\n   purchased  importance  \n0        1.0           1  \n1        1.0           1  \n2        1.0           1  \n3        1.0           1  \n4        1.0           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-07-15</td>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean price PER ITEM PER WEEK\n",
    "mean_price = transactions \\\n",
    "    .groupby(['week', 'article_id'])['price'].mean()\n",
    "\n",
    "# bestseller rank doet niets: ranking is belangrijk om de bestsellers te vinden, maar de kolom zelf mag weg\n",
    "# For each week, list of ranked 12 bestsellers\n",
    "sales = transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1\n",
    "# Per week lijst van customers die IETS gekocht hebben\n",
    "unique_transactions = transactions \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()\n",
    "\n",
    "# Per week lijst van customers die IETS gekocht hebben\n",
    "# MERGE\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "\n",
    "# Per week, per customer die iets gekocht heeft, de 12 bestverkochte uit DE (algemeen) vorige week\n",
    "candidates_bestsellers = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")\n",
    "\n",
    "# unique_transactions = Per week lijst van customers die IETS gekocht hebben\n",
    "# Voor elke customer waar we iets over weten en dus een voorspelling van willen doen, houden we 1 keer de customer id over en zetten we de week op test_week, want dat is wanneer we willen voorspellen wat hij koopt\n",
    "test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "test_set_transactions.week = test_week\n",
    "\n",
    "\n",
    "# Voor elke customer waar we iets over weten en dus een voorspelling van willen doen, houden we 1 keer de customer id over en zetten we de week op test_week, want dat is wanneer we willen voorspellen wat hij koopt\n",
    "# MERGE\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "\n",
    "# Resultaat: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek\n",
    "candidates_bestsellers_test_week = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")\n",
    "\n",
    "# bestseller rank doet niets: ranking is belangrijk om de bestsellers te vinden, maar de kolom zelf mag weg\n",
    "\n",
    "# Per week, per customer die iets gekocht heeft, de 12 bestverkochte uit DE (algemeen) vorige week\n",
    "# Resultaat: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek\n",
    "\n",
    "candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)\n",
    "\n",
    "# Combining transactions and candidates / negative examples\n",
    "\n",
    "transactions['purchased'] = 1\n",
    "\n",
    "\n",
    "# candidates_last_purchase: Candidate for week X: item bought in previous purchase week\n",
    "# candidates_bestsellers: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek\n",
    "# transactions: letterlijk gewoon transactions\n",
    "data = pd.concat([transactions, candidates_last_purchase, candidates_bestsellers])\n",
    "data.purchased.fillna(0, inplace=True)\n",
    "\n",
    "# Voor elke week: kijk alle keren dat customer het artikel koopt OF voorgesteld krijgt, en hou indien gekocht enkel de rij met purchased 1\n",
    "# Opmerking: candidates voor week 105 zijn allemaal purchased==0\n",
    "brak = data.groupby(['customer_id', 'article_id', 'week']).size().reset_index(name=\"importance\")\n",
    "print(brak)\n",
    "data.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    brak,\n",
    "    on=['customer_id', 'article_id', 'week']\n",
    ")\n",
    "\n",
    "data.purchased.mean()\n",
    "print(data[\"importance\"].isna().sum())\n",
    "print(data[\"importance\"].max())\n",
    "print(data[\"importance\"].mean())\n",
    "print(data[\"importance\"].min())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22588375",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac183274",
   "metadata": {},
   "source": [
    "### Add bestseller information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f28957eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# van echte transacties: bestseller onbekend, check candidates om te kijken of er toen wel bestseller rank was. Zo nee, vul later met fillna\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "    on=['week', 'article_id'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e7d3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijder eerste week omdat er voor eerste week geen bestsellers_previous_week is\n",
    "data = data[data.week != data.week.min()]  # Presumably to make sure no data of an incomplete week is included?\n",
    "# Indien geen bestseller: keislecht verkocht\n",
    "data.bestseller_rank.fillna(bestsellerFiller, inplace=True)  # EDITED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5fdc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per customer per week alle transacties en/of candidates\n",
    "\n",
    "# Steek bij elke aankoop alle info over gekocht article erbij\n",
    "data = pd.merge(data, articles, on='article_id', how='left')\n",
    "# Steek bij elke aankoop alle info over customer erbij\n",
    "data = pd.merge(data, customers, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e3a737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorteer eerst op week, dan per week op customer\n",
    "data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_of_(index_group_no)17.836069345474243\n",
      "amount_of_(graphical_appearance_no)20.19042658805847\n",
      "amount_of_(perceived_colour_value_id)20.18234348297119\n",
      "amount_of_(garment_group_no)22.850852727890015\n"
     ]
    }
   ],
   "source": [
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'bestseller_rank','importance']\n",
    "\n",
    "import itertools\n",
    "new_features = dict()\n",
    "# article_features = ['product_type_no','graphical_appearance_no','colour_group_code','perceived_colour_value_id','perceived_colour_master_id', 'department_no', 'index_code','index_group_no', 'section_no', 'garment_group_no']\n",
    "article_features = ['index_group_no','graphical_appearance_no','perceived_colour_value_id','garment_group_no']\n",
    "for feature_column in article_features:\n",
    "    new_features[\"amount_of_(\" + feature_column + \")\"] = [feature_column]\n",
    "# for double_features in itertools.combinations(article_features,2):\n",
    "#     new_features[\"amount_of_(\" + double_features[0] + \"_\" + double_features[1] + \")\"] = [double_features[0],double_features[1]]\n",
    "\n",
    "for feature_name,partial_columns in new_features.items():\n",
    "    time_start = time.time()\n",
    "    columns_to_use.append(feature_name)\n",
    "    df_with_customer_id_and_features_and_count = get_purchase_count_df_of_attributes(transactions_full[transactions_full.week != test_week],articles,partial_columns,feature_name)\n",
    "    data = pd.merge(data,df_with_customer_id_and_features_and_count,on=([\"customer_id\"] + partial_columns),how=\"left\")\n",
    "    print(feature_name +  str(time.time() - time_start))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d83b869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              t_dat     customer_id  article_id     price  sales_channel_id  \\\n11381612 2020-09-03  28847241659200   925246001  0.128797                 2   \n11381613 2020-07-18  28847241659200   924243001  0.041535                 1   \n11381614 2020-07-18  28847241659200   924243002  0.041877                 1   \n11381615 2020-07-18  28847241659200   918522001  0.041435                 1   \n11381616 2020-07-18  28847241659200   923758001  0.033462                 1   \n\n          week  purchased  importance  bestseller_rank  product_code  ...  FN  \\\n11381612   105        0.0           1            999.0        925246  ...   1   \n11381613   105        0.0           1              1.0        924243  ...   1   \n11381614   105        0.0           1              2.0        924243  ...   1   \n11381615   105        0.0           1              3.0        918522  ...   1   \n11381616   105        0.0           1              4.0        923758  ...   1   \n\n          Active  club_member_status  fashion_news_frequency  age  \\\n11381612       1                   0                       1   21   \n11381613       1                   0                       1   21   \n11381614       1                   0                       1   21   \n11381615       1                   0                       1   21   \n11381616       1                   0                       1   21   \n\n          postal_code  amount_of_(index_group_no)  \\\n11381612        57896                        54.0   \n11381613        57896                        54.0   \n11381614        57896                        54.0   \n11381615        57896                        54.0   \n11381616        57896                        54.0   \n\n          amount_of_(graphical_appearance_no)  \\\n11381612                                 59.0   \n11381613                                 59.0   \n11381614                                 59.0   \n11381615                                 59.0   \n11381616                                 59.0   \n\n          amount_of_(perceived_colour_value_id)  amount_of_(garment_group_no)  \n11381612                                   36.0                           2.0  \n11381613                                   19.0                           9.0  \n11381614                                   36.0                           9.0  \n11381615                                   10.0                           9.0  \n11381616                                   10.0                          11.0  \n\n[5 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n      <th>importance</th>\n      <th>bestseller_rank</th>\n      <th>product_code</th>\n      <th>...</th>\n      <th>FN</th>\n      <th>Active</th>\n      <th>club_member_status</th>\n      <th>fashion_news_frequency</th>\n      <th>age</th>\n      <th>postal_code</th>\n      <th>amount_of_(index_group_no)</th>\n      <th>amount_of_(graphical_appearance_no)</th>\n      <th>amount_of_(perceived_colour_value_id)</th>\n      <th>amount_of_(garment_group_no)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11381612</th>\n      <td>2020-09-03</td>\n      <td>28847241659200</td>\n      <td>925246001</td>\n      <td>0.128797</td>\n      <td>2</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>999.0</td>\n      <td>925246</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n      <td>54.0</td>\n      <td>59.0</td>\n      <td>36.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>11381613</th>\n      <td>2020-07-18</td>\n      <td>28847241659200</td>\n      <td>924243001</td>\n      <td>0.041535</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>924243</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n      <td>54.0</td>\n      <td>59.0</td>\n      <td>19.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>11381614</th>\n      <td>2020-07-18</td>\n      <td>28847241659200</td>\n      <td>924243002</td>\n      <td>0.041877</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>924243</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n      <td>54.0</td>\n      <td>59.0</td>\n      <td>36.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>11381615</th>\n      <td>2020-07-18</td>\n      <td>28847241659200</td>\n      <td>918522001</td>\n      <td>0.041435</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>918522</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n      <td>54.0</td>\n      <td>59.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>11381616</th>\n      <td>2020-07-18</td>\n      <td>28847241659200</td>\n      <td>923758001</td>\n      <td>0.033462</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>923758</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n      <td>54.0</td>\n      <td>59.0</td>\n      <td>10.0</td>\n      <td>11.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 43 columns</p>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Niet trainen op laatste week want anders hebben we geen test set\n",
    "train = data[data.week != test_week]\n",
    "# Laatste week, indien item in beide candidate sets, drop duplicates.\n",
    "test = data[data.week==test_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71d57fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              t_dat           customer_id  article_id     price  \\\n",
      "0        2020-07-26        28847241659200   887770001  0.016932   \n",
      "1        2020-07-18        28847241659200   762846001  0.025407   \n",
      "2        2020-07-18        28847241659200   829308001  0.033881   \n",
      "3        2020-07-26        28847241659200   760084003  0.025094   \n",
      "4        2020-07-26        28847241659200   866731001  0.024919   \n",
      "...             ...                   ...         ...       ...   \n",
      "11381596 2020-09-21  18446737527580148316   547780001  0.023712   \n",
      "11381597 2020-09-21  18446737527580148316   763988001  0.023712   \n",
      "11381598 2020-09-21  18446737527580148316   763988003  0.023712   \n",
      "11381599 2020-09-21  18446737527580148316   547780040  0.023712   \n",
      "11381600 2020-09-21  18446737527580148316   909370001  0.032947   \n",
      "\n",
      "          sales_channel_id  week  purchased  importance  bestseller_rank  \\\n",
      "0                        1    96        1.0           1            999.0   \n",
      "1                        1    96        0.0           1            999.0   \n",
      "2                        1    96        0.0           1            999.0   \n",
      "3                        1    96        0.0           1              1.0   \n",
      "4                        1    96        0.0           1              2.0   \n",
      "...                    ...   ...        ...         ...              ...   \n",
      "11381596                 2   104        1.0           1            999.0   \n",
      "11381597                 2   104        1.0           1            999.0   \n",
      "11381598                 2   104        1.0           1            999.0   \n",
      "11381599                 2   104        1.0           1            999.0   \n",
      "11381600                 2   104        0.0           1              1.0   \n",
      "\n",
      "          product_code  ...  FN  Active  club_member_status  \\\n",
      "0               887770  ...   1       1                   0   \n",
      "1               762846  ...   1       1                   0   \n",
      "2               829308  ...   1       1                   0   \n",
      "3               760084  ...   1       1                   0   \n",
      "4               866731  ...   1       1                   0   \n",
      "...                ...  ...  ..     ...                 ...   \n",
      "11381596        547780  ...   1       1                   0   \n",
      "11381597        763988  ...   1       1                   0   \n",
      "11381598        763988  ...   1       1                   0   \n",
      "11381599        547780  ...   1       1                   0   \n",
      "11381600        909370  ...   1       1                   0   \n",
      "\n",
      "          fashion_news_frequency  age  postal_code  \\\n",
      "0                              1   21        57896   \n",
      "1                              1   21        57896   \n",
      "2                              1   21        57896   \n",
      "3                              1   21        57896   \n",
      "4                              1   21        57896   \n",
      "...                          ...  ...          ...   \n",
      "11381596                       1   60        96323   \n",
      "11381597                       1   60        96323   \n",
      "11381598                       1   60        96323   \n",
      "11381599                       1   60        96323   \n",
      "11381600                       1   60        96323   \n",
      "\n",
      "          amount_of_(index_group_no)  amount_of_(graphical_appearance_no)  \\\n",
      "0                               54.0                                 59.0   \n",
      "1                               54.0                                 59.0   \n",
      "2                                7.0                                 59.0   \n",
      "3                               13.0                                 59.0   \n",
      "4                                7.0                                 59.0   \n",
      "...                              ...                                  ...   \n",
      "11381596                         8.0                                 36.0   \n",
      "11381597                        32.0                                 36.0   \n",
      "11381598                        32.0                                  8.0   \n",
      "11381599                         8.0                                 36.0   \n",
      "11381600                        29.0                                  1.0   \n",
      "\n",
      "          amount_of_(perceived_colour_value_id)  amount_of_(garment_group_no)  \n",
      "0                                          36.0                          11.0  \n",
      "1                                          10.0                          11.0  \n",
      "2                                          36.0                          11.0  \n",
      "3                                          36.0                           6.0  \n",
      "4                                          36.0                          11.0  \n",
      "...                                         ...                           ...  \n",
      "11381596                                   37.0                          23.0  \n",
      "11381597                                   37.0                          23.0  \n",
      "11381598                                   37.0                          23.0  \n",
      "11381599                                    6.0                          23.0  \n",
      "11381600                                    6.0                           NaN  \n",
      "\n",
      "[3392165 rows x 43 columns]\n",
      "[15 23 16 ... 14 19 16]\n",
      "12\n",
      "155\n",
      "678433\n"
     ]
    }
   ],
   "source": [
    "print(train.groupby(['week', 'customer_id']).head())\n",
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values\n",
    "print(train_baskets)\n",
    "print(train_baskets.min())\n",
    "print(train_baskets.max())\n",
    "print(len(train_baskets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "562146df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 416 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b26b0a",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17079af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "00b6186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker=LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=LGBMBoostingType,\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31408339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.887558\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.161772\n",
      "[LightGBM] [Debug] init for col-wise cost 0.141665 seconds, init for row-wise cost 0.493081 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.346042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 11381612, number of used features: 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "CPU times: total: 19.2 s\n",
      "Wall time: 7.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7396bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestseller_rank 0.9590945642075946\n",
      "importance 0.03671050672288266\n",
      "amount_of_(index_group_no) 0.0028664852965649586\n",
      "amount_of_(garment_group_no) 0.0007547670312425131\n",
      "amount_of_(graphical_appearance_no) 0.00021948505918151887\n",
      "article_id 0.00018722873669037863\n",
      "index_group_no 5.932510318931642e-05\n",
      "amount_of_(perceived_colour_value_id) 5.675434037113316e-05\n",
      "department_no 5.088350228289172e-05\n",
      "index_code 0.0\n",
      "product_type_no 0.0\n",
      "graphical_appearance_no 0.0\n",
      "colour_group_code 0.0\n",
      "perceived_colour_value_id 0.0\n",
      "perceived_colour_master_id 0.0\n",
      "postal_code 0.0\n",
      "age 0.0\n",
      "section_no 0.0\n",
      "garment_group_no 0.0\n",
      "Active 0.0\n",
      "club_member_status 0.0\n",
      "fashion_news_frequency 0.0\n",
      "FN 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb34139",
   "metadata": {},
   "source": [
    "# Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9fa10874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.05 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "c_id2predicted_article_ids = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e576d90",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb1c56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03d79b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.17 s\n",
      "Wall time: 2.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = []\n",
    "\n",
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)\n",
    "\n",
    "\n",
    "for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "    pred = c_id2predicted_article_ids.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4ed109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "sub.prediction = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "245ce774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "basic_model_submission_dart_fillna-1bestsellerFiller999_weeks10_importance\n"
     ]
    }
   ],
   "source": [
    "sub_name = 'basic_model_submission_' +  str(LGBMBoostingType) + '_fillna' + str(preprocess) + 'bestsellerFiller' + str(bestsellerFiller) + \"_weeks\" + str(transactionBackXWeeks) + \"_importance\" + str(prevYear)\n",
    "sub.to_csv(f'../data/subs/{sub_name}.csv.gz', index=False)\n",
    "sub.to_csv(f'../data/subs/{sub_name}.csv', index=False)\n",
    "print(\"Done\")\n",
    "print(sub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fbb16d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c h-and-m-personalized-fashion-recommendations -f 'data/subs/{sub_name}.csv.gz' -m {sub_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
