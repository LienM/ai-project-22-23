{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2a2a22",
   "metadata": {},
   "source": [
    "This code is from [https://github.com/radekosmulski/personalized_fashion_recs](https://github.com/radekosmulski/personalized_fashion_recs) with extra options and some improvements.\n",
    "Comments explaining the original notebooks code were added by me and Arno Troch.\n",
    "\n",
    "Run lecture6_part1.ipnyb before this one.\n",
    "\n",
    "Notebook can need up to 32GB of ram. If that's too much, go to the first code cell and lower transactionBackXWeeks and/or featuresBackXWeeks.\n",
    "\n",
    "Most things added for lecture 6 should have a comment \"# Lecture 6\", but I might have missed some\n",
    "\n",
    "Changes from last week:\n",
    "- refactored feature generation code\n",
    "- Bugfix for features based on user history: used to take future data into account\n",
    "- add candidates based on favourite value of an article feature\n",
    "\n",
    "Results:\n",
    "- Bugfix: 0.02147 -> 0.02151\n",
    "- Candidates: 0.02151 -> 0.0214 (is actually better depending on the article feature used to generate candidates, but the tests I did this week all gave poor results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edc4660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Lecture 6\n",
    "# TODO: select better features\n",
    "# Generate new features based on these article_id columns\n",
    "# For each of these columns, two features will be generated:\n",
    "# For each transaction (both actual transactions and negative samples), count how often a user has already bought an item with the same value for this column.\n",
    "# Additionally, what rank does the feature have? e.g. If the user has bought more blue items than any other colour, the rank will be one. If his next favourite is red, transactions with a red item will have value 2.\n",
    "article_features = ['index_group_no','graphical_appearance_no','perceived_colour_value_id','garment_group_no']\n",
    "\n",
    "# If True, then for each possible pair that can be made with elements from article_features, two new features will be made (as explained at article values: count and rank)\n",
    "# Example: if article_features contains colour and garment type, then a transaction for blue trousers will have new features with values that say how often the user already bought any blue trousers,\n",
    "# and how it ranks on his list of favourite clothing type/colour combinations.\n",
    "do_combinations_of_features = True\n",
    "\n",
    "#Lecture 6\n",
    "# Should candidates be added based on user purchase history? If True, then if a user likes blue, the most popular blue item of last week will be added as negative sample\n",
    "add_history_candidates = True\n",
    "LGBMBoostingType = 'dart'\n",
    "preprocess = '-1'  # '-1' uses preprocessing from original notebook, 'edited' uses slightly different preprocessing. You should probably use '-1'\n",
    "# If a negative sample did not appear in a bestseller list, this is what the NaN is filled with. Normal values are between 1-12. If None, will use actual bestseller rank even beyond 12.\n",
    "# (Bestseller is a rank of how well an item sold in a certain week, with 1 meaning it was the most sold item)\n",
    "# TODO: I assumed setting bestsellerFiller to None would get better results, but it makes them much worse. Is this an implementation error?\n",
    "bestsellerFiller = 999\n",
    "transactionBackXWeeks = 10  # Size of training+test sets: this many weeks before test set\n",
    "# Lecture 6\n",
    "featuresBackXWeeks = 999  # How much data to use to calculate features based on user history. If set to more weeks than available in dataset, uses entire dataset\n",
    "prevYear = ''  # if \"SkipYear\": uses training data as explained in transactionBackXWeeks + the same weeks of the previous year. Not recommended.\n",
    "assert LGBMBoostingType in ['gbdt','dart','goss','rf']\n",
    "assert preprocess in ['-1','edited']\n",
    "assert prevYear in [\"\",\"SkipYear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad823629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5687e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13fc4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_parquet(f'../data/transactions_train_{preprocess}.parquet')\n",
    "transactions=transactions.drop(columns=\"t_dat\")\n",
    "# Backup is made because some features use the full dataset for calculations\n",
    "transactions_full = pd.read_parquet(f'../data/transactions_train_{preprocess}.parquet')\n",
    "transactions_full=transactions_full.drop(columns=\"t_dat\")\n",
    "transactions_full = transactions_full[transactions_full.week > transactions_full.week.max() - transactionBackXWeeks]\n",
    "customers = pd.read_parquet(f'../data/customers_{preprocess}.parquet')\n",
    "articles = pd.read_parquet(f'../data/articles_{preprocess}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7115a01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   week  article_id     price\n0     0   108775015  0.008373\n1     0   108775044  0.008374\n2     0   108775051  0.005023\n3     0   110065001  0.024983\n4     0   110065002  0.024650",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>week</th>\n      <th>article_id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>108775015</td>\n      <td>0.008373</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>108775044</td>\n      <td>0.008374</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>108775051</td>\n      <td>0.005023</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>110065001</td>\n      <td>0.024983</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>110065002</td>\n      <td>0.024650</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean price PER ITEM PER WEEK\n",
    "mean_price = transactions \\\n",
    "    .groupby(['week', 'article_id'])['price'].mean()\n",
    "mean_price.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36a4cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_week = transactions.week.max() + 1\n",
    "# Unless you really want to test training on transactionBackXWeeks and transactionBackXWeeks of last year, just read the else\n",
    "if prevYear == 'SkipYear':\n",
    "    # Starting from final week in dataset, select past transactionBackXWeeks weeks\n",
    "    transactions3 = transactions[transactions.week > transactions.week.max() - transactionBackXWeeks]\n",
    "    # Starting from final week in dataset but a year earlier, select past transactionBackXWeeks weeks\n",
    "    transactions2 = transactions[(transactions.week.max()-52>=transactions.week) & (transactions.week >transactions.week.max() - transactionBackXWeeks-52)] # EDITED\n",
    "    print(transactions3['week'].unique())\n",
    "    print(transactions2['week'].unique())\n",
    "    # training data now consists of transactionBackXWeeks of current year and last year\n",
    "    transactions = pd.concat([transactions3,transactions2])\n",
    "else:\n",
    "    # Starting from final week in dataset, select past transactionBackXWeeks weeks as training data\n",
    "    transactions = transactions[transactions.week > transactions.week.max() - transactionBackXWeeks]\n",
    "\n",
    "min_week = transactions[\"week\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2beb797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "def get_purchase_rank_df_of_attributes(transactions,articles,attributes_columns_names,feature_name):\n",
    "    \"\"\"\n",
    "    Given customer ids and arbitrary article features (except article id), returns a df with rows containing each combination of customer_id and combination of\n",
    "    For example: if attributes_columns_names contains [\"garment_group_name\"], then the final dataframe will contain for each customer how often he bought a garment with each possible value in garment_group_name, and a rank of which ones are his favourites.\n",
    "    :param transactions: pandas dataframe: Transactions on which to calculate these features, can be full transactions dataset even if training data is a subset\n",
    "    :param articles: pandas dataframe: Articles table, should be full table\n",
    "    :param attributes_columns_names: List of strings: Article Column names for which to calculate these features. Should not contain \"article_id\"\n",
    "    :param feature_name: string: Name for the new feature\n",
    "    :return: pandas dataframe: columns customer_id, attributes_columns_names, feature_name, str(feature_name)+\"_rank\"\n",
    "    \"\"\"\n",
    "\n",
    "    # To make merges later on easier, this variable contains the article columns asked form in the function argument plus article_id\n",
    "    attributes_columns_names_plus_article_id = copy.deepcopy(attributes_columns_names)\n",
    "    attributes_columns_names_plus_article_id.insert(0,\"article_id\")\n",
    "\n",
    "    # To make merges later on easier, this variable contains the article columns asked form in the function argument plus customer_id\n",
    "    attributes_columns_names_plus_customer_id = copy.deepcopy(attributes_columns_names)\n",
    "    attributes_columns_names_plus_customer_id.insert(0,\"customer_id\")\n",
    "\n",
    "    # From articles, select only relevant columns. If we want to calculate what a users favourite colour is, we do not need the garment type.\n",
    "    articles_selected = articles[attributes_columns_names_plus_article_id]\n",
    "\n",
    "    # This merge results in a dataframe containing for each transaction from the function argument the customer_id, article_id and article features as given in the attributes_columns_names argument\n",
    "    big_df = pd.merge(articles_selected,transactions[[\"customer_id\",\"article_id\"]],on=[\"article_id\"])\n",
    "\n",
    "    # Adds a column containing for each transaction how often the customer has already bought clothing with the same attributes_columns_names as the article_id from the transaction\n",
    "    big_df = big_df.groupby(attributes_columns_names_plus_customer_id).size().reset_index(name=feature_name)\n",
    "\n",
    "    # Adds a column containing for each transaction the rank that the user gives to clothing with the same attributes_columns_names as the article_id in the transaction.\n",
    "    # In this case, rank means that if the article id is blue and the user bought lots of blue things, it will be one. If the article is red and red is the users second favourite, it will be 2 etc\n",
    "    big_df[feature_name + \"_rank\"] =  big_df.groupby(\"customer_id\")[feature_name].rank(method=\"dense\",ascending=False)\n",
    "    return big_df\n",
    "\n",
    "def get_purchase_count_df_of_attributes(transactions,articles,attributes_columns_names,feature_name):\n",
    "    \"\"\"\n",
    "    Given customer ids and arbitrary article features (except article id), returns a df with rows containing each combination of customer_id and combination of\n",
    "    For example: if attributes_columns_names contains [\"garment_group_name\"], then the final dataframe will contain for each customer how often he bought a garment with each possible value in garment_group_name, and a rank of which ones are his favourites.\n",
    "    :param transactions: pandas dataframe: Transactions on which to calculate these features, can be full transactions dataset even if training data is a subset\n",
    "    :param articles: pandas dataframe: Articles table, should be full table\n",
    "    :param attributes_columns_names: List of strings: Article Column names for which to calculate these features. Should not contain \"article_id\"\n",
    "    :param feature_name: string: Name for the new feature\n",
    "    :return: pandas dataframe: columns customer_id, attributes_columns_names, feature_name, str(feature_name)+\"_rank\"\n",
    "    \"\"\"\n",
    "\n",
    "    # To make merges later on easier, this variable contains the article columns asked form in the function argument plus article_id\n",
    "    attributes_columns_names_plus_article_id = copy.deepcopy(attributes_columns_names)\n",
    "    attributes_columns_names_plus_article_id.insert(0,\"article_id\")\n",
    "\n",
    "    # To make merges later on easier, this variable contains the article columns asked form in the function argument plus customer_id\n",
    "    attributes_columns_names_plus_customer_id = copy.deepcopy(attributes_columns_names)\n",
    "    attributes_columns_names_plus_customer_id.insert(0,\"customer_id\")\n",
    "\n",
    "    # From articles, select only relevant columns. If we want to calculate what a users favourite colour is, we do not need the garment type.\n",
    "    articles_selected = articles[attributes_columns_names_plus_article_id]\n",
    "\n",
    "    # This merge results in a dataframe containing for each transaction from the function argument the customer_id, article_id and article features as given in the attributes_columns_names argument\n",
    "    big_df = pd.merge(articles_selected,transactions[[\"customer_id\",\"article_id\"]],on=[\"article_id\"])\n",
    "\n",
    "    # Adds a column containing for each transaction how often the customer has already bought clothing with the same attributes_columns_names as the article_id from the transaction\n",
    "    big_df = big_df.groupby(attributes_columns_names_plus_customer_id).size().reset_index(name=feature_name)\n",
    "\n",
    "    # Adds a column containing for each transaction the rank that the user gives to clothing with the same attributes_columns_names as the article_id in the transaction.\n",
    "    # In this case, rank means that if the article id is blue and the user bought lots of blue things, it will be one. If the article is red and red is the users second favourite, it will be 2 etc\n",
    "    # big_df[feature_name + \"_rank\"] =  big_df.groupby(\"customer_id\")[feature_name].rank(method=\"dense\",ascending=False)\n",
    "    return big_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "              customer_id  article_id     price  sales_channel_id  week\n29030503  272412481300040   778064028  0.008458                 1    95\n29030504  272412481300040   816592008  0.016932                 1    95\n29030505  272412481300040   621381021  0.033881                 1    95\n29030506  272412481300040   817477003  0.025407                 1    95\n29030507  272412481300040   899088002  0.025407                 1    95",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29030503</th>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030504</th>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030505</th>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030506</th>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030507</th>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": "    week  article_id  sales_channel_id\n0     96   108775015                 1\n1     96   108775044                 2\n2     96   110065001                 1\n3     96   110065002                 1\n4     96   111565001                 1\n..   ...         ...               ...\n95    96   228257001                 1\n96    96   228257002                 1\n97    96   228257003                 1\n98    96   228257004                 1\n99    96   228257008                 1\n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>week</th>\n      <th>article_id</th>\n      <th>sales_channel_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>96</td>\n      <td>108775015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96</td>\n      <td>108775044</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>96</td>\n      <td>110065001</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96</td>\n      <td>110065002</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>96</td>\n      <td>111565001</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>96</td>\n      <td>228257001</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>96</td>\n      <td>228257002</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>96</td>\n      <td>228257003</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>96</td>\n      <td>228257004</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>96</td>\n      <td>228257008</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture 6\n",
    "# Get for each week, for each article, through which sales_channel_id it was most commonly purchased\n",
    "most_common_sales_channel_id_per_item_per_week = transactions\\\n",
    "    .groupby(['week',\"article_id\"])['sales_channel_id'].value_counts() \\\n",
    "    .groupby(['week',\"article_id\"]).rank(method='dense', ascending=False) \\\n",
    "    .groupby(['week',\"article_id\"]).head(1).rename('temp').astype('int64').reset_index()\n",
    "most_common_sales_channel_id_per_item_per_week=most_common_sales_channel_id_per_item_per_week.drop(columns=[\"temp\"])\n",
    "# Probably not needed\n",
    "most_common_sales_channel_id_per_item_per_week = most_common_sales_channel_id_per_item_per_week.drop_duplicates(subset=[\"week\",\"article_id\"])\n",
    "print(most_common_sales_channel_id_per_item_per_week[\"sales_channel_id\"].min())\n",
    "print(most_common_sales_channel_id_per_item_per_week[\"sales_channel_id\"].max())\n",
    "# TODO: check if this is correct, I do think I need this because I also add 1 to week for some other thing that I merge this with\n",
    "most_common_sales_channel_id_per_item_per_week.week += 1\n",
    "most_common_sales_channel_id_per_item_per_week.head(100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "203292d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    week  article_id  bestseller_rank  product_code  prod_name  \\\n0     95   760084003                1        760084       1134   \n1     95   866731001                2        866731       3609   \n2     95   600886001                3        600886       1424   \n3     95   706016001                4        706016        172   \n4     95   372860002                5        372860      19652   \n..   ...         ...              ...           ...        ...   \n95    95   878013001               75        878013       1011   \n96    95   720125040               76        720125         99   \n97    95   610776071               77        610776         46   \n98    95   852174003               77        852174       3280   \n99    95   684209019               78        684209        272   \n\n    product_type_no  product_type_name  product_group_name  \\\n0               272                  0                   1   \n1               273                 15                   1   \n2                59                 20                   6   \n3               272                  0                   1   \n4               302                 14                   7   \n..              ...                ...                 ...   \n95              265                  1                   2   \n96              273                 15                   1   \n97              255                  3                   0   \n98              306                 13                   4   \n99              298                 31                   6   \n\n    graphical_appearance_no  graphical_appearance_name  ...  index_code  \\\n0                   1010016                          0  ...           1   \n1                   1010016                          0  ...           9   \n2                   1010016                          0  ...           7   \n3                   1010016                          0  ...           1   \n4                   1010016                          0  ...           7   \n..                      ...                        ...  ...         ...   \n95                  1010001                          1  ...           0   \n96                  1010005                          8  ...           9   \n97                  1010001                          1  ...           0   \n98                  1010016                          0  ...           9   \n99                  1010017                          3  ...           7   \n\n    index_name  index_group_no  index_group_name  section_no  section_name  \\\n0            1               2                 2          53             1   \n1            9              26                 4           5            21   \n2            7               1                 0          60            22   \n3            1               2                 2          53             1   \n4            7               1                 0          62            31   \n..         ...             ...               ...         ...           ...   \n95           0               1                 0          15             0   \n96           9              26                 4           5            21   \n97           0               1                 0          16            30   \n98           9              26                 4           5            21   \n99           7               1                 0          60            22   \n\n    garment_group_no  garment_group_name  detail_desc     price  \n0               1009                   5          847  0.025094  \n1               1005                   0         3130  0.024919  \n2               1018                  12          420  0.022980  \n3               1009                   5           30  0.033197  \n4               1021                  13          157  0.013193  \n..               ...                 ...          ...       ...  \n95              1013                   8         3544  0.049460  \n96              1005                   0          313  0.023239  \n97              1002                   2           60  0.008110  \n98              1005                   0         3945  0.024849  \n99              1018                  12          378  0.022544  \n\n[100 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>week</th>\n      <th>article_id</th>\n      <th>bestseller_rank</th>\n      <th>product_code</th>\n      <th>prod_name</th>\n      <th>product_type_no</th>\n      <th>product_type_name</th>\n      <th>product_group_name</th>\n      <th>graphical_appearance_no</th>\n      <th>graphical_appearance_name</th>\n      <th>...</th>\n      <th>index_code</th>\n      <th>index_name</th>\n      <th>index_group_no</th>\n      <th>index_group_name</th>\n      <th>section_no</th>\n      <th>section_name</th>\n      <th>garment_group_no</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>95</td>\n      <td>760084003</td>\n      <td>1</td>\n      <td>760084</td>\n      <td>1134</td>\n      <td>272</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1010016</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>53</td>\n      <td>1</td>\n      <td>1009</td>\n      <td>5</td>\n      <td>847</td>\n      <td>0.025094</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>95</td>\n      <td>866731001</td>\n      <td>2</td>\n      <td>866731</td>\n      <td>3609</td>\n      <td>273</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1010016</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>26</td>\n      <td>4</td>\n      <td>5</td>\n      <td>21</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>3130</td>\n      <td>0.024919</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>95</td>\n      <td>600886001</td>\n      <td>3</td>\n      <td>600886</td>\n      <td>1424</td>\n      <td>59</td>\n      <td>20</td>\n      <td>6</td>\n      <td>1010016</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>60</td>\n      <td>22</td>\n      <td>1018</td>\n      <td>12</td>\n      <td>420</td>\n      <td>0.022980</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>95</td>\n      <td>706016001</td>\n      <td>4</td>\n      <td>706016</td>\n      <td>172</td>\n      <td>272</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1010016</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>53</td>\n      <td>1</td>\n      <td>1009</td>\n      <td>5</td>\n      <td>30</td>\n      <td>0.033197</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>95</td>\n      <td>372860002</td>\n      <td>5</td>\n      <td>372860</td>\n      <td>19652</td>\n      <td>302</td>\n      <td>14</td>\n      <td>7</td>\n      <td>1010016</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>62</td>\n      <td>31</td>\n      <td>1021</td>\n      <td>13</td>\n      <td>157</td>\n      <td>0.013193</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>95</td>\n      <td>878013001</td>\n      <td>75</td>\n      <td>878013</td>\n      <td>1011</td>\n      <td>265</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1010001</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>1013</td>\n      <td>8</td>\n      <td>3544</td>\n      <td>0.049460</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>95</td>\n      <td>720125040</td>\n      <td>76</td>\n      <td>720125</td>\n      <td>99</td>\n      <td>273</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1010005</td>\n      <td>8</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>26</td>\n      <td>4</td>\n      <td>5</td>\n      <td>21</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>313</td>\n      <td>0.023239</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>95</td>\n      <td>610776071</td>\n      <td>77</td>\n      <td>610776</td>\n      <td>46</td>\n      <td>255</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1010001</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>16</td>\n      <td>30</td>\n      <td>1002</td>\n      <td>2</td>\n      <td>60</td>\n      <td>0.008110</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>95</td>\n      <td>852174003</td>\n      <td>77</td>\n      <td>852174</td>\n      <td>3280</td>\n      <td>306</td>\n      <td>13</td>\n      <td>4</td>\n      <td>1010016</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>26</td>\n      <td>4</td>\n      <td>5</td>\n      <td>21</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>3945</td>\n      <td>0.024849</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>95</td>\n      <td>684209019</td>\n      <td>78</td>\n      <td>684209</td>\n      <td>272</td>\n      <td>298</td>\n      <td>31</td>\n      <td>6</td>\n      <td>1010017</td>\n      <td>3</td>\n      <td>...</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>60</td>\n      <td>22</td>\n      <td>1018</td>\n      <td>12</td>\n      <td>378</td>\n      <td>0.022544</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final result of this cell contains for each week in transactions (training data, not full dataset) all articles that were sold, ranked by which ones sold best, their average price in that week, and all data normally included in the articles table.\n",
    "\n",
    "# Ranks for each week which items sold best\n",
    "# Lecture 6\n",
    "sales_nohead = transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(9999999999999).rename('bestseller_rank').astype('int64').reset_index()\n",
    "\n",
    "# Add article columns, e.g. garment_type_name\n",
    "sales_nohead = pd.merge(sales_nohead,articles,how=\"left\",on=[\"article_id\"])\n",
    "# Add average price of product in week\n",
    "sales_nohead = pd.merge(sales_nohead,mean_price,how=\"left\",on=[\"week\",\"article_id\"])\n",
    "sales_nohead.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['week', 'article_id', 'bestseller_rank', 'product_code', 'prod_name',\n       'product_type_no', 'product_type_name', 'product_group_name',\n       'graphical_appearance_no', 'graphical_appearance_name',\n       'colour_group_code', 'colour_group_name', 'perceived_colour_value_id',\n       'perceived_colour_value_name', 'perceived_colour_master_id',\n       'perceived_colour_master_name', 'department_no', 'department_name',\n       'index_code', 'index_name', 'index_group_no', 'index_group_name',\n       'section_no', 'section_name', 'garment_group_no', 'garment_group_name',\n       'detail_desc', 'price'],\n      dtype='object')"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_nohead.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ef902e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_of_(index_group_no)2.3837809562683105\n",
      "amount_of_(index_group_no)2.3837809562683105\n",
      "amount_of_(graphical_appearance_no)3.051215171813965\n",
      "amount_of_(graphical_appearance_no)3.051215171813965\n",
      "amount_of_(perceived_colour_value_id)2.9497110843658447\n",
      "amount_of_(perceived_colour_value_id)2.9497110843658447\n",
      "amount_of_(garment_group_no)3.250373363494873\n",
      "amount_of_(garment_group_no)3.250373363494873\n",
      "amount_of_(index_group_no_graphical_appearance_no)3.571826934814453\n",
      "amount_of_(index_group_no_graphical_appearance_no)3.571826934814453\n",
      "amount_of_(index_group_no_perceived_colour_value_id)3.7461466789245605\n",
      "amount_of_(index_group_no_perceived_colour_value_id)3.7461466789245605\n",
      "amount_of_(index_group_no_garment_group_no)3.910820722579956\n",
      "amount_of_(index_group_no_garment_group_no)3.910820722579956\n",
      "amount_of_(graphical_appearance_no_perceived_colour_value_id)4.089487552642822\n",
      "amount_of_(graphical_appearance_no_perceived_colour_value_id)4.089487552642822\n",
      "amount_of_(graphical_appearance_no_garment_group_no)4.294877529144287\n",
      "amount_of_(graphical_appearance_no_garment_group_no)4.294877529144287\n",
      "amount_of_(perceived_colour_value_id_garment_group_no)4.748805999755859\n",
      "amount_of_(perceived_colour_value_id_garment_group_no)4.749806880950928\n"
     ]
    }
   ],
   "source": [
    "# Columns to use for training\n",
    "# Useful because including garment_type_name and garment_type_no would be redundant\n",
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'bestseller_rank','importance']\n",
    "\n",
    "import itertools\n",
    "# For features generated by get_purchase_rank_df_of_attributes\n",
    "# Key: feature name\n",
    "# Value: list of strings: columns of article_ids the feature is based on\n",
    "new_features = dict()\n",
    "# For each column listed in article_features: say that we want to make a new feature out of it later on\n",
    "for feature_column in article_features:\n",
    "    new_features[\"amount_of_(\" + feature_column + \")\"] = [feature_column]\n",
    "# For each combination of 2 columns listed in article_features: say that we want to make a new feature out of it later on\n",
    "if do_combinations_of_features:\n",
    "    for double_features in itertools.combinations(article_features,2):\n",
    "        new_features[\"amount_of_(\" + double_features[0] + \"_\" + double_features[1] + \")\"] = [double_features[0],double_features[1]]\n",
    "\n",
    "all_new_features = []\n",
    "\n",
    "# Lecture 6\n",
    "# For everything I said I would make a new feature of:\n",
    "for feature_name,partial_columns in new_features.items():\n",
    "    tempname = str(feature_name)+\"_temp\"\n",
    "    time_start = time.time()\n",
    "    # Tell ranker to use new features\n",
    "    # Can be commented out to only use either count/rank\n",
    "    columns_to_use.append(feature_name)\n",
    "    columns_to_use.append(feature_name+\"_rank\")\n",
    "\n",
    "    current_week = min_week+1\n",
    "    feature_all_weeks = pd.DataFrame()\n",
    "    while current_week < test_week:\n",
    "        # Features are calculated on purchase history: taki into account not to incorporate future data\n",
    "        if feature_all_weeks.empty:\n",
    "            # See definition of get_purchase_rank_df_of_attributes for comments\n",
    "            # Get purchase count of articles with certain attributes in past X weeks\n",
    "            df_with_customer_id_and_features_and_count = get_purchase_count_df_of_attributes(transactions_full[(transactions_full.week < current_week) & (transactions_full.week > current_week-featuresBackXWeeks)],articles,partial_columns,feature_name)\n",
    "            df_with_customer_id_and_features_and_count[feature_name] = df_with_customer_id_and_features_and_count[feature_name].fillna(0)  # If user did not buy anything yet, set purchase count to 0\n",
    "            df_with_customer_id_and_features_and_count[\"week\"] = current_week\n",
    "        else:\n",
    "            # Objective of this section: calculate purchase counts for one week, and add those of last week to prevent calculating the entirety of get_purchase_count_df_of_attributes for the (near) full dataset every week\n",
    "            # Get purchase counts for this week\n",
    "            df_with_customer_id_and_features_and_count = get_purchase_count_df_of_attributes(transactions_full[(transactions_full.week == current_week)],articles,partial_columns,feature_name)\n",
    "            df_with_customer_id_and_features_and_count[feature_name] = df_with_customer_id_and_features_and_count[feature_name].fillna(0)  # If user did not buy anything this week, set purchase count to 0\n",
    "            # get purchase counts of last week\n",
    "            previous_week_purchase_counts = feature_all_weeks[(feature_all_weeks.week == (current_week - 1))]\n",
    "            # Rename purchase counts of this week\n",
    "            df_with_customer_id_and_features_and_count = df_with_customer_id_and_features_and_count.rename(columns={feature_name:tempname})\n",
    "            # For each customer and selected article feature, get purchase count of this one week and purchase counts up to and including previous week\n",
    "            df_with_customer_id_and_features_and_count = pd.merge(df_with_customer_id_and_features_and_count[[\"customer_id\",tempname]+partial_columns],previous_week_purchase_counts[[\"customer_id\",feature_name]+partial_columns],how=\"outer\",on=[[\"customer_id\"]+partial_columns][0])\n",
    "            # If customer had not purchased items with certain feature in either this week or before this week, set purchase count to 0\n",
    "            df_with_customer_id_and_features_and_count.fillna(0)\n",
    "            # Add purchase counts of this week and before this week to get purchase counts up to and including this week\n",
    "            df_with_customer_id_and_features_and_count[feature_name] = df_with_customer_id_and_features_and_count[feature_name] + df_with_customer_id_and_features_and_count[tempname]\n",
    "            # Remove temporary column used for calculation above\n",
    "            df_with_customer_id_and_features_and_count.drop(columns=[tempname],inplace=True)\n",
    "            # All purchase counts are up to and including this week\n",
    "            df_with_customer_id_and_features_and_count[\"week\"] = current_week\n",
    "\n",
    "        # Store all weeks in one dataframe\n",
    "        if feature_all_weeks.empty:\n",
    "            feature_all_weeks = df_with_customer_id_and_features_and_count.copy()\n",
    "        else:\n",
    "            feature_all_weeks = pd.concat([feature_all_weeks,df_with_customer_id_and_features_and_count])\n",
    "        current_week += 1\n",
    "\n",
    "    # Include ranking of feature: if blue was the users most bought garment color, each transaction where the customer buys blue things will be 1\n",
    "    feature_all_weeks[feature_name+\"_rank\"] = feature_all_weeks.groupby([\"customer_id\",\"week\"])[feature_name].rank(method=\"dense\",ascending=False)\n",
    "\n",
    "    # Keep list of all new feature dataframes + column names to merge them later\n",
    "    all_new_features.append([feature_all_weeks,partial_columns])\n",
    "\n",
    "    # Print time it took to generate feature\n",
    "    print(feature_name +  str(time.time() - time_start))\n",
    "    print(feature_name +  str(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "       customer_id  index_group_no  amount_of_(index_group_no)  week  \\\n0   28847241659200               1                         1.0    96   \n1   28847241659200              26                         1.0    96   \n2  200292573348128               1                         8.0    96   \n3  200292573348128               3                         1.0    96   \n4  272412481300040               1                         2.0    96   \n\n   amount_of_(index_group_no)_rank  \n0                              1.0  \n1                              1.0  \n2                              1.0  \n3                              2.0  \n4                              2.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>index_group_no</th>\n      <th>amount_of_(index_group_no)</th>\n      <th>week</th>\n      <th>amount_of_(index_group_no)_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28847241659200</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>96</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28847241659200</td>\n      <td>26</td>\n      <td>1.0</td>\n      <td>96</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>200292573348128</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>96</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>200292573348128</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>96</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>272412481300040</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>96</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_new_features[0][0].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "476cb56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      customer_id  garment_group_no  amount_of_garment_group_no\n0  28847241659200              1005                           1\n1  28847241659200              1007                           1\n2  28847241659200              1009                           1\n3  28847241659200              1010                           2\n4  41318098387474              1013                           1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>garment_group_no</th>\n      <th>amount_of_garment_group_no</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28847241659200</td>\n      <td>1005</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28847241659200</td>\n      <td>1007</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28847241659200</td>\n      <td>1009</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28847241659200</td>\n      <td>1010</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41318098387474</td>\n      <td>1013</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example application of get_purchase_rank_df_of_attributes\n",
    "# Assuming output is deterministic, you can see that customer 28847241659200 bought 2 articles from garment_group_no 1010 (as seen in amount_of_garment_group_no),\n",
    "# making it his favourite garment_group_no (as seen inn column amount_of_garment_group_no_rank)\n",
    "temp2 = get_purchase_count_df_of_attributes(transactions,articles,[\"garment_group_no\"],\"amount_of_garment_group_no\")\n",
    "temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2655d034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      customer_id  garment_group_no  amount_of_garment_group_no  \\\n0  28847241659200              1005                           1   \n1  28847241659200              1007                           1   \n2  28847241659200              1009                           1   \n3  28847241659200              1010                           2   \n4  41318098387474              1013                           1   \n\n   amount_of_garment_group_no_rank  \n0                              2.0  \n1                              2.0  \n2                              2.0  \n3                              1.0  \n4                              1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>garment_group_no</th>\n      <th>amount_of_garment_group_no</th>\n      <th>amount_of_garment_group_no_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28847241659200</td>\n      <td>1005</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28847241659200</td>\n      <td>1007</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28847241659200</td>\n      <td>1009</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28847241659200</td>\n      <td>1010</td>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41318098387474</td>\n      <td>1013</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example application of get_purchase_rank_df_of_attributes\n",
    "# Assuming output is deterministic, you can see that customer 28847241659200 bought 2 articles from garment_group_no 1010 (as seen in amount_of_garment_group_no),\n",
    "# making it his favourite garment_group_no (as seen inn column amount_of_garment_group_no_rank)\n",
    "temp2 = get_purchase_rank_df_of_attributes(transactions,articles,[\"garment_group_no\"],\"amount_of_garment_group_no\")\n",
    "temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3df00645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              customer_id  article_id     price  sales_channel_id  week\n29030503  272412481300040   778064028  0.008458                 1    95\n29030504  272412481300040   816592008  0.016932                 1    95\n29030505  272412481300040   621381021  0.033881                 1    95\n29030506  272412481300040   817477003  0.025407                 1    95\n29030507  272412481300040   899088002  0.025407                 1    95",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29030503</th>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030504</th>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030505</th>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030506</th>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030507</th>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56263b7a",
   "metadata": {},
   "source": [
    "# Generating candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd43fcd",
   "metadata": {},
   "source": [
    "### Last purchase candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca3b5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result of cell:\n",
    "# Candidate for week X: item bought in previous purchase week\n",
    "\n",
    "c2weeks = transactions.groupby('customer_id')['week'].unique()\n",
    "\n",
    "c2weeks2shifted_weeks = {}\n",
    "\n",
    "for c_id, weeks in c2weeks.items():\n",
    "    c2weeks2shifted_weeks[c_id] = {}\n",
    "    for i in range(weeks.shape[0]-1):\n",
    "        c2weeks2shifted_weeks[c_id][weeks[i]] = weeks[i+1]\n",
    "    c2weeks2shifted_weeks[c_id][weeks[-1]] = test_week\n",
    "\n",
    "candidates_last_purchase = transactions.copy()\n",
    "\n",
    "weeks = []\n",
    "for i, (c_id, week) in enumerate(zip(transactions['customer_id'], transactions['week'])):\n",
    "    weeks.append(c2weeks2shifted_weeks[c_id][week])\n",
    "\n",
    "# Candidate for week X: item bought in previous purchase week\n",
    "candidates_last_purchase.week=weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a29c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   customer_id  article_id     price  sales_channel_id  week\n",
      "29030503       272412481300040   778064028  0.008458                 1    96\n",
      "29030504       272412481300040   816592008  0.016932                 1    96\n",
      "29030505       272412481300040   621381021  0.033881                 1    96\n",
      "29030506       272412481300040   817477003  0.025407                 1    96\n",
      "29030507       272412481300040   899088002  0.025407                 1    96\n",
      "...                        ...         ...       ...               ...   ...\n",
      "31774722  18439937050817258297   891591003  0.084729                 2   105\n",
      "31774723  18439937050817258297   869706005  0.084729                 2   105\n",
      "31779097  18440902715633436014   918894002  0.016932                 1   105\n",
      "31779098  18440902715633436014   761269001  0.016932                 1   105\n",
      "31780475  18443633011701112574   914868002  0.033881                 1   105\n",
      "\n",
      "[2762872 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(candidates_last_purchase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077cf9c",
   "metadata": {},
   "source": [
    "### Bestsellers candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07eb3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              customer_id  article_id     price  sales_channel_id  week\n29030503  272412481300040   778064028  0.008458                 1    96\n29030504  272412481300040   816592008  0.016932                 1    96\n29030505  272412481300040   621381021  0.033881                 1    96\n29030506  272412481300040   817477003  0.025407                 1    96\n29030507  272412481300040   899088002  0.025407                 1    96",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29030503</th>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>29030504</th>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>29030505</th>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>29030506</th>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>29030507</th>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_last_purchase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72e132a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              customer_id  article_id     price  sales_channel_id  week\n29030503  272412481300040   778064028  0.008458                 1    95\n29030504  272412481300040   816592008  0.016932                 1    95\n29030505  272412481300040   621381021  0.033881                 1    95\n29030506  272412481300040   817477003  0.025407                 1    95\n29030507  272412481300040   899088002  0.025407                 1    95",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29030503</th>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030504</th>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030505</th>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030506</th>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29030507</th>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47f568db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "week  article_id\n95    760084003     1\n      866731001     2\n      600886001     3\n      706016001     4\n      372860002     5\nName: bestseller_rank, dtype: int8"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# bestseller rank doet niets: ranking is belangrijk om de bestsellers te vinden, maar de kolom zelf mag weg\n",
    "# For each week, list of ranked 12 bestsellers\n",
    "sales = transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d25be79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "               customer_id  sales_channel_id  week\n29030503   272412481300040                 1    95\n29064059  1456826891333599                 1    95\n29067103  2133687643102426                 2    95\n29027487  6010692573790711                 1    95\n29046403  6171059100114610                 2    95",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29030503</th>\n      <td>272412481300040</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29064059</th>\n      <td>1456826891333599</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29067103</th>\n      <td>2133687643102426</td>\n      <td>2</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29027487</th>\n      <td>6010692573790711</td>\n      <td>1</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>29046403</th>\n      <td>6171059100114610</td>\n      <td>2</td>\n      <td>95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1\n",
    "# Per week lijst van customers die IETS gekocht hebben\n",
    "unique_transactions = transactions \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()\n",
    "unique_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "514b77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Per week lijst van customers die IETS gekocht hebben\n",
    "# MERGE\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "\n",
    "# Per week, per customer die iets gekocht heeft, de 12 bestverkochte uit DE (algemeen, niet per customer) vorige week\n",
    "candidates_bestsellers = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")\n",
    "\n",
    "# unique_transactions = Per week lijst van customers die IETS gekocht hebben\n",
    "# Voor elke customer waar we iets over weten en dus een voorspelling van willen doen, houden we 1 keer de customer id over en zetten we de week op test_week, want dat is wanneer we willen voorspellen wat hij koopt\n",
    "test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "test_set_transactions.week = test_week\n",
    "\n",
    "\n",
    "# Voor elke customer waar we iets over weten en dus een voorspelling van willen doen, houden we 1 keer de customer id over en zetten we de week op test_week, want dat is wanneer we willen voorspellen wat hij koopt\n",
    "# MERGE\n",
    "# Voor elke week, zegt ge koop het best verkochte item in de vorige week\n",
    "\n",
    "# Resultaat: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek\n",
    "candidates_bestsellers_test_week = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")\n",
    "\n",
    "# Per week, per customer die iets gekocht heeft, de 12 bestverkochte uit DE (algemeen) vorige week\n",
    "# Resultaat: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek\n",
    "candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# Lecture 6\n",
    "# Objective of this cell: for each feature based on purchase count of article with certain features, get most liked feature, look up bestselling item with that feature of last week, add it as negative sample.\n",
    "all_history_based_suggestions = pd.DataFrame()\n",
    "for feature_df_partial_columns in all_new_features:\n",
    "    # Dataframe: per week: customer_id, article features, purchase counts of article features, ranks of article features\n",
    "    feature_df = feature_df_partial_columns[0].copy(deep=True)\n",
    "    # List of strings: Column names on which the new features are based\n",
    "    partial_columns = feature_df_partial_columns[1]\n",
    "\n",
    "    # Get name of column containing rank (where 1 means favourite). Probably a cleaner way to do this\n",
    "    feature_df_columns = list(feature_df.columns)\n",
    "    rank_column = None\n",
    "    # For each column in the df, check if the column name contains \"_rank\"\n",
    "    for column_name in feature_df_columns:\n",
    "        if \"_rank\" in column_name:\n",
    "            rank_column = column_name\n",
    "            break\n",
    "\n",
    "    # Only keep attributes that the customer actually prefers\n",
    "    feature_df = feature_df[feature_df[rank_column] == 1]\n",
    "    # Too many negative samples is probably bad, so if attributes are tied for favourite, break tie randomly (should still be deterministic because drop_duplicates keeps topmost rows)\n",
    "    # Result: for each week, for each customer, one favourite partial_columns\n",
    "    feature_df = feature_df.drop_duplicates(subset=[\"customer_id\",\"week\"])\n",
    "\n",
    "    # Get all sales for relevant weeks (sales_nohead is only training set), but don't copy unused columns\n",
    "    sales_selected_feature = sales_nohead[[\"week\",\"article_id\",\"price\"]+partial_columns].copy(deep=True)\n",
    "\n",
    "    # I want to give cutomers recommendations based on the previous week, otherwise I would be taking future data into account, including the actual purchases the user will make in the future.\n",
    "    # By adding one to each week, this means that week now means \"What was popular last week?\"\n",
    "    sales_selected_feature.week += 1\n",
    "\n",
    "    # If the same feature value (e.g. \"blue\" for colour) appears multiple times in a week, drop duplicates\n",
    "    # This keeps the first row where the value appears, which is the bestselling one (sales_nohead is sorted on bestselling)\n",
    "    sales_selected_feature = sales_selected_feature.drop_duplicates(subset=partial_columns+[\"week\"])\n",
    "\n",
    "    # For each week: For each customer + his favourite value, merge with the most popular item with that value (of last week)\n",
    "    feature_df = pd.merge(feature_df,sales_selected_feature,on=[\"week\"]+partial_columns,how=\"left\")\n",
    "\n",
    "    # These are negative samples. If it turns out the user did actually buy it, the negative sample will be removed later on\n",
    "    feature_df[\"purchased\"] = 0\n",
    "\n",
    "    # Add sales channel by picking most common one for that article last week\n",
    "    # TODO: check if correct: The  \"last week\" part was week += 1, which has also been done on the second df. Is this correct?\n",
    "    feature_df = pd.merge(feature_df,most_common_sales_channel_id_per_item_per_week,on=[\"week\",\"article_id\"],how=\"left\")\n",
    "\n",
    "    # Drop columns not immediately needed anymore\n",
    "    feature_df = feature_df[[\"customer_id\",\"article_id\",\"price\",\"sales_channel_id\",\"week\",\"purchased\"]]\n",
    "\n",
    "    if all_history_based_suggestions.empty:\n",
    "        all_history_based_suggestions= feature_df.copy(deep=True)\n",
    "    else:\n",
    "        all_history_based_suggestions = pd.concat([all_history_based_suggestions,feature_df])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "   week  article_id     price  perceived_colour_value_id  garment_group_no\n0    96   760084003  0.025094                          4              1009\n1    96   866731001  0.024919                          4              1005\n2    96   600886001  0.022980                          4              1018\n4    96   372860002  0.013193                          3              1021\n5    96   610776002  0.008318                          4              1002",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>week</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>perceived_colour_value_id</th>\n      <th>garment_group_no</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>96</td>\n      <td>760084003</td>\n      <td>0.025094</td>\n      <td>4</td>\n      <td>1009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96</td>\n      <td>866731001</td>\n      <td>0.024919</td>\n      <td>4</td>\n      <td>1005</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>96</td>\n      <td>600886001</td>\n      <td>0.022980</td>\n      <td>4</td>\n      <td>1018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>96</td>\n      <td>372860002</td>\n      <td>0.013193</td>\n      <td>3</td>\n      <td>1021</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>96</td>\n      <td>610776002</td>\n      <td>0.008318</td>\n      <td>4</td>\n      <td>1002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_selected_feature.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "\n",
    "# Combining transactions and candidates / negative examples\n",
    "transactions['purchased'] = 1\n",
    "\n",
    "# candidates_last_purchase: Candidate for week X: item bought in previous purchase week, negative samples\n",
    "# candidates_bestsellers: voor elke customer waarvoor we iets kunnen voorspellen, geven we de 12 bestseller van testweek-1 als candidate voor testweek, negative samples\n",
    "# transactions: letterlijk gewoon transactions, positive samples\n",
    "# Lecture 6\n",
    "if add_history_candidates:\n",
    "    data = pd.concat([transactions, candidates_last_purchase, candidates_bestsellers,all_history_based_suggestions])\n",
    "else:\n",
    "    data = pd.concat([transactions, candidates_last_purchase, candidates_bestsellers])\n",
    "# For real transactions, purchased was 1 (positive sample). This sets the value to 0 for negative samples\n",
    "data.purchased.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d18073a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              customer_id  article_id     price  sales_channel_id  week  \\\n29030503  272412481300040   778064028  0.008458                 1    95   \n29030504  272412481300040   816592008  0.016932                 1    95   \n29030505  272412481300040   621381021  0.033881                 1    95   \n29030506  272412481300040   817477003  0.025407                 1    95   \n29030507  272412481300040   899088002  0.025407                 1    95   \n\n          purchased  \n29030503        1.0  \n29030504        1.0  \n29030505        1.0  \n29030506        1.0  \n29030507        1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29030503</th>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29030504</th>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29030505</th>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29030506</th>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29030507</th>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "91827ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   customer_id  article_id  week  importance\n",
      "0               28847241659200   372860002    96           4\n",
      "1               28847241659200   448509014   105           1\n",
      "2               28847241659200   547780003    96           1\n",
      "3               28847241659200   600886001    96           3\n",
      "4               28847241659200   610776002    96           1\n",
      "...                        ...         ...   ...         ...\n",
      "18635253  18446737527580148316   923758001   104           1\n",
      "18635254  18446737527580148316   923758001   105           1\n",
      "18635255  18446737527580148316   924243001   104           1\n",
      "18635256  18446737527580148316   924243001   105           1\n",
      "18635257  18446737527580148316   924243002   105           1\n",
      "\n",
      "[18635258 rows x 4 columns]\n",
      "0\n",
      "74\n",
      "1.0621517018975535\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": "       customer_id  article_id     price  sales_channel_id  week  purchased  \\\n0  272412481300040   778064028  0.008458                 1    95        1.0   \n1  272412481300040   816592008  0.016932                 1    95        1.0   \n2  272412481300040   621381021  0.033881                 1    95        1.0   \n3  272412481300040   817477003  0.025407                 1    95        1.0   \n4  272412481300040   899088002  0.025407                 1    95        1.0   \n\n   importance  \n0           1  \n1           1  \n2           1  \n3           1  \n4           1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Voor elke week: kijk alle keren dat customer het artikel koopt OF voorgesteld krijgt (kolom importance), en hou indien gekocht enkel de rij met purchased 1 (dit is automatisch zo door de volgorde van de concats in de vorige cel)\n",
    "# Opmerking: candidates voor week 105 zijn allemaal purchased==0\n",
    "brak = data.groupby(['customer_id', 'article_id', 'week']).size().reset_index(name=\"importance\")\n",
    "print(brak)\n",
    "data.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    brak,\n",
    "    on=['customer_id', 'article_id', 'week']\n",
    ")\n",
    "\n",
    "data.purchased.mean()\n",
    "print(data[\"importance\"].isna().sum())\n",
    "print(data[\"importance\"].max())\n",
    "print(data[\"importance\"].mean())\n",
    "print(data[\"importance\"].min())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22588375",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d315fe74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "week  article_id\n95    760084003     1\n      866731001     2\n      600886001     3\n      706016001     4\n      372860002     5\nName: bestseller_rank, dtype: int8"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6cbea6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   week  article_id  bestseller_rank     price\n0    96   760084003                1  0.025094\n1    96   866731001                2  0.024919\n2    96   600886001                3  0.022980\n3    96   706016001                4  0.033197\n4    96   372860002                5  0.013193",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>week</th>\n      <th>article_id</th>\n      <th>bestseller_rank</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>96</td>\n      <td>760084003</td>\n      <td>1</td>\n      <td>0.025094</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96</td>\n      <td>866731001</td>\n      <td>2</td>\n      <td>0.024919</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>96</td>\n      <td>600886001</td>\n      <td>3</td>\n      <td>0.022980</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96</td>\n      <td>706016001</td>\n      <td>4</td>\n      <td>0.033197</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>96</td>\n      <td>372860002</td>\n      <td>5</td>\n      <td>0.013193</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestsellers_previous_week.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac183274",
   "metadata": {},
   "source": [
    "### Add bestseller information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f28957eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Van echte transacties: bestseller onbekend, check candidates om te kijken of er toen wel bestseller rank was. Zo nee, vul later met fillna\n",
    "# Lecture 6\n",
    "# Using sales_nohead is supposed to give the true bestseller rank for any item, even if not top 12\n",
    "# TODO: does sales_nohead contain all info needed for this?\n",
    "if bestsellerFiller is None:\n",
    "    full_bestsellers_previous_week = sales_nohead.copy(deep=True)\n",
    "    full_bestsellers_previous_week.week += 1\n",
    "    data = pd.merge(\n",
    "        data,\n",
    "        sales_nohead[['week', 'article_id', 'bestseller_rank']],\n",
    "        on=['week', 'article_id'],\n",
    "        how='left'\n",
    "    )\n",
    "else:\n",
    "    data = pd.merge(\n",
    "    data,\n",
    "    bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "    on=['week', 'article_id'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c46f8fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       customer_id  article_id     price  sales_channel_id  week  purchased  \\\n0  272412481300040   778064028  0.008458                 1    95        1.0   \n1  272412481300040   816592008  0.016932                 1    95        1.0   \n2  272412481300040   621381021  0.033881                 1    95        1.0   \n3  272412481300040   817477003  0.025407                 1    95        1.0   \n4  272412481300040   899088002  0.025407                 1    95        1.0   \n\n   importance  bestseller_rank  \n0           1              NaN  \n1           1              NaN  \n2           1              NaN  \n3           1              NaN  \n4           1              NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n      <th>importance</th>\n      <th>bestseller_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>272412481300040</td>\n      <td>778064028</td>\n      <td>0.008458</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>272412481300040</td>\n      <td>816592008</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>272412481300040</td>\n      <td>621381021</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>272412481300040</td>\n      <td>817477003</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>272412481300040</td>\n      <td>899088002</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>95</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3e7d3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijder eerste week omdat er voor eerste week geen bestsellers_previous_week is\n",
    "data = data[data.week != data.week.min()]  # Presumably to make sure no data of an incomplete week is included?\n",
    "# Indien geen bestseller: keislecht verkocht (default bestsellerFiller is 999, wat betekent dat er zogezegd 998 beter verkopende items zijn)\n",
    "if bestsellerFiller is not None:\n",
    "    data.bestseller_rank.fillna(bestsellerFiller, inplace=True)\n",
    "else:\n",
    "    # https://datatofish.com/count-nan-pandas-dataframe/\n",
    "    print(data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5fdc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per customer per week alle transacties en/of candidates\n",
    "\n",
    "# Steek bij elke aankoop alle info over gekocht article erbij\n",
    "data = pd.merge(data, articles, on='article_id', how='left')\n",
    "# Steek bij elke aankoop alle info over customer erbij\n",
    "data = pd.merge(data, customers, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e3a737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorteer eerst op week, dan per week op customer\n",
    "data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "14328601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      customer_id  article_id     price  sales_channel_id  week  purchased  \\\n0  28847241659200   887770001  0.016932                 1    96        1.0   \n1  28847241659200   762846001  0.025407                 1    96        0.0   \n2  28847241659200   829308001  0.033881                 1    96        0.0   \n3  28847241659200   760084003  0.025094                 1    96        0.0   \n4  28847241659200   866731001  0.024919                 1    96        0.0   \n\n   importance  bestseller_rank  product_code  prod_name  ...  section_name  \\\n0           1            999.0        887770        727  ...            10   \n1           1            999.0        762846        472  ...             7   \n2           1            999.0        829308      11402  ...            21   \n3           2              1.0        760084       1134  ...             1   \n4           3              2.0        866731       3609  ...            21   \n\n   garment_group_no  garment_group_name  detail_desc  FN  Active  \\\n0              1010                   6         3692   1       1   \n1              1010                   6          492   1       1   \n2              1005                   0         9082   1       1   \n3              1009                   5          847   1       1   \n4              1005                   0         3130   1       1   \n\n   club_member_status  fashion_news_frequency  age  postal_code  \n0                   0                       1   21        57896  \n1                   0                       1   21        57896  \n2                   0                       1   21        57896  \n3                   0                       1   21        57896  \n4                   0                       1   21        57896  \n\n[5 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n      <th>importance</th>\n      <th>bestseller_rank</th>\n      <th>product_code</th>\n      <th>prod_name</th>\n      <th>...</th>\n      <th>section_name</th>\n      <th>garment_group_no</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n      <th>FN</th>\n      <th>Active</th>\n      <th>club_member_status</th>\n      <th>fashion_news_frequency</th>\n      <th>age</th>\n      <th>postal_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28847241659200</td>\n      <td>887770001</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>96</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>999.0</td>\n      <td>887770</td>\n      <td>727</td>\n      <td>...</td>\n      <td>10</td>\n      <td>1010</td>\n      <td>6</td>\n      <td>3692</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28847241659200</td>\n      <td>762846001</td>\n      <td>0.025407</td>\n      <td>1</td>\n      <td>96</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>999.0</td>\n      <td>762846</td>\n      <td>472</td>\n      <td>...</td>\n      <td>7</td>\n      <td>1010</td>\n      <td>6</td>\n      <td>492</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28847241659200</td>\n      <td>829308001</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>96</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>999.0</td>\n      <td>829308</td>\n      <td>11402</td>\n      <td>...</td>\n      <td>21</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>9082</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28847241659200</td>\n      <td>760084003</td>\n      <td>0.025094</td>\n      <td>1</td>\n      <td>96</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>760084</td>\n      <td>1134</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1009</td>\n      <td>5</td>\n      <td>847</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28847241659200</td>\n      <td>866731001</td>\n      <td>0.024919</td>\n      <td>1</td>\n      <td>96</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>866731</td>\n      <td>3609</td>\n      <td>...</td>\n      <td>21</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>3130</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>57896</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9b151ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index_group_no']\n",
      "['graphical_appearance_no']\n",
      "['perceived_colour_value_id']\n",
      "['garment_group_no']\n",
      "['index_group_no', 'graphical_appearance_no']\n",
      "['index_group_no', 'perceived_colour_value_id']\n",
      "['index_group_no', 'garment_group_no']\n",
      "['graphical_appearance_no', 'perceived_colour_value_id']\n",
      "['graphical_appearance_no', 'garment_group_no']\n",
      "['perceived_colour_value_id', 'garment_group_no']\n"
     ]
    }
   ],
   "source": [
    "# lecture 6\n",
    "for feature_df_partial_columns in all_new_features:\n",
    "    print(feature_df_partial_columns[1])\n",
    "    # merge new features into training data\n",
    "    data = pd.merge(data,feature_df_partial_columns[0],on=([\"customer_id\",\"week\"] + feature_df_partial_columns[1]),how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2eebc03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d83b869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             customer_id  article_id     price  sales_channel_id  week  \\\n11763121  28847241659200   925246001  0.128797                 2   105   \n11763122  28847241659200   924243001  0.041535                 1   105   \n11763123  28847241659200   924243002  0.041877                 1   105   \n11763124  28847241659200   918522001  0.041435                 1   105   \n11763125  28847241659200   923758001  0.033462                 1   105   \n\n          purchased  importance  bestseller_rank  product_code  prod_name  \\\n11763121        0.0           1            999.0        925246      25454   \n11763122        0.0           1              1.0        924243      19190   \n11763123        0.0           1              2.0        924243      19190   \n11763124        0.0           1              3.0        918522      26372   \n11763125        0.0           1              4.0        923758      19359   \n\n          ...  amount_of_(index_group_no_perceived_colour_value_id)  \\\n11763121  ...                                                NaN      \n11763122  ...                                                NaN      \n11763123  ...                                                NaN      \n11763124  ...                                                NaN      \n11763125  ...                                                NaN      \n\n          amount_of_(index_group_no_perceived_colour_value_id)_rank  \\\n11763121                                                NaN           \n11763122                                                NaN           \n11763123                                                NaN           \n11763124                                                NaN           \n11763125                                                NaN           \n\n          amount_of_(index_group_no_garment_group_no)  \\\n11763121                                          NaN   \n11763122                                          NaN   \n11763123                                          NaN   \n11763124                                          NaN   \n11763125                                          NaN   \n\n          amount_of_(index_group_no_garment_group_no)_rank  \\\n11763121                                               NaN   \n11763122                                               NaN   \n11763123                                               NaN   \n11763124                                               NaN   \n11763125                                               NaN   \n\n          amount_of_(graphical_appearance_no_perceived_colour_value_id)  \\\n11763121                                                NaN               \n11763122                                                NaN               \n11763123                                                NaN               \n11763124                                                NaN               \n11763125                                                NaN               \n\n          amount_of_(graphical_appearance_no_perceived_colour_value_id)_rank  \\\n11763121                                                NaN                    \n11763122                                                NaN                    \n11763123                                                NaN                    \n11763124                                                NaN                    \n11763125                                                NaN                    \n\n          amount_of_(graphical_appearance_no_garment_group_no)  \\\n11763121                                                NaN      \n11763122                                                NaN      \n11763123                                                NaN      \n11763124                                                NaN      \n11763125                                                NaN      \n\n          amount_of_(graphical_appearance_no_garment_group_no)_rank  \\\n11763121                                                NaN           \n11763122                                                NaN           \n11763123                                                NaN           \n11763124                                                NaN           \n11763125                                                NaN           \n\n          amount_of_(perceived_colour_value_id_garment_group_no)  \\\n11763121                                                NaN        \n11763122                                                NaN        \n11763123                                                NaN        \n11763124                                                NaN        \n11763125                                                NaN        \n\n          amount_of_(perceived_colour_value_id_garment_group_no)_rank  \n11763121                                                NaN            \n11763122                                                NaN            \n11763123                                                NaN            \n11763124                                                NaN            \n11763125                                                NaN            \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n      <th>purchased</th>\n      <th>importance</th>\n      <th>bestseller_rank</th>\n      <th>product_code</th>\n      <th>prod_name</th>\n      <th>...</th>\n      <th>amount_of_(index_group_no_perceived_colour_value_id)</th>\n      <th>amount_of_(index_group_no_perceived_colour_value_id)_rank</th>\n      <th>amount_of_(index_group_no_garment_group_no)</th>\n      <th>amount_of_(index_group_no_garment_group_no)_rank</th>\n      <th>amount_of_(graphical_appearance_no_perceived_colour_value_id)</th>\n      <th>amount_of_(graphical_appearance_no_perceived_colour_value_id)_rank</th>\n      <th>amount_of_(graphical_appearance_no_garment_group_no)</th>\n      <th>amount_of_(graphical_appearance_no_garment_group_no)_rank</th>\n      <th>amount_of_(perceived_colour_value_id_garment_group_no)</th>\n      <th>amount_of_(perceived_colour_value_id_garment_group_no)_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11763121</th>\n      <td>28847241659200</td>\n      <td>925246001</td>\n      <td>0.128797</td>\n      <td>2</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>999.0</td>\n      <td>925246</td>\n      <td>25454</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11763122</th>\n      <td>28847241659200</td>\n      <td>924243001</td>\n      <td>0.041535</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>924243</td>\n      <td>19190</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11763123</th>\n      <td>28847241659200</td>\n      <td>924243002</td>\n      <td>0.041877</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>924243</td>\n      <td>19190</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11763124</th>\n      <td>28847241659200</td>\n      <td>918522001</td>\n      <td>0.041435</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>918522</td>\n      <td>26372</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11763125</th>\n      <td>28847241659200</td>\n      <td>923758001</td>\n      <td>0.033462</td>\n      <td>1</td>\n      <td>105</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>923758</td>\n      <td>19359</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Niet trainen op laatste week want anders hebben we geen test set\n",
    "train = data[data.week != test_week]\n",
    "# Laatste week, indien item in beide candidate sets, drop duplicates.\n",
    "test = data[data.week==test_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "71d57fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   customer_id  article_id     price  sales_channel_id  week  \\\n",
      "0               28847241659200   887770001  0.016932                 1    96   \n",
      "1               28847241659200   762846001  0.025407                 1    96   \n",
      "2               28847241659200   829308001  0.033881                 1    96   \n",
      "3               28847241659200   760084003  0.025094                 1    96   \n",
      "4               28847241659200   866731001  0.024919                 1    96   \n",
      "...                        ...         ...       ...               ...   ...   \n",
      "11763105  18446737527580148316   547780001  0.023712                 2   104   \n",
      "11763106  18446737527580148316   763988001  0.023712                 2   104   \n",
      "11763107  18446737527580148316   763988003  0.023712                 2   104   \n",
      "11763108  18446737527580148316   547780040  0.023712                 2   104   \n",
      "11763109  18446737527580148316   909370001  0.032947                 2   104   \n",
      "\n",
      "          purchased  importance  bestseller_rank  product_code  prod_name  \\\n",
      "0               1.0           1            999.0        887770        727   \n",
      "1               0.0           1            999.0        762846        472   \n",
      "2               0.0           1            999.0        829308      11402   \n",
      "3               0.0           2              1.0        760084       1134   \n",
      "4               0.0           3              2.0        866731       3609   \n",
      "...             ...         ...              ...           ...        ...   \n",
      "11763105        1.0           1            999.0        547780       1272   \n",
      "11763106        1.0           1            999.0        763988       1204   \n",
      "11763107        1.0           1            999.0        763988       1204   \n",
      "11763108        1.0           1            999.0        547780       1272   \n",
      "11763109        0.0           1              1.0        909370      23319   \n",
      "\n",
      "          ...  amount_of_(index_group_no_perceived_colour_value_id)  \\\n",
      "0         ...                                                NaN      \n",
      "1         ...                                                1.0      \n",
      "2         ...                                                1.0      \n",
      "3         ...                                                NaN      \n",
      "4         ...                                                1.0      \n",
      "...       ...                                                ...      \n",
      "11763105  ...                                                NaN      \n",
      "11763106  ...                                                NaN      \n",
      "11763107  ...                                                NaN      \n",
      "11763108  ...                                                NaN      \n",
      "11763109  ...                                                NaN      \n",
      "\n",
      "          amount_of_(index_group_no_perceived_colour_value_id)_rank  \\\n",
      "0                                                       NaN           \n",
      "1                                                       1.0           \n",
      "2                                                       1.0           \n",
      "3                                                       NaN           \n",
      "4                                                       1.0           \n",
      "...                                                     ...           \n",
      "11763105                                                NaN           \n",
      "11763106                                                NaN           \n",
      "11763107                                                NaN           \n",
      "11763108                                                NaN           \n",
      "11763109                                                NaN           \n",
      "\n",
      "          amount_of_(index_group_no_garment_group_no)  \\\n",
      "0                                                 1.0   \n",
      "1                                                 1.0   \n",
      "2                                                 1.0   \n",
      "3                                                 NaN   \n",
      "4                                                 1.0   \n",
      "...                                               ...   \n",
      "11763105                                          NaN   \n",
      "11763106                                          NaN   \n",
      "11763107                                          NaN   \n",
      "11763108                                          NaN   \n",
      "11763109                                          NaN   \n",
      "\n",
      "          amount_of_(index_group_no_garment_group_no)_rank  \\\n",
      "0                                                      1.0   \n",
      "1                                                      1.0   \n",
      "2                                                      1.0   \n",
      "3                                                      NaN   \n",
      "4                                                      1.0   \n",
      "...                                                    ...   \n",
      "11763105                                               NaN   \n",
      "11763106                                               NaN   \n",
      "11763107                                               NaN   \n",
      "11763108                                               NaN   \n",
      "11763109                                               NaN   \n",
      "\n",
      "          amount_of_(graphical_appearance_no_perceived_colour_value_id)  \\\n",
      "0                                                       1.0               \n",
      "1                                                       1.0               \n",
      "2                                                       1.0               \n",
      "3                                                       1.0               \n",
      "4                                                       1.0               \n",
      "...                                                     ...               \n",
      "11763105                                                NaN               \n",
      "11763106                                                NaN               \n",
      "11763107                                                NaN               \n",
      "11763108                                                NaN               \n",
      "11763109                                                NaN               \n",
      "\n",
      "          amount_of_(graphical_appearance_no_perceived_colour_value_id)_rank  \\\n",
      "0                                                       1.0                    \n",
      "1                                                       1.0                    \n",
      "2                                                       1.0                    \n",
      "3                                                       1.0                    \n",
      "4                                                       1.0                    \n",
      "...                                                     ...                    \n",
      "11763105                                                NaN                    \n",
      "11763106                                                NaN                    \n",
      "11763107                                                NaN                    \n",
      "11763108                                                NaN                    \n",
      "11763109                                                NaN                    \n",
      "\n",
      "          amount_of_(graphical_appearance_no_garment_group_no)  \\\n",
      "0                                                       1.0      \n",
      "1                                                       1.0      \n",
      "2                                                       1.0      \n",
      "3                                                       NaN      \n",
      "4                                                       1.0      \n",
      "...                                                     ...      \n",
      "11763105                                                NaN      \n",
      "11763106                                                NaN      \n",
      "11763107                                                NaN      \n",
      "11763108                                                NaN      \n",
      "11763109                                                NaN      \n",
      "\n",
      "          amount_of_(graphical_appearance_no_garment_group_no)_rank  \\\n",
      "0                                                       1.0           \n",
      "1                                                       1.0           \n",
      "2                                                       1.0           \n",
      "3                                                       NaN           \n",
      "4                                                       1.0           \n",
      "...                                                     ...           \n",
      "11763105                                                NaN           \n",
      "11763106                                                NaN           \n",
      "11763107                                                NaN           \n",
      "11763108                                                NaN           \n",
      "11763109                                                NaN           \n",
      "\n",
      "          amount_of_(perceived_colour_value_id_garment_group_no)  \\\n",
      "0                                                       NaN        \n",
      "1                                                       1.0        \n",
      "2                                                       1.0        \n",
      "3                                                       NaN        \n",
      "4                                                       1.0        \n",
      "...                                                     ...        \n",
      "11763105                                                NaN        \n",
      "11763106                                                NaN        \n",
      "11763107                                                NaN        \n",
      "11763108                                                NaN        \n",
      "11763109                                                NaN        \n",
      "\n",
      "          amount_of_(perceived_colour_value_id_garment_group_no)_rank  \n",
      "0                                                       NaN            \n",
      "1                                                       1.0            \n",
      "2                                                       1.0            \n",
      "3                                                       NaN            \n",
      "4                                                       1.0            \n",
      "...                                                     ...            \n",
      "11763105                                                NaN            \n",
      "11763106                                                NaN            \n",
      "11763107                                                NaN            \n",
      "11763108                                                NaN            \n",
      "11763109                                                NaN            \n",
      "\n",
      "[3669519 rows x 58 columns]\n",
      "[16 23 16 ... 14 19 16]\n",
      "1\n",
      "155\n",
      "740456\n"
     ]
    }
   ],
   "source": [
    "print(train.groupby(['week', 'customer_id']).head())\n",
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values\n",
    "print(train_baskets)\n",
    "print(train_baskets.min())\n",
    "print(train_baskets.max())\n",
    "print(len(train_baskets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "562146df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b26b0a",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "17079af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "00b6186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker=LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=LGBMBoostingType,\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31408339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.950937\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.587704\n",
      "[LightGBM] [Debug] init for col-wise cost 0.203148 seconds, init for row-wise cost 0.745130 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.284742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1705\n",
      "[LightGBM] [Info] Number of data points in the train set: 11763121, number of used features: 39\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7396bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestseller_rank 0.9567943641944198\n",
      "importance 0.026128328526149804\n",
      "amount_of_(graphical_appearance_no) 0.006453846715952977\n",
      "amount_of_(garment_group_no) 0.003946701752258956\n",
      "amount_of_(index_group_no) 0.003250001892691782\n",
      "amount_of_(perceived_colour_value_id) 0.0008887343614860082\n",
      "amount_of_(perceived_colour_value_id_garment_group_no) 0.0007360766738528465\n",
      "amount_of_(index_group_no_graphical_appearance_no) 0.00036033079319751\n",
      "colour_group_code 0.00030375729146749916\n",
      "amount_of_(perceived_colour_value_id)_rank 0.00015486116377798586\n",
      "index_code 0.00012793118977318837\n",
      "department_no 0.00012724862876690906\n",
      "age 0.00012023531951202131\n",
      "graphical_appearance_no 0.00011264387064437051\n",
      "amount_of_(graphical_appearance_no_garment_group_no) 0.00010442400362737722\n",
      "product_type_no 8.727700574973916e-05\n",
      "article_id 8.146636451343933e-05\n",
      "amount_of_(graphical_appearance_no_perceived_colour_value_id) 8.018011361834995e-05\n",
      "garment_group_no 7.436698091234603e-05\n",
      "perceived_colour_value_id 6.722315762714307e-05\n",
      "amount_of_(index_group_no)_rank 0.0\n",
      "amount_of_(graphical_appearance_no_garment_group_no)_rank 0.0\n",
      "amount_of_(graphical_appearance_no_perceived_colour_value_id)_rank 0.0\n",
      "perceived_colour_master_id 0.0\n",
      "amount_of_(index_group_no_garment_group_no)_rank 0.0\n",
      "amount_of_(index_group_no_garment_group_no) 0.0\n",
      "index_group_no 0.0\n",
      "section_no 0.0\n",
      "amount_of_(graphical_appearance_no)_rank 0.0\n",
      "FN 0.0\n",
      "Active 0.0\n",
      "club_member_status 0.0\n",
      "fashion_news_frequency 0.0\n",
      "amount_of_(index_group_no_perceived_colour_value_id)_rank 0.0\n",
      "postal_code 0.0\n",
      "amount_of_(index_group_no_perceived_colour_value_id) 0.0\n",
      "amount_of_(index_group_no_graphical_appearance_no)_rank 0.0\n",
      "amount_of_(garment_group_no)_rank 0.0\n",
      "amount_of_(perceived_colour_value_id_garment_group_no)_rank 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb34139",
   "metadata": {},
   "source": [
    "# Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fa10874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "c_id2predicted_article_ids = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e576d90",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eb1c56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03d79b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = []\n",
    "\n",
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)\n",
    "\n",
    "\n",
    "for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "    pred = c_id2predicted_article_ids.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e4ed109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "sub.prediction = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "245ce774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "basic_model_submission_dart_fillna-1bestsellerFiller999_weeks10_importance\n"
     ]
    }
   ],
   "source": [
    "sub_name = 'basic_model_submission_' +  str(LGBMBoostingType) + '_fillna' + str(preprocess) + 'bestsellerFiller' + str(bestsellerFiller) + \"_weeks\" + str(transactionBackXWeeks) + \"_importance\" + str(prevYear)\n",
    "sub.to_csv(f'../data/subs/{sub_name}.csv.gz', index=False)\n",
    "sub.to_csv(f'../data/subs/{sub_name}.csv', index=False)\n",
    "print(\"Done\")\n",
    "print(sub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fbb16d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c h-and-m-personalized-fashion-recommendations -f 'data/subs/{sub_name}.csv.gz' -m {sub_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
