{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Introduction to Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles = pd.read_csv('data/articles.csv')\n",
    "# customers = pd.read_csv('data/customers.csv')\n",
    "# transactions = pd.read_csv('data/transactions_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The H&M Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = transactions.merge(customers, how='inner', on='customer_id')\n",
    "# X = X.merge(articles, how='inner', on='article_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Samples \n",
    "If you would rather work with samples instead of the whole dataset (while prototyping your code). You can use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Adapted from: https://www.kaggle.com/code/paweljankiewicz/hm-create-dataset-samples\n",
    "# This extracts three sampled datasets, containing 0.1%, 1% and 5% of all users and their transactions, and the associated articles.\n",
    "# for sample_repr, sample in [(\"01\", 0.001), (\"1\", 0.01), (\"5\", 0.05)]:\n",
    "#     customers_sample = customers.sample(int(customers.shape[0]*sample), replace=False)\n",
    "#     customers_sample_ids = set(customers_sample[\"customer_id\"])\n",
    "#     transactions_sample = transactions[transactions[\"customer_id\"].isin(customers_sample_ids)]\n",
    "#     articles_sample_ids = set(transactions_sample[\"article_id\"])\n",
    "#     articles_sample = articles[articles[\"article_id\"].isin(articles_sample_ids)]\n",
    "#     customers_sample.to_csv(f\"data/customers_sample{sample_repr}.csv.gz\", index=False)\n",
    "#     transactions_sample.to_csv(f\"data/transactions_sample{sample_repr}.csv.gz\", index=False)\n",
    "#     articles_sample.to_csv(f\"data/articles_sample{sample_repr}.csv.gz\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# articles_sample = pd.read_csv('data/articles_sample5.csv.gz')\n",
    "# customers_sample = pd.read_csv('data/customers_sample5.csv.gz')\n",
    "# transactions_sample = pd.read_csv('data/transactions_sample5.csv.gz')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simplified Task: Binary Classification\n",
    "\n",
    "The task of predicting which 12 items users are most likely to buy in the next week is difficult to translate to a traditional classification machine learning setting. \n",
    "To obtain the 12 items a user is most likely to buy, we need to make predictions for all items (or the ones selected by a baseline) and select the 12 that have the highest predicted scores.\n",
    "\n",
    "In this assignment, we'll consider a simplified task: Predict whether a user ordered a single item or not, based on the features of the user and the item. \n",
    "We provide a baseline logistic regression model below, but haven't done much feature preprocessing or engineering!\n",
    "Initially, it is always best to focus your efforts on getting your features in the right shape and setting up the right validation scheme and baselines.\n",
    "Once you are sure that your features add value and your validation scheme is correct, then you typically move on to trying more elaborate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd rather use a sample. Uncomment the following code:\n",
    "sample = \"5\"\n",
    "\n",
    "articles = pd.read_csv(f'data/articles_sample{sample}.csv.gz')\n",
    "customers = pd.read_csv(f'data/customers_sample{sample}.csv.gz')\n",
    "transactions = pd.read_csv(f'data/transactions_sample{sample}.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['ordered'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem setting is an example of a \"PU learning\" problem, i.e. only positives are labeled, everything else is unlabeled (and can be either positive or negative). \n",
    "Of course, we cannot train a classifier with just positive samples: The classifier will just learn that everything is positive.\n",
    "Therefore, we need to manually generate negative samples.\n",
    "\n",
    "Below, we use a simple random negative sampling strategy.\n",
    "We want to create a balanced dataset, meaning that we have just as many positives as negatives.\n",
    "This makes sure that the classifier will not benefit from predicting the positive/negative class more often than the other.\n",
    "Realistically, the amount of positive samples is of course many times smaller than the amount of unlabeled, possibly negative instances.\n",
    "\n",
    "\n",
    "If you want to try your hand at a more complex negative sampling strategy, you may want to check out this blog as a starting point: https://medium.com/mlearning-ai/overview-negative-sampling-on-recommendation-systems-230a051c6cd7.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        t_dat                                        customer_id  article_id  \\\n0  2018-09-20  001fd23db1109a94bba1319bb73df0b479059027c182da...   631744002   \n1  2018-09-20  001fd23db1109a94bba1319bb73df0b479059027c182da...   562252035   \n2  2018-09-20  00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...   255396006   \n3  2018-09-20  00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...   594834010   \n4  2018-09-20  00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...   516712001   \n\n      price  sales_channel_id  ordered  \n0  0.016932                 1        1  \n1  0.021593                 1        1  \n2  0.067780                 2        1  \n3  0.042356                 2        1  \n4  0.022017                 2        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-20</td>\n      <td>001fd23db1109a94bba1319bb73df0b479059027c182da...</td>\n      <td>631744002</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-20</td>\n      <td>001fd23db1109a94bba1319bb73df0b479059027c182da...</td>\n      <td>562252035</td>\n      <td>0.021593</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-09-20</td>\n      <td>00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...</td>\n      <td>255396006</td>\n      <td>0.067780</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-09-20</td>\n      <td>00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...</td>\n      <td>594834010</td>\n      <td>0.042356</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-09-20</td>\n      <td>00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...</td>\n      <td>516712001</td>\n      <td>0.022017</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's happening here? \n",
    "# We're creating negative samples. I.e. we're creating transactions that didn't actually occur.\n",
    "# First, we need to know which interactions did occur:\n",
    "positive_pairs = list(map(tuple, transactions[['customer_id', 'article_id']].drop_duplicates().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        t_dat                                        customer_id  article_id  \\\n0  2018-09-20  001fd23db1109a94bba1319bb73df0b479059027c182da...   631744002   \n1  2018-09-20  001fd23db1109a94bba1319bb73df0b479059027c182da...   562252035   \n2  2018-09-20  00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...   255396006   \n3  2018-09-20  00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...   594834010   \n4  2018-09-20  00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...   516712001   \n\n      price  sales_channel_id  ordered  \n0  0.016932                 1        1  \n1  0.021593                 1        1  \n2  0.067780                 2        1  \n3  0.042356                 2        1  \n4  0.022017                 2        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-20</td>\n      <td>001fd23db1109a94bba1319bb73df0b479059027c182da...</td>\n      <td>631744002</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-20</td>\n      <td>001fd23db1109a94bba1319bb73df0b479059027c182da...</td>\n      <td>562252035</td>\n      <td>0.021593</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-09-20</td>\n      <td>00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...</td>\n      <td>255396006</td>\n      <td>0.067780</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-09-20</td>\n      <td>00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...</td>\n      <td>594834010</td>\n      <td>0.042356</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-09-20</td>\n      <td>00708c3da4d07706d4cad77c6aecc1b1ce33d21d73022c...</td>\n      <td>516712001</td>\n      <td>0.022017</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we need to know what every synthetic transaction should contain: a date, a customer_id, an article_id, price, sales_channel_id. We will set ordered = 0, as these transactions didn't really occur.\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract real values\n",
    "real_dates = transactions[\"t_dat\"].unique()\n",
    "real_customers = transactions[\"customer_id\"].unique()\n",
    "real_articles = transactions[\"article_id\"].unique()\n",
    "real_channels = transactions[\"sales_channel_id\"].unique()\n",
    "article_and_price = transactions[[\"article_id\",\"price\"]].drop_duplicates(\"article_id\").set_index(\"article_id\").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566354\n"
     ]
    }
   ],
   "source": [
    "# How many negatives do we need to sample?\n",
    "num_neg_pos = transactions.shape[0]\n",
    "print(num_neg_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling negatives by selecting random users, articles, dates and sales channel:\n",
    "# Note: This is quite naive. Some articles may not even have been available at the date we are sampling.\n",
    "random.seed(42)\n",
    "\n",
    "# Afterwards, we need to remove potential duplicates, so we'll sample too many.\n",
    "num_neg_samples = int(num_neg_pos * 1.1)\n",
    "\n",
    "# Sample each of the independent attributes.\n",
    "neg_dates = np.random.choice(real_dates, size=num_neg_samples)\n",
    "neg_articles = np.random.choice(real_articles, size=num_neg_samples)\n",
    "neg_customers = np.random.choice(real_customers, size=num_neg_samples)\n",
    "neg_channels = np.random.choice(real_channels, size=num_neg_samples)\n",
    "ordered = np.array([0] * num_neg_samples)\n",
    "# Assign to every article a real price.\n",
    "neg_prices = article_and_price[neg_articles].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_transactions = pd.DataFrame([neg_dates, neg_customers, neg_articles, neg_prices, neg_channels, ordered], index=transactions.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        t_dat                                        customer_id article_id  \\\n0  2020-06-24  00386204792883fdad2a2f5aa6ee2354e6019518fe31cc...  720137007   \n1  2020-07-25  6e28d610e006e71d4708469df683efcc1bbed528f73945...  399223034   \n2  2018-10-17  eb84b0d215fff1bd481867543bb14f5cda104904b07eae...  669900002   \n3  2019-11-21  c2e7fc9f53ccce64884ff3b65a3cbef869ebcceeb04468...  679135003   \n4  2019-06-23  6dc70e9b92075149ef1ac4696404775e21ec6908ab1a53...  799679001   \n\n      price sales_channel_id ordered  \n0  0.003373                1       0  \n1  0.033881                2       0  \n2  0.040661                1       0  \n3  0.042356                2       0  \n4  0.010593                2       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-24</td>\n      <td>00386204792883fdad2a2f5aa6ee2354e6019518fe31cc...</td>\n      <td>720137007</td>\n      <td>0.003373</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-07-25</td>\n      <td>6e28d610e006e71d4708469df683efcc1bbed528f73945...</td>\n      <td>399223034</td>\n      <td>0.033881</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-10-17</td>\n      <td>eb84b0d215fff1bd481867543bb14f5cda104904b07eae...</td>\n      <td>669900002</td>\n      <td>0.040661</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-11-21</td>\n      <td>c2e7fc9f53ccce64884ff3b65a3cbef869ebcceeb04468...</td>\n      <td>679135003</td>\n      <td>0.042356</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-06-23</td>\n      <td>6dc70e9b92075149ef1ac4696404775e21ec6908ab1a53...</td>\n      <td>799679001</td>\n      <td>0.010593</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result:\n",
    "neg_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1722989, 6)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove random negative samples that actually coincide with positives\n",
    "df = neg_transactions[\n",
    "    ~neg_transactions.set_index([\"customer_id\", \"article_id\"]).index.isin(positive_pairs)\n",
    "]\n",
    "\n",
    "# Remove any excess\n",
    "chosen_neg_transactions = df.sample(num_neg_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the negative samples to the positive samples:\n",
    "transactions = pd.concat([transactions, chosen_neg_transactions])\n",
    "transactions = transactions.merge(customers, how=\"inner\", on='customer_id')\n",
    "transactions = transactions.merge(articles, how=\"inner\", on='article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3132708 entries, 0 to 3132707\n",
      "Data columns (total 36 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   t_dat                         object \n",
      " 1   customer_id                   object \n",
      " 2   article_id                    object \n",
      " 3   price                         object \n",
      " 4   sales_channel_id              object \n",
      " 5   ordered                       object \n",
      " 6   FN                            float64\n",
      " 7   Active                        float64\n",
      " 8   club_member_status            object \n",
      " 9   fashion_news_frequency        object \n",
      " 10  age                           float64\n",
      " 11  postal_code                   object \n",
      " 12  product_code                  int64  \n",
      " 13  prod_name                     object \n",
      " 14  product_type_no               int64  \n",
      " 15  product_type_name             object \n",
      " 16  product_group_name            object \n",
      " 17  graphical_appearance_no       int64  \n",
      " 18  graphical_appearance_name     object \n",
      " 19  colour_group_code             int64  \n",
      " 20  colour_group_name             object \n",
      " 21  perceived_colour_value_id     int64  \n",
      " 22  perceived_colour_value_name   object \n",
      " 23  perceived_colour_master_id    int64  \n",
      " 24  perceived_colour_master_name  object \n",
      " 25  department_no                 int64  \n",
      " 26  department_name               object \n",
      " 27  index_code                    object \n",
      " 28  index_name                    object \n",
      " 29  index_group_no                int64  \n",
      " 30  index_group_name              object \n",
      " 31  section_no                    int64  \n",
      " 32  section_name                  object \n",
      " 33  garment_group_no              int64  \n",
      " 34  garment_group_name            object \n",
      " 35  detail_desc                   object \n",
      "dtypes: float64(3), int64(10), object(23)\n",
      "memory usage: 884.3+ MB\n"
     ]
    }
   ],
   "source": [
    "transactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Preprocessing\n",
    "Some very basic preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                         customer_id   age article_id  \\\n0  001fd23db1109a94bba1319bb73df0b479059027c182da...  53.0  631744002   \n1  ab355a515d8eb0038a4b39aa9fd9439af221d3beca0794...  27.0  631744002   \n2  4471add869b42428fcc4aab3dccdac378542f4c2ec4b15...  24.0  631744002   \n3  02fcbfadd7f268ee2604ae1d2b8d944e2e946f8b297cbd...  26.0  631744002   \n4  c5609385a4ab538a56c5e1c54355c5b4e6fa5956d3ce9d...  47.0  631744002   \n\n  sales_channel_id     price ordered  \n0                1  0.016932       1  \n1                1  0.016932       0  \n2                2  0.016932       0  \n3                2  0.016932       0  \n4                2  0.016932       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>sales_channel_id</th>\n      <th>price</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001fd23db1109a94bba1319bb73df0b479059027c182da...</td>\n      <td>53.0</td>\n      <td>631744002</td>\n      <td>1</td>\n      <td>0.016932</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ab355a515d8eb0038a4b39aa9fd9439af221d3beca0794...</td>\n      <td>27.0</td>\n      <td>631744002</td>\n      <td>1</td>\n      <td>0.016932</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4471add869b42428fcc4aab3dccdac378542f4c2ec4b15...</td>\n      <td>24.0</td>\n      <td>631744002</td>\n      <td>2</td>\n      <td>0.016932</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>02fcbfadd7f268ee2604ae1d2b8d944e2e946f8b297cbd...</td>\n      <td>26.0</td>\n      <td>631744002</td>\n      <td>2</td>\n      <td>0.016932</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c5609385a4ab538a56c5e1c54355c5b4e6fa5956d3ce9d...</td>\n      <td>47.0</td>\n      <td>631744002</td>\n      <td>2</td>\n      <td>0.016932</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm dropping a lot of columns, use them in your engineering tasks!\n",
    "transactions_processed = transactions[['customer_id', 'age', 'article_id', 'sales_channel_id', 'price', 'ordered']].copy()\n",
    "transactions_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does it make sense to label encode?\n",
    "# Label encoding the customer and article IDs:\n",
    "customer_encoder = preprocessing.LabelEncoder()\n",
    "article_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_processed['customer_id'] = customer_encoder.fit_transform(transactions_processed['customer_id'])\n",
    "transactions_processed['article_id'] = article_encoder.fit_transform(transactions_processed['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['0001b0127d3e5ff8dadcfc6e5043682dba2070f2667081623faeb31c996242a6'],\n      dtype=object)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to go back to the original encoding:\n",
    "customer_encoder.inverse_transform([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   customer_id   age  article_id sales_channel_id     price ordered\n0           32  53.0       19551                1  0.016932       1\n1        45430  27.0       19551                1  0.016932       0\n2        18287  24.0       19551                2  0.016932       0\n3          796  26.0       19551                2  0.016932       0\n4        52507  47.0       19551                2  0.016932       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>sales_channel_id</th>\n      <th>price</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32</td>\n      <td>53.0</td>\n      <td>19551</td>\n      <td>1</td>\n      <td>0.016932</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45430</td>\n      <td>27.0</td>\n      <td>19551</td>\n      <td>1</td>\n      <td>0.016932</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18287</td>\n      <td>24.0</td>\n      <td>19551</td>\n      <td>2</td>\n      <td>0.016932</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>796</td>\n      <td>26.0</td>\n      <td>19551</td>\n      <td>2</td>\n      <td>0.016932</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52507</td>\n      <td>47.0</td>\n      <td>19551</td>\n      <td>2</td>\n      <td>0.016932</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can you come up with a NaN strategy that makes sense for each column in the dataset?\n",
    "# Imputing all NaN values with zeros:\n",
    "transactions_processed = transactions_processed.fillna(0)\n",
    "transactions_processed.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does it make sense to one-hot encode?\n",
    "# One-hot-encoding sales_channel_id:\n",
    "transactions_processed = pd.get_dummies(transactions_processed, columns=['sales_channel_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   customer_id   age  article_id     price  ordered  sales_channel_id_1  \\\n0           32  53.0       19551  0.016932        1                   1   \n1        45430  27.0       19551  0.016932        0                   1   \n2        18287  24.0       19551  0.016932        0                   0   \n3          796  26.0       19551  0.016932        0                   0   \n4        52507  47.0       19551  0.016932        0                   0   \n\n   sales_channel_id_2  \n0                   0  \n1                   0  \n2                   1  \n3                   1  \n4                   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>ordered</th>\n      <th>sales_channel_id_1</th>\n      <th>sales_channel_id_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32</td>\n      <td>53.0</td>\n      <td>19551</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45430</td>\n      <td>27.0</td>\n      <td>19551</td>\n      <td>0.016932</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18287</td>\n      <td>24.0</td>\n      <td>19551</td>\n      <td>0.016932</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>796</td>\n      <td>26.0</td>\n      <td>19551</td>\n      <td>0.016932</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52507</td>\n      <td>47.0</td>\n      <td>19551</td>\n      <td>0.016932</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Train / Test Split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(transactions_processed.drop('ordered', axis=1), transactions_processed['ordered'], test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         customer_id   age  article_id     price  sales_channel_id_1  \\\n176388          1839  20.0       22627  0.016932                   1   \n806818         17597  27.0       53004  0.118627                   1   \n1807634        32964   0.0       62961  0.013542                   0   \n1343423        23362  57.0       10439  0.033881                   0   \n233105         42647  27.0       13494  0.015237                   0   \n\n         sales_channel_id_2  \n176388                    0  \n806818                    0  \n1807634                   1  \n1343423                   1  \n233105                    1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>age</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id_1</th>\n      <th>sales_channel_id_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>176388</th>\n      <td>1839</td>\n      <td>20.0</td>\n      <td>22627</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806818</th>\n      <td>17597</td>\n      <td>27.0</td>\n      <td>53004</td>\n      <td>0.118627</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1807634</th>\n      <td>32964</td>\n      <td>0.0</td>\n      <td>62961</td>\n      <td>0.013542</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1343423</th>\n      <td>23362</td>\n      <td>57.0</td>\n      <td>10439</td>\n      <td>0.033881</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>233105</th>\n      <td>42647</td>\n      <td>27.0</td>\n      <td>13494</td>\n      <td>0.015237</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "176388     0\n806818     0\n1807634    0\n1343423    0\n233105     0\nName: ordered, dtype: int64"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will take a few minutes to run, if you're using the whole dataset:\n",
    "baseline = LogisticRegression(random_state=42)\n",
    "baseline = baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.51234718, 0.48765282],\n       [0.50411886, 0.49588114],\n       [0.51145939, 0.48854061],\n       ...,\n       [0.51829938, 0.48170062],\n       [0.50760542, 0.49239458],\n       [0.49215028, 0.50784972]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1649772    1\n482687     1\n393230     1\n3082071    0\n2353135    1\n          ..\n3097538    0\n2032851    0\n1323787    0\n535384     1\n2428458    0\nName: ordered, Length: 313271, dtype: int64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.5064433030826345"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Accuracy:\n",
    "baseline.score(X_test, y_test)\n",
    "# As you can see, the accuracy is ~0.51. In other words, the classifier predicts correctly 51% of the time whether a customer did or didn't buy an item.\n",
    "# Can you improve this baseline logistic regression model by doing better preprocessing and generating new features?\n",
    "# Also think about my steps! Did it make sense to include the article and customer ids? (And things like that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.55      0.52    156287\n",
      "           1       0.51      0.47      0.49    156984\n",
      "\n",
      "    accuracy                           0.51    313271\n",
      "   macro avg       0.51      0.51      0.51    313271\n",
      "weighted avg       0.51      0.51      0.51    313271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Metrics:\n",
    "predictions = baseline.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Feature engineering\n",
    "**TODO:** \n",
    "- In groups (of 2-3 students), think about (a few) features that can be engineered (preprocess and generate new features). Divide the work!\n",
    "- Do these engineered features improve the baseline model?\n",
    "- Add your thoughts & results to a slide deck for discussion next week (again, 1 slide per person).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "        t_dat                                        customer_id article_id  \\\n0  2018-09-20  001fd23db1109a94bba1319bb73df0b479059027c182da...  631744002   \n1  2019-08-27  ab355a515d8eb0038a4b39aa9fd9439af221d3beca0794...  631744002   \n2  2019-02-25  4471add869b42428fcc4aab3dccdac378542f4c2ec4b15...  631744002   \n3  2020-06-12  02fcbfadd7f268ee2604ae1d2b8d944e2e946f8b297cbd...  631744002   \n4  2020-01-21  c5609385a4ab538a56c5e1c54355c5b4e6fa5956d3ce9d...  631744002   \n\n      price sales_channel_id ordered   FN  Active club_member_status  \\\n0  0.016932                1       1  NaN     NaN             ACTIVE   \n1  0.016932                1       0  1.0     1.0             ACTIVE   \n2  0.016932                2       0  NaN     NaN             ACTIVE   \n3  0.016932                2       0  NaN     NaN             ACTIVE   \n4  0.016932                2       0  1.0     1.0             ACTIVE   \n\n  fashion_news_frequency  ...   department_name index_code        index_name  \\\n0                   NONE  ...  Shopbasket Socks          B  Lingeries/Tights   \n1              Regularly  ...  Shopbasket Socks          B  Lingeries/Tights   \n2                   NONE  ...  Shopbasket Socks          B  Lingeries/Tights   \n3                   NONE  ...  Shopbasket Socks          B  Lingeries/Tights   \n4              Regularly  ...  Shopbasket Socks          B  Lingeries/Tights   \n\n  index_group_no  index_group_name section_no                    section_name  \\\n0              1        Ladieswear         62  Womens Nightwear, Socks & Tigh   \n1              1        Ladieswear         62  Womens Nightwear, Socks & Tigh   \n2              1        Ladieswear         62  Womens Nightwear, Socks & Tigh   \n3              1        Ladieswear         62  Womens Nightwear, Socks & Tigh   \n4              1        Ladieswear         62  Womens Nightwear, Socks & Tigh   \n\n   garment_group_no garment_group_name  \\\n0              1021   Socks and Tights   \n1              1021   Socks and Tights   \n2              1021   Socks and Tights   \n3              1021   Socks and Tights   \n4              1021   Socks and Tights   \n\n                                         detail_desc  \n0  Fine-knit shaftless socks with a silicone trim...  \n1  Fine-knit shaftless socks with a silicone trim...  \n2  Fine-knit shaftless socks with a silicone trim...  \n3  Fine-knit shaftless socks with a silicone trim...  \n4  Fine-knit shaftless socks with a silicone trim...  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>ordered</th>\n      <th>FN</th>\n      <th>Active</th>\n      <th>club_member_status</th>\n      <th>fashion_news_frequency</th>\n      <th>...</th>\n      <th>department_name</th>\n      <th>index_code</th>\n      <th>index_name</th>\n      <th>index_group_no</th>\n      <th>index_group_name</th>\n      <th>section_no</th>\n      <th>section_name</th>\n      <th>garment_group_no</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-20</td>\n      <td>001fd23db1109a94bba1319bb73df0b479059027c182da...</td>\n      <td>631744002</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ACTIVE</td>\n      <td>NONE</td>\n      <td>...</td>\n      <td>Shopbasket Socks</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>62</td>\n      <td>Womens Nightwear, Socks &amp; Tigh</td>\n      <td>1021</td>\n      <td>Socks and Tights</td>\n      <td>Fine-knit shaftless socks with a silicone trim...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-08-27</td>\n      <td>ab355a515d8eb0038a4b39aa9fd9439af221d3beca0794...</td>\n      <td>631744002</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>ACTIVE</td>\n      <td>Regularly</td>\n      <td>...</td>\n      <td>Shopbasket Socks</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>62</td>\n      <td>Womens Nightwear, Socks &amp; Tigh</td>\n      <td>1021</td>\n      <td>Socks and Tights</td>\n      <td>Fine-knit shaftless socks with a silicone trim...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-02-25</td>\n      <td>4471add869b42428fcc4aab3dccdac378542f4c2ec4b15...</td>\n      <td>631744002</td>\n      <td>0.016932</td>\n      <td>2</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ACTIVE</td>\n      <td>NONE</td>\n      <td>...</td>\n      <td>Shopbasket Socks</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>62</td>\n      <td>Womens Nightwear, Socks &amp; Tigh</td>\n      <td>1021</td>\n      <td>Socks and Tights</td>\n      <td>Fine-knit shaftless socks with a silicone trim...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-12</td>\n      <td>02fcbfadd7f268ee2604ae1d2b8d944e2e946f8b297cbd...</td>\n      <td>631744002</td>\n      <td>0.016932</td>\n      <td>2</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ACTIVE</td>\n      <td>NONE</td>\n      <td>...</td>\n      <td>Shopbasket Socks</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>62</td>\n      <td>Womens Nightwear, Socks &amp; Tigh</td>\n      <td>1021</td>\n      <td>Socks and Tights</td>\n      <td>Fine-knit shaftless socks with a silicone trim...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-01-21</td>\n      <td>c5609385a4ab538a56c5e1c54355c5b4e6fa5956d3ce9d...</td>\n      <td>631744002</td>\n      <td>0.016932</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>ACTIVE</td>\n      <td>Regularly</td>\n      <td>...</td>\n      <td>Shopbasket Socks</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>62</td>\n      <td>Womens Nightwear, Socks &amp; Tigh</td>\n      <td>1021</td>\n      <td>Socks and Tights</td>\n      <td>Fine-knit shaftless socks with a silicone trim...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "fn_encoder = preprocessing.LabelEncoder()\n",
    "active_encoder = preprocessing.LabelEncoder()\n",
    "club_member_status_encoder = preprocessing.LabelEncoder()\n",
    "fashion_news_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "transactions['FN'] = fn_encoder.fit_transform(transactions['FN'])\n",
    "transactions['Active'] = active_encoder.fit_transform(transactions['Active'])\n",
    "transactions['club_member_status'] = club_member_status_encoder.fit_transform(transactions['club_member_status'])\n",
    "transactions['fashion_news_frequency'] = fashion_news_encoder.fit_transform(transactions['fashion_news_frequency'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "transactions['t_days'] = df['t_dat'].apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d').value)\n",
    "article_grouped = transactions.groupby('article_id')\n",
    "customer_grouped = transactions.groupby('customer_id')\n",
    "\n",
    "interval = lambda group: group['t_days'].max() - group['t_days'].min() / group['t_days'].count()\n",
    "\n",
    "mean_age = article_grouped['age'].mean().reset_index(name=\"mean_age\")\n",
    "last_bought = article_grouped['t_days'].max().reset_index(name=\"last_bought\")\n",
    "buy_interval = article_grouped.apply(interval).reset_index(name=\"buy_interval\")\n",
    "mean_price = customer_grouped['price'].mean().reset_index(name=\"mean_price\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# buy_interval.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "transactions.drop(columns=[\"mean_age\", \"age_diff\", \"last_bought\", \"buy_interval\", \"mean_price\"], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "transactions = pd.merge(transactions, mean_age, on='article_id', how='left')\n",
    "transactions = pd.merge(transactions, last_bought, on='article_id', how='left')\n",
    "transactions = pd.merge(transactions, buy_interval, on='article_id', how='left')\n",
    "transactions = pd.merge(transactions, mean_price, on='customer_id', how='left')\n",
    "\n",
    "transactions['age_diff'] = transactions['age'] - transactions['mean_age']\n",
    "transactions['price_diff'] = transactions['price'] - transactions['mean_price']\n",
    "\n",
    "transactions['age_diff'] = pd.DataFrame(minmax_scale(transactions['age_diff']))\n",
    "transactions['age'] = pd.DataFrame(minmax_scale(transactions['age']))\n",
    "transactions['last_bought'] = pd.DataFrame(minmax_scale(transactions['last_bought']))\n",
    "transactions['buy_interval'] = pd.DataFrame(minmax_scale(transactions['buy_interval']))\n",
    "transactions['price_diff'] = pd.DataFrame(minmax_scale(transactions['price_diff']))\n",
    "transactions['price'] = pd.DataFrame(minmax_scale(transactions['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "   ordered  FN  Active  club_member_status  fashion_news_frequency  \\\n0        1   1       1                   0                       1   \n1        0   0       0                   0                       2   \n2        0   1       1                   0                       1   \n3        0   1       1                   0                       1   \n4        0   0       0                   0                       2   \n5        0   1       1                   0                       1   \n6        1   1       1                   0                       1   \n7        0   0       0                   0                       2   \n8        0   1       1                   0                       1   \n9        1   0       0                   0                       2   \n\n   sales_channel_id_1  sales_channel_id_2  \n0                   1                   0  \n1                   1                   0  \n2                   0                   1  \n3                   0                   1  \n4                   0                   1  \n5                   0                   1  \n6                   1                   0  \n7                   0                   1  \n8                   1                   0  \n9                   1                   0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ordered</th>\n      <th>FN</th>\n      <th>Active</th>\n      <th>club_member_status</th>\n      <th>fashion_news_frequency</th>\n      <th>sales_channel_id_1</th>\n      <th>sales_channel_id_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed = transactions[['sales_channel_id', 'ordered', 'price', 'price_diff', 'age_diff', 'last_bought', 'buy_interval', 'FN', 'Active', 'club_member_status', 'fashion_news_frequency']]\n",
    "processed = transactions[['sales_channel_id', 'ordered', 'FN', 'Active', 'club_member_status', 'fashion_news_frequency']]\n",
    "\n",
    "# processed = transactions[['age', 'sales_channel_id', 'price', 'ordered']].copy()\n",
    "\n",
    "processed = processed.fillna(0)\n",
    "processed.isnull().values.any()\n",
    "\n",
    "processed = pd.get_dummies(processed, columns=['sales_channel_id'])\n",
    "\n",
    "processed.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58    156287\n",
      "           1       0.60      0.68      0.64    156984\n",
      "\n",
      "    accuracy                           0.61    313271\n",
      "   macro avg       0.61      0.61      0.61    313271\n",
      "weighted avg       0.61      0.61      0.61    313271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(processed.drop('ordered', axis=1), processed['ordered'], test_size=0.10, random_state=42)\n",
    "\n",
    "baseline = LogisticRegression(random_state=42)\n",
    "baseline = baseline.fit(X_train, y_train)\n",
    "\n",
    "baseline.score(X_test, y_test)\n",
    "\n",
    "predictions = baseline.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
